<extensionManifest><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-nar</artifactId><version>2.4.0</version><parentNar><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-shared-nar</artifactId><version>2.4.0</version></parentNar><systemApiVersion>2.1.0</systemApiVersion><buildInfo><tag>HEAD</tag><branch>UNKNOWN</branch><revision>65c7732</revision></buildInfo><extensions><extension><name>org.apache.nifi.processors.standard.AttributesToCSV</name><type>PROCESSOR</type><description>Generates a CSV representation of the input FlowFile Attributes. The resulting CSV can be written to either a newly generated attribute named 'CSVAttributes' or written to the FlowFile as content.  If the attribute value contains a comma, newline or double quote, then the attribute value will be escaped with double quotes.  Any double quote characters in the attribute value are escaped with another double quote.</description><tags><tag>csv</tag><tag>attributes</tag><tag>flowfile</tag></tags><properties><property><name>attribute-list</name><displayName>Attribute List</displayName><description>Comma separated list of attributes to be included in the resulting CSV. If this value is left empty then all existing Attributes will be included. This list of attributes is case sensitive and supports attribute names that contain commas. If an attribute specified in the list is not found it will be emitted to the resulting CSV with an empty string or null depending on the 'Null Value' property. If a core attribute is specified in this list and the 'Include Core Attributes' property is false, the core attribute will be included. The attribute list ALWAYS wins.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>attributes-regex</name><displayName>Attributes Regular Expression</displayName><description>Regular expression that will be evaluated against the flow file attributes to select the matching attributes. This property can be used in combination with the attributes list property.  The final output will contain a combination of matches found in the ATTRIBUTE_LIST and ATTRIBUTE_REGEX.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>destination</name><displayName>Destination</displayName><description>Control if CSV value is written as a new flowfile attribute 'CSVData' or written in the flowfile content.</description><defaultValue>flowfile-attribute</defaultValue><allowableValues><allowableValue><displayName>flowfile-attribute</displayName><value>flowfile-attribute</value><description>The resulting CSV string will be placed into a new flowfile attribute named 'CSVData'.  The content of the flowfile will not be changed.</description></allowableValue><allowableValue><displayName>flowfile-content</displayName><value>flowfile-content</value><description>The resulting CSV string will be placed into the content of the flowfile.Existing flowfile context will be overwritten. 'CSVData' will not be written to at all (neither null nor empty string).</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>include-core-attributes</name><displayName>Include Core Attributes</displayName><description>Determines if the FlowFile org.apache.nifi.flowfile.attributes.CoreAttributes, which are contained in every FlowFile, should be included in the final CSV value generated.  Core attributes will be added to the end of the CSVData and CSVSchema strings.  The Attribute List property overrides this setting.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>null-value</name><displayName>Null Value</displayName><description>If true a non existing or empty attribute will be 'null' in the resulting CSV. If false an empty string will be placed in the CSV</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>include-schema</name><displayName>Include Schema</displayName><description>If true the schema (attribute names) will also be converted to a CSV string which will either be applied to a new attribute named 'CSVSchema' or applied at the first row in the content depending on the DESTINATION property setting.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>Failed to convert attributes to CSV</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>Successfully converted attributes to CSV</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>CSVSchema</name><description>CSV representation of the Schema</description></writesAttribute><writesAttribute><name>CSVData</name><description>CSV representation of Attributes</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.AttributesToJSON</name><type>PROCESSOR</type><description>Generates a JSON representation of the input FlowFile Attributes. The resulting JSON can be written to either a new Attribute 'JSONAttributes' or written to the FlowFile as content. Attributes  which contain nested JSON objects can either be handled as JSON or as escaped JSON depending on the strategy chosen.</description><tags><tag>json</tag><tag>attributes</tag><tag>flowfile</tag></tags><properties><property><name>Attributes List</name><displayName>Attributes List</displayName><description>Comma separated list of attributes to be included in the resulting JSON. If this value is left empty then all existing Attributes will be included. This list of attributes is case sensitive. If an attribute specified in the list is not found it will be be emitted to the resulting JSON with an empty string or NULL value.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>attributes-to-json-regex</name><displayName>Attributes Regular Expression</displayName><description>Regular expression that will be evaluated against the flow file attributes to select the matching attributes. This property can be used in combination with the attributes list property.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Destination</name><displayName>Destination</displayName><description>Control if JSON value is written as a new flowfile attribute 'JSONAttributes' or written in the flowfile content. Writing to flowfile content will overwrite any existing flowfile content.</description><defaultValue>flowfile-attribute</defaultValue><allowableValues><allowableValue><displayName>flowfile-attribute</displayName><value>flowfile-attribute</value><description></description></allowableValue><allowableValue><displayName>flowfile-content</displayName><value>flowfile-content</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Include Core Attributes</name><displayName>Include Core Attributes</displayName><description>Determines if the FlowFile org.apache.nifi.flowfile.attributes.CoreAttributes which are contained in every FlowFile should be included in the final JSON value generated.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Null Value</name><displayName>Null Value</displayName><description>If true a non existing selected attribute will be NULL in the resulting JSON. If false an empty string will be placed in the JSON</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>JSON Handling Strategy</name><displayName>JSON Handling Strategy</displayName><description>Strategy to use for handling attributes which contain nested JSON.</description><defaultValue>ESCAPED</defaultValue><allowableValues><allowableValue><displayName>Escaped</displayName><value>ESCAPED</value><description>Escapes JSON attribute values to strings</description></allowableValue><allowableValue><displayName>Nested</displayName><value>NESTED</value><description>Handles JSON attribute values as nested structured objects or arrays</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Pretty Print</name><displayName>Pretty Print</displayName><description>Apply pretty print formatting to the output.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Destination</propertyName><propertyDisplayName>Destination</propertyDisplayName><dependentValues><dependentValue>flowfile-content</dependentValue></dependentValues></dependency></dependencies></property></properties><relationships><relationship><name>failure</name><description>Failed to convert attributes to JSON</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>Successfully converted attributes to JSON</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>JSONAttributes</name><description>JSON representation of Attributes</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.CalculateRecordStats</name><type>PROCESSOR</type><description>Counts the number of Records in a record set, optionally counting the number of elements per category, where the categories are defined by user-defined properties.</description><tags><tag>record</tag><tag>stats</tag><tag>metrics</tag></tags><properties><property><name>record-stats-reader</name><displayName>Record Reader</displayName><description>A record reader to use for reading the records.</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>record-stats-limit</name><displayName>record-stats-limit</displayName><description>Limit the number of individual stats that are returned for each record path to the top N results.</description><defaultValue>10</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>The name of the category. For example, sport</name><value>The RecordPath that points to the value of the category. For example /sport</value><description>Specifies a category that should be counted. For example, if the property name is 'sport' and the value is '/sport', the processor will count how many records have a value of 'soccer' for the /sport field, how many have a value of 'baseball' for the /sport, and so on. These counts be added as attributes named recordStats.sport.soccer, recordStats.sport.baseball.</description><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>failure</name><description>If a FlowFile cannot be processed for any reason, it is routed to this Relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>All FlowFiles that are successfully processed, are routed to this Relationship.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>record.count</name><description>A count of the records in the record set in the FlowFile.</description></writesAttribute><writesAttribute><name>recordStats.&lt;User Defined Property Name&gt;.count</name><description>A count of the records that contain a value for the user defined property.</description></writesAttribute><writesAttribute><name>recordStats.&lt;User Defined Property Name&gt;.&lt;value&gt;.count</name><description>Each value discovered for the user defined property will have its own count attribute. Total number of top N value counts to be added is defined by the limit configuration.</description></writesAttribute></writesAttributes><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.CompressContent</name><type>PROCESSOR</type><description>Compresses or decompresses the contents of FlowFiles using a user-specified compression algorithm and updates the mime.type attribute as appropriate. A common idiom is to precede CompressContent with IdentifyMimeType and configure Mode='decompress' AND Compression Format='use mime.type attribute'. When used in this manner, the MIME type is automatically detected and the data is decompressed, if necessary. If decompression is unnecessary, the data is passed through to the 'success' relationship. This processor operates in a very memory efficient way so very large objects well beyond the heap size are generally fine to process.</description><tags><tag>content</tag><tag>compress</tag><tag>decompress</tag><tag>gzip</tag><tag>bzip2</tag><tag>lzma</tag><tag>xz-lzma2</tag><tag>snappy</tag><tag>snappy-hadoop</tag><tag>snappy framed</tag><tag>lz4-framed</tag><tag>deflate</tag><tag>zstd</tag><tag>brotli</tag></tags><properties><property><name>Mode</name><displayName>Mode</displayName><description>Indicates whether the processor should compress content or decompress content. Must be either 'compress' or 'decompress'</description><defaultValue>compress</defaultValue><allowableValues><allowableValue><displayName>compress</displayName><value>compress</value><description></description></allowableValue><allowableValue><displayName>decompress</displayName><value>decompress</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Compression Format</name><displayName>Compression Format</displayName><description>The compression format to use. Valid values are: GZIP, Deflate, ZSTD, BZIP2, XZ-LZMA2, LZMA, Brotli, Snappy, Snappy Hadoop, Snappy Framed, and LZ4-Framed</description><defaultValue>use mime.type attribute</defaultValue><allowableValues><allowableValue><displayName>use mime.type attribute</displayName><value>use mime.type attribute</value><description></description></allowableValue><allowableValue><displayName>gzip</displayName><value>gzip</value><description></description></allowableValue><allowableValue><displayName>deflate</displayName><value>deflate</value><description></description></allowableValue><allowableValue><displayName>bzip2</displayName><value>bzip2</value><description></description></allowableValue><allowableValue><displayName>xz-lzma2</displayName><value>xz-lzma2</value><description></description></allowableValue><allowableValue><displayName>lzma</displayName><value>lzma</value><description></description></allowableValue><allowableValue><displayName>snappy</displayName><value>snappy</value><description></description></allowableValue><allowableValue><displayName>snappy-hadoop</displayName><value>snappy-hadoop</value><description></description></allowableValue><allowableValue><displayName>snappy framed</displayName><value>snappy framed</value><description></description></allowableValue><allowableValue><displayName>lz4-framed</displayName><value>lz4-framed</value><description></description></allowableValue><allowableValue><displayName>zstd</displayName><value>zstd</value><description></description></allowableValue><allowableValue><displayName>brotli</displayName><value>brotli</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Compression Level</name><displayName>Compression Level</displayName><description>The compression level to use; this is valid only when using gzip, deflate or xz-lzma2 compression. A lower value results in faster processing but less compression; a value of 0 indicates no (that is, simple archiving) for gzip or minimal for xz-lzma2 compression. Higher levels can mean much larger memory usage such as the case with levels 7-9 for xz-lzma/2 so be careful relative to heap size.</description><defaultValue>1</defaultValue><allowableValues><allowableValue><displayName>0</displayName><value>0</value><description></description></allowableValue><allowableValue><displayName>1</displayName><value>1</value><description></description></allowableValue><allowableValue><displayName>2</displayName><value>2</value><description></description></allowableValue><allowableValue><displayName>3</displayName><value>3</value><description></description></allowableValue><allowableValue><displayName>4</displayName><value>4</value><description></description></allowableValue><allowableValue><displayName>5</displayName><value>5</value><description></description></allowableValue><allowableValue><displayName>6</displayName><value>6</value><description></description></allowableValue><allowableValue><displayName>7</displayName><value>7</value><description></description></allowableValue><allowableValue><displayName>8</displayName><value>8</value><description></description></allowableValue><allowableValue><displayName>9</displayName><value>9</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Compression Format</propertyName><propertyDisplayName>Compression Format</propertyDisplayName><dependentValues><dependentValue>brotli</dependentValue><dependentValue>deflate</dependentValue><dependentValue>gzip</dependentValue><dependentValue>use mime.type attribute</dependentValue><dependentValue>xz-lzma2</dependentValue><dependentValue>zstd</dependentValue></dependentValues></dependency><dependency><propertyName>Mode</propertyName><propertyDisplayName>Mode</propertyDisplayName><dependentValues><dependentValue>compress</dependentValue></dependentValues></dependency></dependencies></property><property><name>Update Filename</name><displayName>Update Filename</displayName><description>If true, will remove the filename extension when decompressing data (only if the extension indicates the appropriate compression format) and add the appropriate extension when compressing data</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>FlowFiles will be transferred to the failure relationship if they fail to compress/decompress</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>FlowFiles will be transferred to the success relationship after successfully being compressed or decompressed</description><autoTerminated>false</autoTerminated></relationship></relationships><readsAttributes><readsAttribute><name>mime.type</name><description>If the Compression Format is set to use mime.type attribute, this attribute is used to determine the compression type. Otherwise, this attribute is ignored.</description></readsAttribute></readsAttributes><writesAttributes><writesAttribute><name>mime.type</name><description>If the Mode property is set to compress, the appropriate MIME Type is set. If the Mode property is set to decompress and the file is successfully decompressed, this attribute is removed, as the MIME Type is no longer known.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><systemResourceConsiderations><systemResourceConsideration><resource>CPU</resource><description>An instance of this component can cause high usage of this system resource.  Multiple instances or high concurrency settings may result a degradation of performance.</description></systemResourceConsideration><systemResourceConsideration><resource>MEMORY</resource><description>An instance of this component can cause high usage of this system resource.  Multiple instances or high concurrency settings may result a degradation of performance.</description></systemResourceConsideration></systemResourceConsiderations><useCases><useCase><description>Compress the contents of a FlowFile</description><notes></notes><keywords></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>"Mode" = "compress"
"Compression Format" should be set to whichever compression algorithm should be used.</configuration></useCase><useCase><description>Decompress the contents of a FlowFile</description><notes></notes><keywords></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>"Mode" = "decompress"
"Compression Format" should be set to whichever compression algorithm was used to compress the data previously.</configuration></useCase></useCases><multiProcessorUseCases><multiProcessorUseCase><description>Check whether or not a FlowFile is compressed and if so, decompress it.</description><notes>If IdentifyMimeType determines that the content is not compressed, CompressContent will pass the FlowFile along to the 'success' relationship without attempting to decompress it.</notes><keywords><keyword>auto</keyword><keyword>detect</keyword><keyword>mime type</keyword><keyword>compress</keyword><keyword>decompress</keyword><keyword>gzip</keyword><keyword>bzip2</keyword></keywords><processorConfigurations><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.IdentifyMimeType</processorClassName><configuration>Default property values are sufficient.
Connect the 'success' relationship to CompressContent.
</configuration></processorConfiguration><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.CompressContent</processorClassName><configuration>"Mode" = "decompress"
"Compression Format" = "use mime.type attribute"
</configuration></processorConfiguration></processorConfigurations></multiProcessorUseCase></multiProcessorUseCases></extension><extension><name>org.apache.nifi.processors.standard.ControlRate</name><type>PROCESSOR</type><description>Controls the rate at which data is transferred to follow-on processors. If you configure a very small Time Duration, then the accuracy of the throttle gets worse. You can improve this accuracy by decreasing the Yield Duration, at the expense of more Tasks given to the processor.</description><tags><tag>rate control</tag><tag>throttle</tag><tag>rate</tag><tag>throughput</tag></tags><properties><property><name>Rate Control Criteria</name><displayName>Rate Control Criteria</displayName><description>Indicates the criteria that is used to control the throughput rate. Changing this value resets the rate counters.</description><defaultValue>data rate</defaultValue><allowableValues><allowableValue><displayName>data rate</displayName><value>data rate</value><description>Rate is controlled by counting bytes transferred per time duration.</description></allowableValue><allowableValue><displayName>flowfile count</displayName><value>flowfile count</value><description>Rate is controlled by counting FlowFiles transferred per time duration</description></allowableValue><allowableValue><displayName>attribute value</displayName><value>attribute value</value><description>Rate is controlled by accumulating the value of a specified attribute that is transferred per time duration</description></allowableValue><allowableValue><displayName>data rate or flowfile count</displayName><value>data rate or flowfile count</value><description>Rate is controlled by counting bytes and FlowFiles transferred per time duration; if either threshold is met, throttling is enforced</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Time Duration</name><displayName>Time Duration</displayName><description>The amount of time to which the Maximum Rate pertains. Changing this value resets the rate counters.</description><defaultValue>1 min</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum Rate</name><displayName>Maximum Rate</displayName><description>The maximum rate at which data should pass through this processor. The format of this property is expected to be a positive integer, or a Data Size (such as '1 MB') if Rate Control Criteria is set to 'data rate'.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Rate Control Criteria</propertyName><propertyDisplayName>Rate Control Criteria</propertyDisplayName><dependentValues><dependentValue>attribute value</dependentValue><dependentValue>data rate</dependentValue><dependentValue>flowfile count</dependentValue></dependentValues></dependency></dependencies></property><property><name>Maximum Data Rate</name><displayName>Maximum Data Rate</displayName><description>The maximum rate at which data should pass through this processor. The format of this property is expected to be a Data Size (such as '1 MB') representing bytes per Time Duration.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Rate Control Criteria</propertyName><propertyDisplayName>Rate Control Criteria</propertyDisplayName><dependentValues><dependentValue>data rate or flowfile count</dependentValue></dependentValues></dependency></dependencies></property><property><name>Maximum FlowFile Rate</name><displayName>Maximum FlowFile Rate</displayName><description>The maximum rate at which FlowFiles should pass through this processor. The format of this property is expected to be a positive integer representing FlowFiles count per Time Duration</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Rate Control Criteria</propertyName><propertyDisplayName>Rate Control Criteria</propertyDisplayName><dependentValues><dependentValue>data rate or flowfile count</dependentValue></dependentValues></dependency></dependencies></property><property><name>Rate Exceeded Strategy</name><displayName>Rate Exceeded Strategy</displayName><description>Specifies how to handle an incoming FlowFile when the maximum data rate has been exceeded.</description><defaultValue>Hold FlowFile</defaultValue><allowableValues><allowableValue><displayName>Hold FlowFile</displayName><value>Hold FlowFile</value><description>The FlowFile will be held in its input queue until the rate of data has fallen below the configured maximum and will then be allowed through.</description></allowableValue><allowableValue><displayName>Route to 'rate exceeded'</displayName><value>Route to 'rate exceeded'</value><description>The FlowFile will be routed to the 'rate exceeded' Relationship.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Rate Controlled Attribute</name><displayName>Rate Controlled Attribute</displayName><description>The name of an attribute whose values build toward the rate limit if Rate Control Criteria is set to 'attribute value'. The value of the attribute referenced by this property must be a positive long, or the FlowFile will be routed to failure. This value is ignored if Rate Control Criteria is not set to 'attribute value'. Changing this value resets the rate counters.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Rate Control Criteria</propertyName><propertyDisplayName>Rate Control Criteria</propertyDisplayName><dependentValues><dependentValue>attribute value</dependentValue></dependentValues></dependency></dependencies></property><property><name>Grouping Attribute</name><displayName>Grouping Attribute</displayName><description>By default, a single "throttle" is used for all FlowFiles. If this value is specified, a separate throttle is used for each value specified by the attribute with this name. Changing this value resets the rate counters.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>FlowFiles will be routed to this relationship if they are missing a necessary Rate Controlled Attribute or the attribute is not in the expected format</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>FlowFiles are transferred to this relationship under normal conditions</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><triggerSerially>true</triggerSerially><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><useCases><useCase><description>Limit the rate at which data is sent to a downstream system with little to no bursts</description><notes></notes><keywords><keyword>throttle</keyword><keyword>limit</keyword><keyword>slow down</keyword><keyword>data rate</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>Set the "Rate Control Criteria" to `data rate`.
Set the "Time Duration" property to `1 sec`.
Configure the "Maximum Rate" property to specify how much data should be allowed through each second.

For example, to allow through 8 MB per second, set "Maximum Rate" to `8 MB`.
</configuration></useCase><useCase><description>Limit the rate at which FlowFiles are sent to a downstream system with little to no bursts</description><notes></notes><keywords><keyword>throttle</keyword><keyword>limit</keyword><keyword>slow down</keyword><keyword>flowfile rate</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>Set the "Rate Control Criteria" to `flowfile count`.
Set the "Time Duration" property to `1 sec`.
Configure the "Maximum Rate" property to specify how many FlowFiles should be allowed through each second.

For example, to allow through 100 FlowFiles per second, set "Maximum Rate" to `100`.
</configuration></useCase><useCase><description>Reject requests that exceed a specific rate with little to no bursts</description><notes></notes><keywords><keyword>throttle</keyword><keyword>limit</keyword><keyword>slow down</keyword><keyword>request rate</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>Set the "Rate Control Criteria" to `flowfile count`.
Set the "Time Duration" property to `1 sec`.
Set the "Rate Exceeded Strategy" property to `Route to 'rate exceeded'`.
Configure the "Maximum Rate" property to specify how many requests should be allowed through each second.

For example, to allow through 100 requests per second, set "Maximum Rate" to `100`.
If more than 100 requests come in during any one second, the additional requests will be routed to `rate exceeded` instead of `success`.
</configuration></useCase><useCase><description>Reject requests that exceed a specific rate, allowing for bursts</description><notes></notes><keywords><keyword>throttle</keyword><keyword>limit</keyword><keyword>slow down</keyword><keyword>request rate</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>Set the "Rate Control Criteria" to `flowfile count`.
Set the "Time Duration" property to `1 min`.
Set the "Rate Exceeded Strategy" property to `Route to 'rate exceeded'`.
Configure the "Maximum Rate" property to specify how many requests should be allowed through each minute.

For example, to allow through 100 requests per second, set "Maximum Rate" to `6000`.
This will allow through 6,000 FlowFiles per minute, which averages to 100 FlowFiles per second. However, those 6,000 FlowFiles may come all within the first couple of
seconds, or they may come in over a period of 60 seconds. As a result, this gives us an average rate of 100 FlowFiles per second but allows for bursts of data.
If more than 6,000 requests come in during any one minute, the additional requests will be routed to `rate exceeded` instead of `success`.
</configuration></useCase></useCases></extension><extension><name>org.apache.nifi.processors.standard.ConvertCharacterSet</name><type>PROCESSOR</type><description>Converts a FlowFile's content from one character set to another</description><tags><tag>text</tag><tag>convert</tag><tag>characterset</tag><tag>character set</tag></tags><properties><property><name>Input Character Set</name><displayName>Input Character Set</displayName><description>The name of the CharacterSet to expect for Input</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Output Character Set</name><displayName>Output Character Set</displayName><description>The name of the CharacterSet to convert to</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>success</name><description></description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.ConvertRecord</name><type>PROCESSOR</type><description>Converts records from one data format to another using configured Record Reader and Record Write Controller Services. The Reader and Writer must be configured with "matching" schemas. By this, we mean the schemas must have the same field names. The types of the fields do not have to be the same if a field value can be coerced from one type to another. For instance, if the input schema has a field named "balance" of type double, the output schema can have a field named "balance" with a type of string, double, or float. If any field is present in the input that is not present in the output, the field will be left out of the output. If any field is specified in the output schema but is not present in the input data/schema, then the field will not be present in the output or will have a null value, depending on the writer.</description><tags><tag>convert</tag><tag>record</tag><tag>generic</tag><tag>schema</tag><tag>json</tag><tag>csv</tag><tag>avro</tag><tag>log</tag><tag>logs</tag><tag>freeform</tag><tag>text</tag></tags><properties><property><name>Record Reader</name><displayName>Record Reader</displayName><description>Specifies the Controller Service to use for reading incoming data</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Record Writer</name><displayName>Record Writer</displayName><description>Specifies the Controller Service to use for writing out the records</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Include Zero Record FlowFiles</name><displayName>Include Zero Record FlowFiles</displayName><description>When converting an incoming FlowFile, if the conversion results in no data, this property specifies whether or not a FlowFile will be sent to the corresponding relationship</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>If a FlowFile cannot be transformed from the configured input format to the configured output format, the unchanged FlowFile will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>FlowFiles that are successfully transformed will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>mime.type</name><description>Sets the mime.type attribute to the MIME Type specified by the Record Writer</description></writesAttribute><writesAttribute><name>record.count</name><description>The number of records in the FlowFile</description></writesAttribute><writesAttribute><name>record.error.message</name><description>This attribute provides on failure the error message encountered by the Reader or Writer.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><useCases><useCase><description>Convert data from one record-oriented format to another</description><notes></notes><keywords></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>The Record Reader should be configured according to the incoming data format.
The Record Writer should be configured according to the desired output format.</configuration></useCase></useCases></extension><extension><name>org.apache.nifi.processors.standard.CountText</name><type>PROCESSOR</type><description>Counts various metrics on incoming text. The requested results will be recorded as attributes. The resulting flowfile will not have its content modified.</description><tags><tag>count</tag><tag>text</tag><tag>line</tag><tag>word</tag><tag>character</tag></tags><properties><property><name>text-line-count</name><displayName>Count Lines</displayName><description>If enabled, will count the number of lines present in the incoming text.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>text-line-nonempty-count</name><displayName>Count Non-Empty Lines</displayName><description>If enabled, will count the number of lines that contain a non-whitespace character present in the incoming text.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>text-word-count</name><displayName>Count Words</displayName><description>If enabled, will count the number of words (alphanumeric character groups bounded by whitespace) present in the incoming text. Common logical delimiters [_-.] do not bound a word unless 'Split Words on Symbols' is true.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>text-character-count</name><displayName>Count Characters</displayName><description>If enabled, will count the number of characters (including whitespace and symbols, but not including newlines and carriage returns) present in the incoming text.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>split-words-on-symbols</name><displayName>Split Words on Symbols</displayName><description>If enabled, the word count will identify strings separated by common logical delimiters [ _ - . ] as independent words (ex. split-words-on-symbols = 4 words).</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>character-encoding</name><displayName>Character Encoding</displayName><description>Specifies a character encoding to use.</description><defaultValue>UTF-8</defaultValue><allowableValues><allowableValue><displayName>ISO-8859-1</displayName><value>ISO-8859-1</value><description></description></allowableValue><allowableValue><displayName>UTF-8</displayName><value>UTF-8</value><description></description></allowableValue><allowableValue><displayName>UTF-16</displayName><value>UTF-16</value><description></description></allowableValue><allowableValue><displayName>UTF-16LE</displayName><value>UTF-16LE</value><description></description></allowableValue><allowableValue><displayName>UTF-16BE</displayName><value>UTF-16BE</value><description></description></allowableValue><allowableValue><displayName>US-ASCII</displayName><value>US-ASCII</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>ajust-immediately</name><displayName>Call Immediate Adjustment</displayName><description>If true, the counter will be updated immediately, without regard to whether the ProcessSession is commit or rolled back;otherwise, the counter will be incremented only if and when the ProcessSession is committed.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>If the flowfile text cannot be counted for some reason, the original file will be routed to this destination and nothing will be routed elsewhere</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>The flowfile contains the original content with one or more attributes added containing the respective counts</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>text.line.count</name><description>The number of lines of text present in the FlowFile content</description></writesAttribute><writesAttribute><name>text.line.nonempty.count</name><description>The number of lines of text (with at least one non-whitespace character) present in the original FlowFile</description></writesAttribute><writesAttribute><name>text.word.count</name><description>The number of words present in the original FlowFile</description></writesAttribute><writesAttribute><name>text.character.count</name><description>The number of characters (given the specified character encoding) present in the original FlowFile</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.SplitText</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.CryptographicHashContent</name><type>PROCESSOR</type><description>Calculates a cryptographic hash value for the flowfile content using the given algorithm and writes it to an output attribute. Please refer to https://csrc.nist.gov/Projects/Hash-Functions/NIST-Policy-on-Hash-Functions for help to decide which algorithm to use.</description><tags><tag>content</tag><tag>hash</tag><tag>sha</tag><tag>blake2</tag><tag>md5</tag><tag>cryptography</tag></tags><properties><property><name>fail_when_empty</name><displayName>Fail if the content is empty</displayName><description>Route to failure if the content is empty. While hashing an empty value is valid, some flows may want to detect empty input.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>hash_algorithm</name><displayName>Hash Algorithm</displayName><description>The hash algorithm to use. Note that not all of the algorithms available are recommended for use (some are provided for legacy compatibility). There are many things to consider when picking an algorithm; it is recommended to use the most secure algorithm possible.</description><defaultValue>SHA-256</defaultValue><allowableValues><allowableValue><displayName>MD2</displayName><value>MD2</value><description>MD2 (16 byte output) [WARNING -- Cryptographically broken] Cryptographically broken due to collisions</description></allowableValue><allowableValue><displayName>MD5</displayName><value>MD5</value><description>MD5 (16 byte output) [WARNING -- Cryptographically broken] Cryptographically broken due to collisions</description></allowableValue><allowableValue><displayName>SHA-1</displayName><value>SHA-1</value><description>SHA-1 (20 byte output) [WARNING -- Cryptographically broken] Cryptographically broken due to collisions</description></allowableValue><allowableValue><displayName>SHA-224</displayName><value>SHA-224</value><description>SHA-224 (28 byte output) SHA-2 family</description></allowableValue><allowableValue><displayName>SHA-256</displayName><value>SHA-256</value><description>SHA-256 (32 byte output) SHA-2 family</description></allowableValue><allowableValue><displayName>SHA-384</displayName><value>SHA-384</value><description>SHA-384 (48 byte output) SHA-2 family</description></allowableValue><allowableValue><displayName>SHA-512</displayName><value>SHA-512</value><description>SHA-512 (64 byte output) SHA-2 family</description></allowableValue><allowableValue><displayName>SHA-512/224</displayName><value>SHA-512/224</value><description>SHA-512/224 (28 byte output) SHA-2 using SHA-512 with truncated output</description></allowableValue><allowableValue><displayName>SHA-512/256</displayName><value>SHA-512/256</value><description>SHA-512/256 (32 byte output) SHA-2 using SHA-512 with truncated output</description></allowableValue><allowableValue><displayName>SHA3-224</displayName><value>SHA3-224</value><description>SHA3-224 (28 byte output) Keccak-based SHA3 family</description></allowableValue><allowableValue><displayName>SHA3-256</displayName><value>SHA3-256</value><description>SHA3-256 (32 byte output) Keccak-based SHA3 family</description></allowableValue><allowableValue><displayName>SHA3-384</displayName><value>SHA3-384</value><description>SHA3-384 (48 byte output) Keccak-based SHA3 family</description></allowableValue><allowableValue><displayName>SHA3-512</displayName><value>SHA3-512</value><description>SHA3-512 (64 byte output) Keccak-based SHA3 family</description></allowableValue><allowableValue><displayName>BLAKE2-160</displayName><value>BLAKE2-160</value><description>BLAKE2-160 (20 byte output) Also known as Blake2b</description></allowableValue><allowableValue><displayName>BLAKE2-256</displayName><value>BLAKE2-256</value><description>BLAKE2-256 (32 byte output) Also known as Blake2b</description></allowableValue><allowableValue><displayName>BLAKE2-384</displayName><value>BLAKE2-384</value><description>BLAKE2-384 (48 byte output) Also known as Blake2b</description></allowableValue><allowableValue><displayName>BLAKE2-512</displayName><value>BLAKE2-512</value><description>BLAKE2-512 (64 byte output) Also known as Blake2b</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>Used for flowfiles that have no content if the 'fail on empty' setting is enabled</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>Used for flowfiles that have a hash value added</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>content_&lt;algorithm&gt;</name><description>This processor adds an attribute whose value is the result of hashing the flowfile content. The name of this attribute is specified by the value of the algorithm, e.g. 'content_SHA-256'.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.DebugFlow</name><type>PROCESSOR</type><description>The DebugFlow processor aids testing and debugging the FlowFile framework by allowing various responses to be explicitly triggered in response to the receipt of a FlowFile or a timer event without a FlowFile if using timer or cron based scheduling.  It can force responses needed to exercise or test various failure modes that can occur when a processor runs.</description><tags><tag>test</tag><tag>debug</tag><tag>processor</tag><tag>utility</tag><tag>flow</tag><tag>FlowFile</tag></tags><properties><property><name>FlowFile Success Iterations</name><displayName>FlowFile Success Iterations</displayName><description>Number of FlowFiles to forward to success relationship.</description><defaultValue>1</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>FlowFile Failure Iterations</name><displayName>FlowFile Failure Iterations</displayName><description>Number of FlowFiles to forward to failure relationship.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>FlowFile Rollback Iterations</name><displayName>FlowFile Rollback Iterations</displayName><description>Number of FlowFiles to roll back (without penalty).</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>FlowFile Rollback Yield Iterations</name><displayName>FlowFile Rollback Yield Iterations</displayName><description>Number of FlowFiles to roll back and yield.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>FlowFile Rollback Penalty Iterations</name><displayName>FlowFile Rollback Penalty Iterations</displayName><description>Number of FlowFiles to roll back with penalty.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>FlowFile Exception Iterations</name><displayName>FlowFile Exception Iterations</displayName><description>Number of FlowFiles to throw exception.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>FlowFile Exception Class</name><displayName>FlowFile Exception Class</displayName><description>Exception class to be thrown (must extend java.lang.RuntimeException).</description><defaultValue>java.lang.RuntimeException</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>No FlowFile Skip Iterations</name><displayName>No FlowFile Skip Iterations</displayName><description>Number of times to skip onTrigger if no FlowFile.</description><defaultValue>1</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>No FlowFile Exception Iterations</name><displayName>No FlowFile Exception Iterations</displayName><description>Number of times to throw NPE exception if no FlowFile.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>No FlowFile Yield Iterations</name><displayName>No FlowFile Yield Iterations</displayName><description>Number of times to yield if no FlowFile.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>No FlowFile Exception Class</name><displayName>No FlowFile Exception Class</displayName><description>Exception class to be thrown if no FlowFile (must extend java.lang.RuntimeException).</description><defaultValue>java.lang.RuntimeException</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Write Iterations</name><displayName>Write Iterations</displayName><description>Number of times to write to the FlowFile</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Content Size</name><displayName>Content Size</displayName><description>The number of bytes to write each time that the FlowFile is written to</description><defaultValue>1 KB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>@OnScheduled Pause Time</name><displayName>@OnScheduled Pause Time</displayName><description>Specifies how long the processor should sleep in the @OnScheduled method, so that the processor can be forced to take a long time to start up</description><defaultValue>0 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Fail When @OnScheduled called</name><displayName>Fail When @OnScheduled called</displayName><description>Specifies whether or not the Processor should throw an Exception when the methods annotated with @OnScheduled are called</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>@OnUnscheduled Pause Time</name><displayName>@OnUnscheduled Pause Time</displayName><description>Specifies how long the processor should sleep in the @OnUnscheduled method, so that the processor can be forced to take a long time to respond when user clicks stop</description><defaultValue>0 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Fail When @OnUnscheduled called</name><displayName>Fail When @OnUnscheduled called</displayName><description>Specifies whether or not the Processor should throw an Exception when the methods annotated with @OnUnscheduled are called</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>@OnStopped Pause Time</name><displayName>@OnStopped Pause Time</displayName><description>Specifies how long the processor should sleep in the @OnStopped method, so that the processor can be forced to take a long time to shutdown</description><defaultValue>0 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Fail When @OnStopped called</name><displayName>Fail When @OnStopped called</displayName><description>Specifies whether or not the Processor should throw an Exception when the methods annotated with @OnStopped are called</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>OnTrigger Pause Time</name><displayName>OnTrigger Pause Time</displayName><description>Specifies how long the processor should sleep in the onTrigger() method, so that the processor can be forced to take a long time to perform its task</description><defaultValue>0 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>CustomValidate Pause Time</name><displayName>CustomValidate Pause Time</displayName><description>Specifies how long the processor should sleep in the customValidate() method</description><defaultValue>0 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Ignore Interrupts When Paused</name><displayName>Ignore Interrupts When Paused</displayName><description>If the Processor's thread(s) are sleeping (due to one of the "Pause Time" properties above), and the thread is interrupted, this indicates whether the Processor should ignore the interrupt and continue sleeping or if it should allow itself to be interrupted.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>FlowFiles that failed to process.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>FlowFiles processed successfully.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes></extension><extension><name>org.apache.nifi.processors.standard.DeduplicateRecord</name><type>PROCESSOR</type><description>This processor de-duplicates individual records within a record set. It can operate on a per-file basis using an in-memory hashset or bloom filter. When configured with a distributed map cache, it de-duplicates records across multiple files.</description><tags><tag>text</tag><tag>record</tag><tag>update</tag><tag>change</tag><tag>replace</tag><tag>modify</tag><tag>distinct</tag><tag>unique</tag><tag>filter</tag><tag>hash</tag><tag>dupe</tag><tag>duplicate</tag><tag>dedupe</tag></tags><properties><property><name>deduplication-strategy</name><displayName>Deduplication Strategy</displayName><description>The strategy to use for detecting and routing duplicate records. The option for detecting duplicates across a single FlowFile operates in-memory, whereas detection spanning multiple FlowFiles utilises a distributed map cache.</description><defaultValue>single</defaultValue><allowableValues><allowableValue><displayName>Single File</displayName><value>single</value><description></description></allowableValue><allowableValue><displayName>Multiple Files</displayName><value>multiple</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>distributed-map-cache</name><displayName>Distributed Map Cache client</displayName><description>This property is required when the deduplication strategy is set to 'multiple files.' The map cache will for each record, atomically check whether the cache key exists and if not, set it.</description><controllerServiceDefinition><className>org.apache.nifi.distributed.cache.client.DistributedMapCacheClient</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>deduplication-strategy</propertyName><propertyDisplayName>Deduplication Strategy</propertyDisplayName><dependentValues><dependentValue>multiple</dependentValue></dependentValues></dependency></dependencies></property><property><name>cache-identifier</name><displayName>Cache Identifier</displayName><description>An optional expression language field that overrides the record's computed cache key. This field has an additional attribute available: ${record.hash.value}, which contains the cache key derived from dynamic properties (if set) or record fields.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>deduplication-strategy</propertyName><propertyDisplayName>Deduplication Strategy</propertyDisplayName><dependentValues><dependentValue>multiple</dependentValue></dependentValues></dependency></dependencies></property><property><name>put-cache-identifier</name><displayName>Cache the Entry Identifier</displayName><description>For each record, check whether the cache identifier exists in the distributed map cache. If it doesn't exist and this property is true, put the identifier to the cache.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>distributed-map-cache</propertyName><propertyDisplayName>Distributed Map Cache client</propertyDisplayName></dependency></dependencies></property><property><name>record-reader</name><displayName>Record Reader</displayName><description>Specifies the Controller Service to use for reading incoming data</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>record-writer</name><displayName>Record Writer</displayName><description>Specifies the Controller Service to use for writing out the records</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>include-zero-record-flowfiles</name><displayName>Include Zero Record FlowFiles</displayName><description>If a FlowFile sent to either the duplicate or non-duplicate relationships contains no records, a value of `false` in this property causes the FlowFile to be dropped. Otherwise, the empty FlowFile is emitted.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>record-hashing-algorithm</name><displayName>Record Hashing Algorithm</displayName><description>The algorithm used to hash the cache key.</description><defaultValue>SHA-256</defaultValue><allowableValues><allowableValue><displayName>None</displayName><value>none</value><description>Do not use a hashing algorithm. The value of resolved RecordPaths will be combined with a delimiter (~) to form the unique cache key. This may use significantly more storage depending on the size and shape or your data.</description></allowableValue><allowableValue><displayName>SHA-256</displayName><value>SHA-256</value><description>SHA-256 cryptographic hashing algorithm.</description></allowableValue><allowableValue><displayName>SHA-512</displayName><value>SHA-512</value><description>SHA-512 cryptographic hashing algorithm.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>filter-type</name><displayName>Filter Type</displayName><description>The filter used to determine whether a record has been seen before based on the matching RecordPath criteria. If hash set is selected, a Java HashSet object will be used to deduplicate all encountered records. If the bloom filter option is selected, a bloom filter will be used. The bloom filter option is less memory intensive, but has a chance of having false positives.</description><defaultValue>hash-set</defaultValue><allowableValues><allowableValue><displayName>HashSet</displayName><value>hash-set</value><description>Exactly matches records seen before with 100% accuracy at the expense of more storage usage. Stores the filter data in a single cache entry in the distributed cache, and is loaded entirely into memory during duplicate detection. This filter is preferred for small to medium data sets and offers high performance, being loaded into memory when this processor is running.</description></allowableValue><allowableValue><displayName>BloomFilter</displayName><value>bloom-filter</value><description>Space-efficient data structure ideal for large data sets using probability to determine if a record was seen previously. False positive matches are possible, but false negatives are not – in other words, a query returns either "possibly in the set" or "definitely not in the set". You should use this option if the FlowFile content is large and you can tolerate some duplication in the data. Uses constant storage space regardless of the record set size.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>deduplication-strategy</propertyName><propertyDisplayName>Deduplication Strategy</propertyDisplayName><dependentValues><dependentValue>single</dependentValue></dependentValues></dependency></dependencies></property><property><name>filter-capacity-hint</name><displayName>Filter Capacity Hint</displayName><description>An estimation of the total number of unique records to be processed. The more accurate this number is will lead to fewer false negatives on a BloomFilter.</description><defaultValue>25000</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>filter-type</propertyName><propertyDisplayName>Filter Type</propertyDisplayName><dependentValues><dependentValue>bloom-filter</dependentValue></dependentValues></dependency></dependencies></property><property><name>bloom-filter-certainty</name><displayName>Bloom Filter Certainty</displayName><description>The desired false positive probability when using the BloomFilter type. Using a value of .05 for example, guarantees a five-percent probability that the result is a false positive. The closer to 1 this value is set, the more precise the result at the expense of more storage space utilization.</description><defaultValue>0.10</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>Name of the property.</name><value>A valid RecordPath to the record field to be included in the cache key used for deduplication.</value><description>A record's cache key is generated by combining the name of each dynamic property with its evaluated record value (as specified by the corresponding RecordPath).</description><expressionLanguageScope>NONE</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>duplicate</name><description>Records detected as duplicates are routed to this relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>failure</name><description>If unable to communicate with the cache, the FlowFile will be penalized and routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>non-duplicate</name><description>Records not found in the cache are routed to this relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>original</name><description>The original input FlowFile is sent to this relationship unless a fatal error occurs.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>record.count</name><description>Number of records written to the destination FlowFile.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_REQUIRED</inputRequirement><systemResourceConsiderations><systemResourceConsideration><resource>MEMORY</resource><description>The HashSet filter type will grow memory space proportionate to the number of unique records processed. The BloomFilter type will use constant memory regardless of the number of records processed.</description></systemResourceConsideration><systemResourceConsideration><resource>CPU</resource><description>If a more advanced hash algorithm is chosen, the amount of time required to hash any particular record could increase substantially.</description></systemResourceConsideration></systemResourceConsiderations><seeAlso><see>org.apache.nifi.distributed.cache.client.DistributedMapCacheClientService</see><see>org.apache.nifi.distributed.cache.server.map.DistributedMapCacheServer</see><see>org.apache.nifi.processors.standard.DetectDuplicate</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.DeleteFile</name><type>PROCESSOR</type><description>Deletes a file from the filesystem.</description><tags><tag>file</tag><tag>remove</tag><tag>delete</tag><tag>local</tag><tag>files</tag><tag>filesystem</tag></tags><properties><property><name>Directory Path</name><displayName>Directory Path</displayName><description>The path to the directory the file to delete is located in.</description><defaultValue>${absolute.path}</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Filename</name><displayName>Filename</displayName><description>The name of the file to delete.</description><defaultValue>${filename}</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>All FlowFiles, for which an existing file could not be deleted, are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>not found</name><description>All FlowFiles, for which the file to delete did not exist, are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>All FlowFiles, for which an existing file has been deleted, are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><restricted><restrictions><restriction><requiredPermission>read filesystem</requiredPermission><explanation>Provides operator the ability to read from any file that NiFi has access to.</explanation></restriction><restriction><requiredPermission>write filesystem</requiredPermission><explanation>Provides operator the ability to delete any file that NiFi has access to.</explanation></restriction></restrictions></restricted><inputRequirement>INPUT_REQUIRED</inputRequirement><useCases><useCase><description>Delete source file only after its processing completed</description><notes></notes><keywords></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>Retrieve a file from the filesystem, e.g. using 'ListFile' and 'FetchFile'.
Process the file using any combination of processors.
Store the resulting file to a destination, e.g. using 'PutSFTP'.
Using 'DeleteFile', delete the file from the filesystem only after the result has been stored.
</configuration></useCase></useCases></extension><extension><name>org.apache.nifi.processors.standard.DeleteSFTP</name><type>PROCESSOR</type><description>Deletes a file residing on an SFTP server.</description><tags><tag>remote</tag><tag>remove</tag><tag>delete</tag><tag>sftp</tag></tags><properties><property><name>Directory Path</name><displayName>Directory Path</displayName><description>The path to the directory the file to delete is located in.</description><defaultValue>${path}</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Filename</name><displayName>Filename</displayName><description>The name of the file to delete.</description><defaultValue>${filename}</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Hostname</name><displayName>Hostname</displayName><description>The fully qualified hostname or IP address of the remote system</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Port</name><displayName>Port</displayName><description>The port that the remote system is listening on for file transfers</description><defaultValue>22</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Username</name><displayName>Username</displayName><description>Username</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Password</name><displayName>Password</displayName><description>Password for the user account</description><required>false</required><sensitive>true</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Private Key Path</name><displayName>Private Key Path</displayName><description>The fully qualified path to the Private Key file</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType></resourceTypes></resourceDefinition></property><property><name>Private Key Passphrase</name><displayName>Private Key Passphrase</displayName><description>Password for the private key</description><required>false</required><sensitive>true</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Strict Host Key Checking</name><displayName>Strict Host Key Checking</displayName><description>Indicates whether or not strict enforcement of hosts keys should be applied</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Host Key File</name><displayName>Host Key File</displayName><description>If supplied, the given file will be used as the Host Key; otherwise, if 'Strict Host Key Checking' property is applied (set to true) then uses the 'known_hosts' and 'known_hosts2' files from ~/.ssh directory else no host key file will be used</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType></resourceTypes></resourceDefinition></property><property><name>Batch Size</name><displayName>Batch Size</displayName><description>The maximum number of FlowFiles to send in a single connection</description><defaultValue>500</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Connection Timeout</name><displayName>Connection Timeout</displayName><description>Amount of time to wait before timing out while creating a connection</description><defaultValue>30 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Data Timeout</name><displayName>Data Timeout</displayName><description>When transferring a file between the local and remote system, this value specifies how long is allowed to elapse without any data being transferred between systems</description><defaultValue>30 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Send Keep Alive On Timeout</name><displayName>Send Keep Alive On Timeout</displayName><description>Send a Keep Alive message every 5 seconds up to 5 times for an overall timeout of 25 seconds.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Use Compression</name><displayName>Use Compression</displayName><description>Indicates whether or not ZLIB compression should be used when transferring files</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>proxy-configuration-service</name><displayName>Proxy Configuration Service</displayName><description>Specifies the Proxy Configuration Controller Service to proxy network requests. Supported proxies: HTTP + AuthN, SOCKS + AuthN</description><controllerServiceDefinition><className>org.apache.nifi.proxy.ProxyConfigurationService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Ciphers Allowed</name><displayName>Ciphers Allowed</displayName><description>A comma-separated list of Ciphers allowed for SFTP connections. Leave unset to allow all. Available options are: 3des-cbc, 3des-ctr, aes128-cbc, aes128-ctr, aes128-gcm@openssh.com, aes192-cbc, aes192-ctr, aes256-cbc, aes256-ctr, aes256-gcm@openssh.com, arcfour, arcfour128, arcfour256, blowfish-cbc, blowfish-ctr, cast128-cbc, cast128-ctr, chacha20-poly1305@openssh.com, idea-cbc, idea-ctr, serpent128-cbc, serpent128-ctr, serpent192-cbc, serpent192-ctr, serpent256-cbc, serpent256-ctr, twofish-cbc, twofish128-cbc, twofish128-ctr, twofish192-cbc, twofish192-ctr, twofish256-cbc, twofish256-ctr</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Key Algorithms Allowed</name><displayName>Key Algorithms Allowed</displayName><description>A comma-separated list of Key Algorithms allowed for SFTP connections. Leave unset to allow all. Available options are: ecdsa-sha2-nistp256, ecdsa-sha2-nistp256-cert-v01@openssh.com, ecdsa-sha2-nistp384, ecdsa-sha2-nistp384-cert-v01@openssh.com, ecdsa-sha2-nistp521, ecdsa-sha2-nistp521-cert-v01@openssh.com, rsa-sha2-256, rsa-sha2-512, ssh-dss, ssh-dss-cert-v01@openssh.com, ssh-ed25519, ssh-ed25519-cert-v01@openssh.com, ssh-rsa, ssh-rsa-cert-v01@openssh.com</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Key Exchange Algorithms Allowed</name><displayName>Key Exchange Algorithms Allowed</displayName><description>A comma-separated list of Key Exchange Algorithms allowed for SFTP connections. Leave unset to allow all. Available options are: curve25519-sha256, curve25519-sha256@libssh.org, diffie-hellman-group-exchange-sha1, diffie-hellman-group-exchange-sha256, diffie-hellman-group1-sha1, diffie-hellman-group14-sha1, diffie-hellman-group14-sha256, diffie-hellman-group14-sha256@ssh.com, diffie-hellman-group15-sha256, diffie-hellman-group15-sha256@ssh.com, diffie-hellman-group15-sha384@ssh.com, diffie-hellman-group15-sha512, diffie-hellman-group16-sha256, diffie-hellman-group16-sha384@ssh.com, diffie-hellman-group16-sha512, diffie-hellman-group16-sha512@ssh.com, diffie-hellman-group17-sha512, diffie-hellman-group18-sha512, diffie-hellman-group18-sha512@ssh.com, ecdh-sha2-nistp256, ecdh-sha2-nistp384, ecdh-sha2-nistp521, ext-info-c</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Message Authentication Codes Allowed</name><displayName>Message Authentication Codes Allowed</displayName><description>A comma-separated list of Message Authentication Codes allowed for SFTP connections. Leave unset to allow all. Available options are: hmac-md5, hmac-md5-96, hmac-md5-96-etm@openssh.com, hmac-md5-etm@openssh.com, hmac-ripemd160, hmac-ripemd160-96, hmac-ripemd160-etm@openssh.com, hmac-ripemd160@openssh.com, hmac-sha1, hmac-sha1-96, hmac-sha1-96@openssh.com, hmac-sha1-etm@openssh.com, hmac-sha2-256, hmac-sha2-256-etm@openssh.com, hmac-sha2-512, hmac-sha2-512-etm@openssh.com</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>All FlowFiles, for which an existing file could not be deleted, are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>not found</name><description>All FlowFiles, for which the file to delete did not exist, are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>All FlowFiles, for which an existing file has been deleted, are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_REQUIRED</inputRequirement><useCases><useCase><description>Delete source file only after its processing completed</description><notes></notes><keywords></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>Retrieve a file residing on an SFTP server, e.g. using 'ListSFTP' and 'FetchSFTP'.
Process the file using any combination of processors.
Store the resulting file to a destination, e.g. using 'PutFile'.
Using 'DeleteSFTP', delete the file residing on an SFTP server only after the result has been stored.
</configuration></useCase></useCases></extension><extension><name>org.apache.nifi.processors.standard.DetectDuplicate</name><type>PROCESSOR</type><description>Caches a value, computed from FlowFile attributes, for each incoming FlowFile and determines if the cached value has already been seen. If so, routes the FlowFile to 'duplicate' with an attribute named 'original.identifier' that specifies the original FlowFile's "description", which is specified in the &lt;FlowFile Description&gt; property. If the FlowFile is not determined to be a duplicate, the Processor routes the FlowFile to 'non-duplicate'</description><tags><tag>hash</tag><tag>dupe</tag><tag>duplicate</tag><tag>dedupe</tag></tags><properties><property><name>Cache Entry Identifier</name><displayName>Cache Entry Identifier</displayName><description>A FlowFile attribute, or the results of an Attribute Expression Language statement, which will be evaluated against a FlowFile in order to determine the value used to identify duplicates; it is this value that is cached</description><defaultValue>${hash.value}</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>FlowFile Description</name><displayName>FlowFile Description</displayName><description>When a FlowFile is added to the cache, this value is stored along with it so that if a duplicate is found, this description of the original FlowFile will be added to the duplicate's "original.flowfile.description" attribute</description><defaultValue></defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Age Off Duration</name><displayName>Age Off Duration</displayName><description>Time interval to age off cached FlowFiles</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Distributed Cache Service</name><displayName>Distributed Cache Service</displayName><description>The Controller Service that is used to cache unique identifiers, used to determine duplicates</description><controllerServiceDefinition><className>org.apache.nifi.distributed.cache.client.DistributedMapCacheClient</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Cache The Entry Identifier</name><displayName>Cache The Entry Identifier</displayName><description>When true this cause the processor to check for duplicates and cache the Entry Identifier. When false, the processor would only check for duplicates and not cache the Entry Identifier, requiring another processor to add identifiers to the distributed cache.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>duplicate</name><description>If a FlowFile has been detected to be a duplicate, it will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>failure</name><description>If unable to communicate with the cache, the FlowFile will be penalized and routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>non-duplicate</name><description>If a FlowFile's Cache Entry Identifier was not found in the cache, it will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>original.flowfile.description</name><description>All FlowFiles routed to the duplicate relationship will have an attribute added named original.flowfile.description. The value of this attribute is determined by the attributes of the original copy of the data and by the FlowFile Description property.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_REQUIRED</inputRequirement><seeAlso><see>org.apache.nifi.distributed.cache.client.DistributedMapCacheClientService</see><see>org.apache.nifi.distributed.cache.server.map.DistributedMapCacheServer</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.DistributeLoad</name><type>PROCESSOR</type><description>Distributes FlowFiles to downstream processors based on a Distribution Strategy. If using the Round Robin strategy, the default is to assign each destination a weighting of 1 (evenly distributed). However, optional properties can be added to the change this; adding a property with the name '5' and value '10' means that the relationship with name '5' will be receive 10 FlowFiles in each iteration instead of 1.</description><tags><tag>distribute</tag><tag>load balance</tag><tag>route</tag><tag>round robin</tag><tag>weighted</tag></tags><properties><property><name>Number of Relationships</name><displayName>Number of Relationships</displayName><description>Determines the number of Relationships to which the load should be distributed</description><defaultValue>1</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Distribution Strategy</name><displayName>Distribution Strategy</displayName><description>Determines how the load will be distributed. Relationship weight is in numeric order where '1' has the greatest weight.</description><defaultValue>round robin</defaultValue><allowableValues><allowableValue><displayName>round robin</displayName><value>round robin</value><description>Relationship selection is evenly distributed in a round robin fashion; all relationships must be available.</description></allowableValue><allowableValue><displayName>next available</displayName><value>next available</value><description>Relationship selection is distributed across all available relationships in order of their weight; at least one relationship must be available.</description></allowableValue><allowableValue><displayName>overflow</displayName><value>overflow</value><description>Relationship selection is the first available relationship without further distribution among all relationships; at least one relationship must be available.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>The relationship name (positive number)</name><value>The relationship Weight (positive number)</value><description>Adding a property with the name '5' and value '10' means that the relationship with name '5' will receive 10 FlowFiles in each iteration instead of 1.</description><expressionLanguageScope>NONE</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>1</name><description>Where to route flowfiles for this relationship index</description><autoTerminated>false</autoTerminated></relationship></relationships><dynamicRelationship><name>A number 1..&lt;Number Of Relationships&gt;</name><description>FlowFiles are sent to this relationship per the &lt;Distribution Strategy&gt;</description></dynamicRelationship><writesAttributes><writesAttribute><name>distribute.load.relationship</name><description>The name of the specific relationship the FlowFile has been routed through</description></writesAttribute></writesAttributes><triggerWhenAnyDestinationAvailable>true</triggerWhenAnyDestinationAvailable><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.DuplicateFlowFile</name><type>PROCESSOR</type><description>Intended for load testing, this processor will create the configured number of copies of each incoming FlowFile. The original FlowFile as well as all generated copies are sent to the 'success' relationship. In addition, each FlowFile gets an attribute 'copy.index' set to the copy number, where the original FlowFile gets a value of zero, and all copies receive incremented integer values.</description><tags><tag>test</tag><tag>load</tag><tag>duplicate</tag></tags><properties><property><name>Number of Copies</name><displayName>Number of Copies</displayName><description>Specifies how many copies of each incoming FlowFile will be made</description><defaultValue>100</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>success</name><description>The original FlowFile and all copies will be sent to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>copy.index</name><description>A zero-based incrementing integer value based on which copy the FlowFile is.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.EncodeContent</name><type>PROCESSOR</type><description>Encode or decode the contents of a FlowFile using Base64, Base32, or hex encoding schemes</description><tags><tag>encode</tag><tag>decode</tag><tag>base64</tag><tag>base32</tag><tag>hex</tag></tags><properties><property><name>Mode</name><displayName>Mode</displayName><description>Specifies whether the content should be encoded or decoded.</description><defaultValue>Encode</defaultValue><allowableValues><allowableValue><displayName>Encode</displayName><value>Encode</value><description>Transform original input to encoded representation</description></allowableValue><allowableValue><displayName>Decode</displayName><value>Decode</value><description>Transform encoded input to original representation</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Encoding</name><displayName>Encoding</displayName><description>Specifies the type of encoding used.</description><defaultValue>base64</defaultValue><allowableValues><allowableValue><displayName>Base64</displayName><value>base64</value><description>Encode or decode using Base64 set of characters</description></allowableValue><allowableValue><displayName>Base32</displayName><value>base32</value><description>Encode or decode using Base32 set of characters</description></allowableValue><allowableValue><displayName>Hexadecimal</displayName><value>hex</value><description>Encode or decode using hexadecimal set of characters</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Line Output Mode</name><displayName>Line Output Mode</displayName><description>Controls the line formatting for encoded content based on selected property values.</description><defaultValue>SINGLE_LINE</defaultValue><allowableValues><allowableValue><displayName>Single Line</displayName><value>SINGLE_LINE</value><description>The encoded content will be written as a single line.</description></allowableValue><allowableValue><displayName>Multiple Lines</displayName><value>MULTIPLE_LINES</value><description>The encoded content will be written as multiple lines.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Encoding</propertyName><propertyDisplayName>Encoding</propertyDisplayName><dependentValues><dependentValue>base32</dependentValue><dependentValue>base64</dependentValue></dependentValues></dependency><dependency><propertyName>Mode</propertyName><propertyDisplayName>Mode</propertyDisplayName><dependentValues><dependentValue>Encode</dependentValue></dependentValues></dependency></dependencies></property><property><name>Encoded Line Length</name><displayName>Encoded Line Length</displayName><description>Each line of encoded data will contain up to the configured number of characters, rounded down to the nearest multiple of 4.</description><defaultValue>76</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Encoding</propertyName><propertyDisplayName>Encoding</propertyDisplayName><dependentValues><dependentValue>base32</dependentValue><dependentValue>base64</dependentValue></dependentValues></dependency><dependency><propertyName>Line Output Mode</propertyName><propertyDisplayName>Line Output Mode</propertyDisplayName><dependentValues><dependentValue>MULTIPLE_LINES</dependentValue></dependentValues></dependency><dependency><propertyName>Mode</propertyName><propertyDisplayName>Mode</propertyDisplayName><dependentValues><dependentValue>Encode</dependentValue></dependentValues></dependency></dependencies></property></properties><relationships><relationship><name>failure</name><description>Any FlowFile that cannot be encoded or decoded will be routed to failure</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>Any FlowFile that is successfully encoded or decoded will be routed to success</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.EnforceOrder</name><type>PROCESSOR</type><description>Enforces expected ordering of FlowFiles that belong to the same data group within a single node.  Although PriorityAttributePrioritizer can be used on a connection to ensure that flow files going through that connection are in priority order, depending on error-handling, branching, and other flow designs, it is possible for FlowFiles to get out-of-order. EnforceOrder can be used to enforce original ordering for those FlowFiles. [IMPORTANT] In order to take effect of EnforceOrder, FirstInFirstOutPrioritizer should be used at EVERY downstream relationship UNTIL the order of FlowFiles physically get FIXED by operation such as MergeContent or being stored to the final destination.</description><tags><tag>sort</tag><tag>order</tag></tags><properties><property><name>group-id</name><displayName>Group Identifier</displayName><description>EnforceOrder is capable of multiple ordering groups. 'Group Identifier' is used to determine which group a FlowFile belongs to. This property will be evaluated with each incoming FlowFile. If evaluated result is empty, the FlowFile will be routed to failure.</description><defaultValue>${filename}</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>order-attribute</name><displayName>Order Attribute</displayName><description>A name of FlowFile attribute whose value will be used to enforce order of FlowFiles within a group. If a FlowFile does not have this attribute, or its value is not an integer, the FlowFile will be routed to failure.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>initial-order</name><displayName>Initial Order</displayName><description>When the first FlowFile of a group arrives, initial target order will be computed and stored in the managed state. After that, target order will start being tracked by EnforceOrder and stored in the state management store. If Expression Language is used but evaluated result was not an integer, then the FlowFile will be routed to failure, and initial order will be left unknown until consecutive FlowFiles provide a valid initial order.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>maximum-order</name><displayName>Maximum Order</displayName><description>If specified, any FlowFiles that have larger order will be routed to failure. This property is computed only once for a given group. After a maximum order is computed, it will be persisted in the state management store and used for other FlowFiles belonging to the same group. If Expression Language is used but evaluated result was not an integer, then the FlowFile will be routed to failure, and maximum order will be left unknown until consecutive FlowFiles provide a valid maximum order.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>batch-count</name><displayName>Batch Count</displayName><description>The maximum number of FlowFiles that EnforceOrder can process at an execution.</description><defaultValue>1000</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>wait-timeout</name><displayName>Wait Timeout</displayName><description>Indicates the duration after which waiting FlowFiles will be routed to the 'overtook' relationship.</description><defaultValue>10 min</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>inactive-timeout</name><displayName>Inactive Timeout</displayName><description>Indicates the duration after which state for an inactive group will be cleared from managed state. Group is determined as inactive if any new incoming FlowFile has not seen for a group for specified duration. Inactive Timeout must be longer than Wait Timeout. If a FlowFile arrives late after its group is already cleared, it will be treated as a brand new group, but will never match the order since expected preceding FlowFiles are already gone. The FlowFile will eventually timeout for waiting and routed to 'overtook'. To avoid this, group states should be kept long enough, however, shorter duration would be helpful for reusing the same group identifier again.</description><defaultValue>30 min</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>A FlowFiles which does not have required attributes, or fails to compute those will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>overtook</name><description>A FlowFile that waited for preceding FlowFiles longer than Wait Timeout and overtook those FlowFiles, will be routed to this relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>skipped</name><description>A FlowFile that has an order younger than current, which means arrived too late and skipped, will be routed to this relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>A FlowFile with a matching order number will be routed to this relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>wait</name><description>A FlowFile with non matching order will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>EnforceOrder.startedAt</name><description>All FlowFiles going through this processor will have this attribute. This value is used to determine wait timeout.</description></writesAttribute><writesAttribute><name>EnforceOrder.result</name><description>All FlowFiles going through this processor will have this attribute denoting which relationship it was routed to.</description></writesAttribute><writesAttribute><name>EnforceOrder.detail</name><description>FlowFiles routed to 'failure' or 'skipped' relationship will have this attribute describing details.</description></writesAttribute><writesAttribute><name>EnforceOrder.expectedOrder</name><description>FlowFiles routed to 'wait' or 'skipped' relationship will have this attribute denoting expected order when the FlowFile was processed.</description></writesAttribute></writesAttributes><triggerSerially>true</triggerSerially><stateful><description>EnforceOrder uses following states per ordering group: '&lt;groupId&gt;.target' is a order number which is being waited to arrive next. When a FlowFile with a matching order arrives, or a FlowFile overtakes the FlowFile being waited for because of wait timeout, target order will be updated to (FlowFile.order + 1). '&lt;groupId&gt;.max is the maximum order number for a group. '&lt;groupId&gt;.updatedAt' is a timestamp when the order of a group was updated last time. These managed states will be removed automatically once a group is determined as inactive, see 'Inactive Timeout' for detail.</description><scopes><scope>LOCAL</scope></scopes></stateful><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.EvaluateJsonPath</name><type>PROCESSOR</type><description>Evaluates one or more JsonPath expressions against the content of a FlowFile. The results of those expressions are assigned to FlowFile Attributes or are written to the content of the FlowFile itself, depending on configuration of the Processor. JsonPaths are entered by adding user-defined properties; the name of the property maps to the Attribute Name into which the result will be placed (if the Destination is flowfile-attribute; otherwise, the property name is ignored). The value of the property must be a valid JsonPath expression. A Return Type of 'auto-detect' will make a determination based off the configured destination. When 'Destination' is set to 'flowfile-attribute,' a return type of 'scalar' will be used. When 'Destination' is set to 'flowfile-content,' a return type of 'JSON' will be used.If the JsonPath evaluates to a JSON array or JSON object and the Return Type is set to 'scalar' the FlowFile will be unmodified and will be routed to failure. A Return Type of JSON can return scalar values if the provided JsonPath evaluates to the specified value and will be routed as a match.If Destination is 'flowfile-content' and the JsonPath does not evaluate to a defined path, the FlowFile will be routed to 'unmatched' without having its contents modified. If Destination is 'flowfile-attribute' and the expression matches nothing, attributes will be created with empty strings as the value unless 'Path Not Found Behaviour' is set to 'skip', and the FlowFile will always be routed to 'matched.'</description><tags><tag>JSON</tag><tag>evaluate</tag><tag>JsonPath</tag></tags><properties><property><name>Destination</name><displayName>Destination</displayName><description>Indicates whether the results of the JsonPath evaluation are written to the FlowFile content or a FlowFile attribute; if using attribute, must specify the Attribute Name property. If set to flowfile-content, only one JsonPath may be specified, and the property name is ignored.</description><defaultValue>flowfile-content</defaultValue><allowableValues><allowableValue><displayName>flowfile-content</displayName><value>flowfile-content</value><description></description></allowableValue><allowableValue><displayName>flowfile-attribute</displayName><value>flowfile-attribute</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Return Type</name><displayName>Return Type</displayName><description>Indicates the desired return type of the JSON Path expressions.  Selecting 'auto-detect' will set the return type to 'json' for a Destination of 'flowfile-content', and 'scalar' for a Destination of 'flowfile-attribute'.</description><defaultValue>auto-detect</defaultValue><allowableValues><allowableValue><displayName>auto-detect</displayName><value>auto-detect</value><description></description></allowableValue><allowableValue><displayName>json</displayName><value>json</value><description></description></allowableValue><allowableValue><displayName>scalar</displayName><value>scalar</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Path Not Found Behavior</name><displayName>Path Not Found Behavior</displayName><description>Indicates how to handle missing JSON path expressions when destination is set to 'flowfile-attribute'. Selecting 'warn' will generate a warning when a JSON path expression is not found. Selecting 'skip' will omit attributes for any unmatched JSON path expressions.</description><defaultValue>ignore</defaultValue><allowableValues><allowableValue><displayName>warn</displayName><value>warn</value><description></description></allowableValue><allowableValue><displayName>ignore</displayName><value>ignore</value><description></description></allowableValue><allowableValue><displayName>skip</displayName><value>skip</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Destination</propertyName><propertyDisplayName>Destination</propertyDisplayName><dependentValues><dependentValue>flowfile-attribute</dependentValue></dependentValues></dependency></dependencies></property><property><name>Null Value Representation</name><displayName>Null Value Representation</displayName><description>Indicates the desired representation of JSON Path expressions resulting in a null value.</description><defaultValue>empty string</defaultValue><allowableValues><allowableValue><displayName>the string 'null'</displayName><value>the string 'null'</value><description></description></allowableValue><allowableValue><displayName>empty string</displayName><value>empty string</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max String Length</name><displayName>Max String Length</displayName><description>The maximum allowed length of a string value when parsing the JSON document</description><defaultValue>20 MB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>A FlowFile attribute(if &lt;Destination&gt; is set to 'flowfile-attribute')</name><value>A JsonPath expression</value><description>If &lt;Destination&gt;='flowfile-attribute' then that FlowFile attribute will be set to any JSON objects that match the JsonPath.  If &lt;Destination&gt;='flowfile-content' then the FlowFile content will be updated to any JSON objects that match the JsonPath.</description><expressionLanguageScope>NONE</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>failure</name><description>FlowFiles are routed to this relationship when the JsonPath cannot be evaluated against the content of the FlowFile; for instance, if the FlowFile is not valid JSON</description><autoTerminated>false</autoTerminated></relationship><relationship><name>matched</name><description>FlowFiles are routed to this relationship when the JsonPath is successfully evaluated and the FlowFile is modified as a result</description><autoTerminated>false</autoTerminated></relationship><relationship><name>unmatched</name><description>FlowFiles are routed to this relationship when the JsonPath does not match the content of the FlowFile and the Destination is set to flowfile-content</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.EvaluateXPath</name><type>PROCESSOR</type><description>Evaluates one or more XPaths against the content of a FlowFile. The results of those XPaths are assigned to FlowFile Attributes or are written to the content of the FlowFile itself, depending on configuration of the Processor. XPaths are entered by adding user-defined properties; the name of the property maps to the Attribute Name into which the result will be placed (if the Destination is flowfile-attribute; otherwise, the property name is ignored). The value of the property must be a valid XPath expression. If the XPath evaluates to more than one node and the Return Type is set to 'nodeset' (either directly, or via 'auto-detect' with a Destination of 'flowfile-content'), the FlowFile will be unmodified and will be routed to failure. If the XPath does not evaluate to a Node, the FlowFile will be routed to 'unmatched' without having its contents modified. If Destination is flowfile-attribute and the expression matches nothing, attributes will be created with empty strings as the value, and the FlowFile will always be routed to 'matched'</description><tags><tag>XML</tag><tag>evaluate</tag><tag>XPath</tag></tags><properties><property><name>Destination</name><displayName>Destination</displayName><description>Indicates whether the results of the XPath evaluation are written to the FlowFile content or a FlowFile attribute; if using attribute, must specify the Attribute Name property. If set to flowfile-content, only one XPath may be specified, and the property name is ignored.</description><defaultValue>flowfile-content</defaultValue><allowableValues><allowableValue><displayName>flowfile-content</displayName><value>flowfile-content</value><description></description></allowableValue><allowableValue><displayName>flowfile-attribute</displayName><value>flowfile-attribute</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Return Type</name><displayName>Return Type</displayName><description>Indicates the desired return type of the Xpath expressions.  Selecting 'auto-detect' will set the return type to 'nodeset' for a Destination of 'flowfile-content', and 'string' for a Destination of 'flowfile-attribute'.</description><defaultValue>auto-detect</defaultValue><allowableValues><allowableValue><displayName>auto-detect</displayName><value>auto-detect</value><description></description></allowableValue><allowableValue><displayName>nodeset</displayName><value>nodeset</value><description></description></allowableValue><allowableValue><displayName>string</displayName><value>string</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Validate DTD</name><displayName>Allow DTD</displayName><description>Allow embedded Document Type Declaration in XML. This feature should be disabled to avoid XML entity expansion vulnerabilities.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>A FlowFile attribute(if &lt;Destination&gt; is set to 'flowfile-attribute'</name><value>An XPath expression</value><description>If &lt;Destination&gt;='flowfile-attribute' then the FlowFile attribute is set to the result of the XPath Expression.  If &lt;Destination&gt;='flowfile-content' then the FlowFile content is set to the result of the XPath Expression.</description><expressionLanguageScope>NONE</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>failure</name><description>FlowFiles are routed to this relationship when the XPath cannot be evaluated against the content of the FlowFile; for instance, if the FlowFile is not valid XML, or if the Return Type is 'nodeset' and the XPath evaluates to multiple nodes</description><autoTerminated>false</autoTerminated></relationship><relationship><name>matched</name><description>FlowFiles are routed to this relationship when the XPath is successfully evaluated and the FlowFile is modified as a result</description><autoTerminated>false</autoTerminated></relationship><relationship><name>unmatched</name><description>FlowFiles are routed to this relationship when the XPath does not match the content of the FlowFile and the Destination is set to flowfile-content</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>user-defined</name><description>This processor adds user-defined attributes if the &lt;Destination&gt; property is set to flowfile-attribute.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><systemResourceConsiderations><systemResourceConsideration><resource>MEMORY</resource><description>Processing requires reading the entire FlowFile into memory</description></systemResourceConsideration></systemResourceConsiderations></extension><extension><name>org.apache.nifi.processors.standard.EvaluateXQuery</name><type>PROCESSOR</type><description>Evaluates one or more XQueries against the content of a FlowFile.  The results of those XQueries are assigned to FlowFile Attributes or are written to the content of the FlowFile itself, depending on configuration of the Processor.  XQueries are entered by adding user-defined properties; the name of the property maps to the Attribute Name into which the result will be placed (if the Destination is 'flowfile-attribute'; otherwise, the property name is ignored).  The value of the property must be a valid XQuery.  If the XQuery returns more than one result, new attributes or FlowFiles (for Destinations of 'flowfile-attribute' or 'flowfile-content' respectively) will be created for each result (attributes will have a '.n' one-up number appended to the specified attribute name).  If any provided XQuery returns a result, the FlowFile(s) will be routed to 'matched'. If no provided XQuery returns a result, the FlowFile will be routed to 'unmatched'.  If the Destination is 'flowfile-attribute' and the XQueries matche nothing, no attributes will be applied to the FlowFile.</description><tags><tag>XML</tag><tag>evaluate</tag><tag>XPath</tag><tag>XQuery</tag></tags><properties><property><name>Destination</name><displayName>Destination</displayName><description>Indicates whether the results of the XQuery evaluation are written to the FlowFile content or a FlowFile attribute. If set to &lt;flowfile-content&gt;, only one XQuery may be specified and the property name is ignored.  If set to &lt;flowfile-attribute&gt; and the XQuery returns more than one result, multiple attributes will be added to theFlowFile, each named with a '.n' one-up number appended to the specified attribute name</description><defaultValue>flowfile-content</defaultValue><allowableValues><allowableValue><displayName>flowfile-content</displayName><value>flowfile-content</value><description></description></allowableValue><allowableValue><displayName>flowfile-attribute</displayName><value>flowfile-attribute</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Output: Method</name><displayName>Output: Method</displayName><description>Identifies the overall method that should be used for outputting a result tree.</description><defaultValue>xml</defaultValue><allowableValues><allowableValue><displayName>xml</displayName><value>xml</value><description></description></allowableValue><allowableValue><displayName>html</displayName><value>html</value><description></description></allowableValue><allowableValue><displayName>text</displayName><value>text</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Output: Omit XML Declaration</name><displayName>Output: Omit XML Declaration</displayName><description>Specifies whether the processor should output an XML declaration when transforming a result tree.</description><defaultValue>false</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Output: Indent</name><displayName>Output: Indent</displayName><description>Specifies whether the processor may add additional whitespace when outputting a result tree.</description><defaultValue>false</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Validate DTD</name><displayName>Allow DTD</displayName><description>Allow embedded Document Type Declaration in XML. This feature should be disabled to avoid XML entity expansion vulnerabilities.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>A FlowFile attribute(if &lt;Destination&gt; is set to 'flowfile-attribute'</name><value>An XQuery</value><description>If &lt;Destination&gt;='flowfile-attribute' then the FlowFile attribute is set to the result of the XQuery.  If &lt;Destination&gt;='flowfile-content' then the FlowFile content is set to the result of the XQuery.</description><expressionLanguageScope>NONE</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>failure</name><description>FlowFiles are routed to this relationship when the XQuery cannot be evaluated against the content of the FlowFile.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>matched</name><description>FlowFiles are routed to this relationship when the XQuery is successfully evaluated and the FlowFile is modified as a result</description><autoTerminated>false</autoTerminated></relationship><relationship><name>unmatched</name><description>FlowFiles are routed to this relationship when the XQuery does not match the content of the FlowFile and the Destination is set to flowfile-content</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>user-defined</name><description>This processor adds user-defined attributes if the &lt;Destination&gt; property is set to flowfile-attribute .</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><systemResourceConsiderations><systemResourceConsideration><resource>MEMORY</resource><description>Processing requires reading the entire FlowFile into memory</description></systemResourceConsideration></systemResourceConsiderations></extension><extension><name>org.apache.nifi.processors.standard.ExecuteProcess</name><type>PROCESSOR</type><description>Runs an operating system command specified by the user and writes the output of that command to a FlowFile. If the command is expected to be long-running, the Processor can output the partial data on a specified interval. When this option is used, the output is expected to be in textual format, as it typically does not make sense to split binary data on arbitrary time-based intervals.</description><tags><tag>command</tag><tag>process</tag><tag>source</tag><tag>external</tag><tag>invoke</tag><tag>script</tag></tags><properties><property><name>Command</name><displayName>Command</displayName><description>Specifies the command to be executed; if just the name of an executable is provided, it must be in the user's environment PATH.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Command Arguments</name><displayName>Command Arguments</displayName><description>The arguments to supply to the executable delimited by white space. White space can be escaped by enclosing it in double-quotes.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Batch Duration</name><displayName>Batch Duration</displayName><description>If the process is expected to be long-running and produce textual output, a batch duration can be specified so that the output will be captured for this amount of time and a FlowFile will then be sent out with the results and a new FlowFile will be started, rather than waiting for the process to finish before sending out the results</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Redirect Error Stream</name><displayName>Redirect Error Stream</displayName><description>If true will redirect any error stream output of the process to the output stream. This is particularly helpful for processes which write extensively to the error stream or for troubleshooting.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Working Directory</name><displayName>Working Directory</displayName><description>The directory to use as the current working directory when executing the command</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Argument Delimiter</name><displayName>Argument Delimiter</displayName><description>Delimiter to use to separate arguments for a command [default: space]. Must be a single character.</description><defaultValue> </defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Output MIME type</name><displayName>Output MIME Type</displayName><description>Specifies the value to set for the "mime.type" attribute. This property is ignored if 'Batch Duration' is set.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>An environment variable name</name><value>An environment variable value</value><description>These environment variables are passed to the process spawned by this Processor</description><expressionLanguageScope>NONE</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>success</name><description>All created FlowFiles are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>command</name><description>Executed command</description></writesAttribute><writesAttribute><name>command.arguments</name><description>Arguments of the command</description></writesAttribute><writesAttribute><name>mime.type</name><description>Sets the MIME type of the output if the 'Output MIME Type' property is set and 'Batch Duration' is not set</description></writesAttribute></writesAttributes><restricted><restrictions><restriction><requiredPermission>execute code</requiredPermission><explanation>Provides operator the ability to execute arbitrary code assuming all permissions that NiFi has.</explanation></restriction></restrictions></restricted><inputRequirement>INPUT_FORBIDDEN</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.ExecuteSQL</name><type>PROCESSOR</type><description>Executes provided SQL select query. Query result will be converted to Avro format. Streaming is used so arbitrarily large result sets are supported. This processor can be scheduled to run on a timer, or cron expression, using the standard scheduling methods, or it can be triggered by an incoming FlowFile. If it is triggered by an incoming FlowFile, then attributes of that FlowFile will be available when evaluating the select query, and the query may use the ? to escape parameters. In this case, the parameters to use must exist as FlowFile attributes with the naming convention sql.args.N.type and sql.args.N.value, where N is a positive integer. The sql.args.N.type is expected to be a number indicating the JDBC Type. The content of the FlowFile is expected to be in UTF-8 format. FlowFile attribute 'executesql.row.count' indicates how many rows were selected.</description><tags><tag>sql</tag><tag>select</tag><tag>jdbc</tag><tag>query</tag><tag>database</tag></tags><properties><property><name>Database Connection Pooling Service</name><displayName>Database Connection Pooling Service</displayName><description>The Controller Service that is used to obtain connection to database</description><controllerServiceDefinition><className>org.apache.nifi.dbcp.DBCPService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>sql-pre-query</name><displayName>SQL Pre-Query</displayName><description>A semicolon-delimited list of queries executed before the main SQL query is executed. For example, set session properties before main query. It's possible to include semicolons in the statements themselves by escaping them with a backslash ('\;'). Results/outputs from these queries will be suppressed if there are no errors.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>SQL Query</name><displayName>SQL Query</displayName><description>The SQL query to execute. The query can be empty, a constant value, or built from attributes using Expression Language. If this property is specified, it will be used regardless of the content of incoming flowfiles. If this property is empty, the content of the incoming flow file is expected to contain a valid SQL select query, to be issued by the processor to the database. Note that Expression Language is not evaluated for flow file contents.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>sql-post-query</name><displayName>SQL Post-Query</displayName><description>A semicolon-delimited list of queries executed after the main SQL query is executed. Example like setting session properties after main query. It's possible to include semicolons in the statements themselves by escaping them with a backslash ('\;'). Results/outputs from these queries will be suppressed if there are no errors.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Wait Time</name><displayName>Max Wait Time</displayName><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><defaultValue>0 seconds</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dbf-normalize</name><displayName>Normalize Table/Column Names</displayName><description>Whether to change non-Avro-compatible characters in column names to Avro-compatible characters. For example, colons and periods will be changed to underscores in order to build a valid Avro record.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dbf-user-logical-types</name><displayName>Use Avro Logical Types</displayName><description>Whether to use Avro Logical Types for DECIMAL/NUMBER, DATE, TIME and TIMESTAMP columns. If disabled, written as string. If enabled, Logical types are used and written as its underlying type, specifically, DECIMAL/NUMBER as logical 'decimal': written as bytes with additional precision and scale meta data, DATE as logical 'date-millis': written as int denoting days since Unix epoch (1970-01-01), TIME as logical 'time-millis': written as int denoting milliseconds since Unix epoch, and TIMESTAMP as logical 'timestamp-millis': written as long denoting milliseconds since Unix epoch. If a reader of written Avro records also knows these logical types, then these values can be deserialized with more context depending on reader implementation.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>compression-format</name><displayName>Compression Format</displayName><description>Compression type to use when writing Avro files. Default is None.</description><defaultValue>NONE</defaultValue><allowableValues><allowableValue><displayName>BZIP2</displayName><value>BZIP2</value><description></description></allowableValue><allowableValue><displayName>DEFLATE</displayName><value>DEFLATE</value><description></description></allowableValue><allowableValue><displayName>NONE</displayName><value>NONE</value><description></description></allowableValue><allowableValue><displayName>SNAPPY</displayName><value>SNAPPY</value><description></description></allowableValue><allowableValue><displayName>LZO</displayName><value>LZO</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dbf-default-precision</name><displayName>Default Decimal Precision</displayName><description>When a DECIMAL/NUMBER value is written as a 'decimal' Avro logical type, a specific 'precision' denoting number of available digits is required. Generally, precision is defined by column data type definition or database engines default. However undefined precision (0) can be returned from some database engines. 'Default Decimal Precision' is used when writing those undefined precision numbers.</description><defaultValue>10</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dbf-default-scale</name><displayName>Default Decimal Scale</displayName><description>When a DECIMAL/NUMBER value is written as a 'decimal' Avro logical type, a specific 'scale' denoting number of available decimal digits is required. Generally, scale is defined by column data type definition or database engines default. However when undefined precision (0) is returned, scale can also be uncertain with some database engines. 'Default Decimal Scale' is used when writing those undefined numbers. If a value has more decimals than specified scale, then the value will be rounded-up, e.g. 1.53 becomes 2 with scale 0, and 1.5 with scale 1.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>esql-max-rows</name><displayName>Max Rows Per Flow File</displayName><description>The maximum number of result rows that will be included in a single FlowFile. This will allow you to break up very large result sets into multiple FlowFiles. If the value specified is zero, then all rows are returned in a single FlowFile.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>esql-output-batch-size</name><displayName>Output Batch Size</displayName><description>The number of output FlowFiles to queue before committing the process session. When set to zero, the session will be committed when all result set rows have been processed and the output FlowFiles are ready for transfer to the downstream relationship. For large result sets, this can cause a large burst of FlowFiles to be transferred at the end of processor execution. If this property is set, then when the specified number of FlowFiles are ready for transfer, then the session will be committed, thus releasing the FlowFiles to the downstream relationship. NOTE: The fragment.count attribute will not be set on FlowFiles when this property is set.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>esql-fetch-size</name><displayName>Fetch Size</displayName><description>The number of result rows to be fetched from the result set at a time. This is a hint to the database driver and may not be honored and/or exact. If the value specified is zero, then the hint is ignored.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>esql-auto-commit</name><displayName>Set Auto Commit</displayName><description>Enables or disables the auto commit functionality of the DB connection. Default value is 'true'. The default value can be used with most of the JDBC drivers and this functionality doesn't have any impact in most of the cases since this processor is used to read data. However, for some JDBC drivers such as PostgreSQL driver, it is required to disable the auto committing functionality to limit the number of result rows fetching at a time. When auto commit is enabled, postgreSQL driver loads whole result set to memory at once. This could lead for a large amount of memory usage when executing queries which fetch large data sets. More Details of this behaviour in PostgreSQL driver can be found in https://jdbc.postgresql.org//documentation/head/query.html. </description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Content Output Strategy</name><displayName>Content Output Strategy</displayName><description>Specifies the strategy for writing FlowFile content when processing input FlowFiles.
The strategy applies when handling queries that do not produce results.
</description><defaultValue>EMPTY</defaultValue><allowableValues><allowableValue><displayName>Empty</displayName><value>EMPTY</value><description>Overwrite the input FlowFile content with an empty result set</description></allowableValue><allowableValue><displayName>Original</displayName><value>ORIGINAL</value><description>Retain the input FlowFile content without changes</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>sql.args.N.type</name><value>SQL type argument to be supplied</value><description>Incoming FlowFiles are expected to be parametrized SQL statements. The type of each Parameter is specified as an integer that represents the JDBC Type of the parameter. The following types are accepted: [LONGNVARCHAR: -16], [BIT: -7], [BOOLEAN: 16], [TINYINT: -6], [BIGINT: -5], [LONGVARBINARY: -4], [VARBINARY: -3], [BINARY: -2], [LONGVARCHAR: -1], [CHAR: 1], [NUMERIC: 2], [DECIMAL: 3], [INTEGER: 4], [SMALLINT: 5] [FLOAT: 6], [REAL: 7], [DOUBLE: 8], [VARCHAR: 12], [DATE: 91], [TIME: 92], [TIMESTAMP: 93], [VARCHAR: 12], [CLOB: 2005], [NCLOB: 2011]</description><expressionLanguageScope>NONE</expressionLanguageScope></dynamicProperty><dynamicProperty><name>sql.args.N.value</name><value>Argument to be supplied</value><description>Incoming FlowFiles are expected to be parametrized SQL statements. The value of the Parameters are specified as sql.args.1.value, sql.args.2.value, sql.args.3.value, and so on. The type of the sql.args.1.value Parameter is specified by the sql.args.1.type attribute.</description><expressionLanguageScope>NONE</expressionLanguageScope></dynamicProperty><dynamicProperty><name>sql.args.N.format</name><value>SQL format argument to be supplied</value><description>This attribute is always optional, but default options may not always work for your data. Incoming FlowFiles are expected to be parametrized SQL statements. In some cases a format option needs to be specified, currently this is only applicable for binary data types, dates, times and timestamps. Binary Data Types (defaults to 'ascii') - ascii: each string character in your attribute value represents a single byte. This is the format provided by Avro Processors. base64: the string is a Base64 encoded string that can be decoded to bytes. hex: the string is hex encoded with all letters in upper case and no '0x' at the beginning. Dates/Times/Timestamps - Date, Time and Timestamp formats all support both custom formats or named format ('yyyy-MM-dd','ISO_OFFSET_DATE_TIME') as specified according to java.time.format.DateTimeFormatter. If not specified, a long value input is expected to be an unix epoch (milli seconds from 1970/1/1), or a string value in 'yyyy-MM-dd' format for Date, 'HH:mm:ss.SSS' for Time (some database engines e.g. Derby or MySQL do not support milliseconds and will truncate milliseconds), 'yyyy-MM-dd HH:mm:ss.SSS' for Timestamp is used.</description><expressionLanguageScope>NONE</expressionLanguageScope></dynamicProperty></dynamicProperties><supportsSensitiveDynamicProperties>true</supportsSensitiveDynamicProperties><relationships><relationship><name>failure</name><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>Successfully created FlowFile from SQL query result set.</description><autoTerminated>false</autoTerminated></relationship></relationships><readsAttributes><readsAttribute><name>sql.args.N.type</name><description>Incoming FlowFiles are expected to be parametrized SQL statements. The type of each Parameter is specified as an integer that represents the JDBC Type of the parameter. The following types are accepted: [LONGNVARCHAR: -16], [BIT: -7], [BOOLEAN: 16], [TINYINT: -6], [BIGINT: -5], [LONGVARBINARY: -4], [VARBINARY: -3], [BINARY: -2], [LONGVARCHAR: -1], [CHAR: 1], [NUMERIC: 2], [DECIMAL: 3], [INTEGER: 4], [SMALLINT: 5] [FLOAT: 6], [REAL: 7], [DOUBLE: 8], [VARCHAR: 12], [DATE: 91], [TIME: 92], [TIMESTAMP: 93], [VARCHAR: 12], [CLOB: 2005], [NCLOB: 2011]</description></readsAttribute><readsAttribute><name>sql.args.N.value</name><description>Incoming FlowFiles are expected to be parametrized SQL statements. The value of the Parameters are specified as sql.args.1.value, sql.args.2.value, sql.args.3.value, and so on. The type of the sql.args.1.value Parameter is specified by the sql.args.1.type attribute.</description></readsAttribute><readsAttribute><name>sql.args.N.format</name><description>This attribute is always optional, but default options may not always work for your data. Incoming FlowFiles are expected to be parametrized SQL statements. In some cases a format option needs to be specified, currently this is only applicable for binary data types, dates, times and timestamps. Binary Data Types (defaults to 'ascii') - ascii: each string character in your attribute value represents a single byte. This is the format provided by Avro Processors. base64: the string is a Base64 encoded string that can be decoded to bytes. hex: the string is hex encoded with all letters in upper case and no '0x' at the beginning. Dates/Times/Timestamps - Date, Time and Timestamp formats all support both custom formats or named format ('yyyy-MM-dd','ISO_OFFSET_DATE_TIME') as specified according to java.time.format.DateTimeFormatter. If not specified, a long value input is expected to be an unix epoch (milli seconds from 1970/1/1), or a string value in 'yyyy-MM-dd' format for Date, 'HH:mm:ss.SSS' for Time (some database engines e.g. Derby or MySQL do not support milliseconds and will truncate milliseconds), 'yyyy-MM-dd HH:mm:ss.SSS' for Timestamp is used.</description></readsAttribute></readsAttributes><writesAttributes><writesAttribute><name>executesql.row.count</name><description>Contains the number of rows returned by the query. If 'Max Rows Per Flow File' is set, then this number will reflect the number of rows in the Flow File instead of the entire result set.</description></writesAttribute><writesAttribute><name>executesql.query.duration</name><description>Combined duration of the query execution time and fetch time in milliseconds. If 'Max Rows Per Flow File' is set, then this number will reflect only the fetch time for the rows in the Flow File instead of the entire result set.</description></writesAttribute><writesAttribute><name>executesql.query.executiontime</name><description>Duration of the query execution time in milliseconds. This number will reflect the query execution time regardless of the 'Max Rows Per Flow File' setting.</description></writesAttribute><writesAttribute><name>executesql.query.fetchtime</name><description>Duration of the result set fetch time in milliseconds. If 'Max Rows Per Flow File' is set, then this number will reflect only the fetch time for the rows in the Flow File instead of the entire result set.</description></writesAttribute><writesAttribute><name>executesql.resultset.index</name><description>Assuming multiple result sets are returned, the zero based index of this result set.</description></writesAttribute><writesAttribute><name>executesql.error.message</name><description>If processing an incoming flow file causes an Exception, the Flow File is routed to failure and this attribute is set to the exception message.</description></writesAttribute><writesAttribute><name>fragment.identifier</name><description>If 'Max Rows Per Flow File' is set then all FlowFiles from the same query result set will have the same value for the fragment.identifier attribute. This can then be used to correlate the results.</description></writesAttribute><writesAttribute><name>fragment.count</name><description>If 'Max Rows Per Flow File' is set then this is the total number of  FlowFiles produced by a single ResultSet. This can be used in conjunction with the fragment.identifier attribute in order to know how many FlowFiles belonged to the same incoming ResultSet. If Output Batch Size is set, then this attribute will not be populated.</description></writesAttribute><writesAttribute><name>fragment.index</name><description>If 'Max Rows Per Flow File' is set then the position of this FlowFile in the list of outgoing FlowFiles that were all derived from the same result set FlowFile. This can be used in conjunction with the fragment.identifier attribute to know which FlowFiles originated from the same query result set and in what order  FlowFiles were produced</description></writesAttribute><writesAttribute><name>input.flowfile.uuid</name><description>If the processor has an incoming connection, outgoing FlowFiles will have this attribute set to the value of the input FlowFile's UUID. If there is no incoming connection, the attribute will not be added.</description></writesAttribute></writesAttributes><inputRequirement>INPUT_ALLOWED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.ExecuteSQLRecord</name><type>PROCESSOR</type><description>Executes provided SQL select query. Query result will be converted to the format specified by a Record Writer. Streaming is used so arbitrarily large result sets are supported. This processor can be scheduled to run on a timer, or cron expression, using the standard scheduling methods, or it can be triggered by an incoming FlowFile. If it is triggered by an incoming FlowFile, then attributes of that FlowFile will be available when evaluating the select query, and the query may use the ? to escape parameters. In this case, the parameters to use must exist as FlowFile attributes with the naming convention sql.args.N.type and sql.args.N.value, where N is a positive integer. The sql.args.N.type is expected to be a number indicating the JDBC Type. The content of the FlowFile is expected to be in UTF-8 format. FlowFile attribute 'executesql.row.count' indicates how many rows were selected.</description><tags><tag>sql</tag><tag>select</tag><tag>jdbc</tag><tag>query</tag><tag>database</tag><tag>record</tag></tags><properties><property><name>Database Connection Pooling Service</name><displayName>Database Connection Pooling Service</displayName><description>The Controller Service that is used to obtain connection to database</description><controllerServiceDefinition><className>org.apache.nifi.dbcp.DBCPService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>sql-pre-query</name><displayName>SQL Pre-Query</displayName><description>A semicolon-delimited list of queries executed before the main SQL query is executed. For example, set session properties before main query. It's possible to include semicolons in the statements themselves by escaping them with a backslash ('\;'). Results/outputs from these queries will be suppressed if there are no errors.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>SQL Query</name><displayName>SQL Query</displayName><description>The SQL query to execute. The query can be empty, a constant value, or built from attributes using Expression Language. If this property is specified, it will be used regardless of the content of incoming flowfiles. If this property is empty, the content of the incoming flow file is expected to contain a valid SQL select query, to be issued by the processor to the database. Note that Expression Language is not evaluated for flow file contents.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>sql-post-query</name><displayName>SQL Post-Query</displayName><description>A semicolon-delimited list of queries executed after the main SQL query is executed. Example like setting session properties after main query. It's possible to include semicolons in the statements themselves by escaping them with a backslash ('\;'). Results/outputs from these queries will be suppressed if there are no errors.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Wait Time</name><displayName>Max Wait Time</displayName><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><defaultValue>0 seconds</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>esqlrecord-record-writer</name><displayName>Record Writer</displayName><description>Specifies the Controller Service to use for writing results to a FlowFile. The Record Writer may use Inherit Schema to emulate the inferred schema behavior, i.e. an explicit schema need not be defined in the writer, and will be supplied by the same logic used to infer the schema from the column types.</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>esqlrecord-normalize</name><displayName>Normalize Table/Column Names</displayName><description>Whether to change characters in column names. For example, colons and periods will be changed to underscores.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dbf-user-logical-types</name><displayName>Use Avro Logical Types</displayName><description>Whether to use Avro Logical Types for DECIMAL/NUMBER, DATE, TIME and TIMESTAMP columns. If disabled, written as string. If enabled, Logical types are used and written as its underlying type, specifically, DECIMAL/NUMBER as logical 'decimal': written as bytes with additional precision and scale meta data, DATE as logical 'date-millis': written as int denoting days since Unix epoch (1970-01-01), TIME as logical 'time-millis': written as int denoting milliseconds since Unix epoch, and TIMESTAMP as logical 'timestamp-millis': written as long denoting milliseconds since Unix epoch. If a reader of written Avro records also knows these logical types, then these values can be deserialized with more context depending on reader implementation.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dbf-default-precision</name><displayName>Default Decimal Precision</displayName><description>When a DECIMAL/NUMBER value is written as a 'decimal' Avro logical type, a specific 'precision' denoting number of available digits is required. Generally, precision is defined by column data type definition or database engines default. However undefined precision (0) can be returned from some database engines. 'Default Decimal Precision' is used when writing those undefined precision numbers.</description><defaultValue>10</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dbf-default-scale</name><displayName>Default Decimal Scale</displayName><description>When a DECIMAL/NUMBER value is written as a 'decimal' Avro logical type, a specific 'scale' denoting number of available decimal digits is required. Generally, scale is defined by column data type definition or database engines default. However when undefined precision (0) is returned, scale can also be uncertain with some database engines. 'Default Decimal Scale' is used when writing those undefined numbers. If a value has more decimals than specified scale, then the value will be rounded-up, e.g. 1.53 becomes 2 with scale 0, and 1.5 with scale 1.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>esql-max-rows</name><displayName>Max Rows Per Flow File</displayName><description>The maximum number of result rows that will be included in a single FlowFile. This will allow you to break up very large result sets into multiple FlowFiles. If the value specified is zero, then all rows are returned in a single FlowFile.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>esql-output-batch-size</name><displayName>Output Batch Size</displayName><description>The number of output FlowFiles to queue before committing the process session. When set to zero, the session will be committed when all result set rows have been processed and the output FlowFiles are ready for transfer to the downstream relationship. For large result sets, this can cause a large burst of FlowFiles to be transferred at the end of processor execution. If this property is set, then when the specified number of FlowFiles are ready for transfer, then the session will be committed, thus releasing the FlowFiles to the downstream relationship. NOTE: The fragment.count attribute will not be set on FlowFiles when this property is set.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>esql-fetch-size</name><displayName>Fetch Size</displayName><description>The number of result rows to be fetched from the result set at a time. This is a hint to the database driver and may not be honored and/or exact. If the value specified is zero, then the hint is ignored.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>esql-auto-commit</name><displayName>Set Auto Commit</displayName><description>Enables or disables the auto commit functionality of the DB connection. Default value is 'true'. The default value can be used with most of the JDBC drivers and this functionality doesn't have any impact in most of the cases since this processor is used to read data. However, for some JDBC drivers such as PostgreSQL driver, it is required to disable the auto committing functionality to limit the number of result rows fetching at a time. When auto commit is enabled, postgreSQL driver loads whole result set to memory at once. This could lead for a large amount of memory usage when executing queries which fetch large data sets. More Details of this behaviour in PostgreSQL driver can be found in https://jdbc.postgresql.org//documentation/head/query.html. </description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>sql.args.N.type</name><value>SQL type argument to be supplied</value><description>Incoming FlowFiles are expected to be parametrized SQL statements. The type of each Parameter is specified as an integer that represents the JDBC Type of the parameter. The following types are accepted: [LONGNVARCHAR: -16], [BIT: -7], [BOOLEAN: 16], [TINYINT: -6], [BIGINT: -5], [LONGVARBINARY: -4], [VARBINARY: -3], [BINARY: -2], [LONGVARCHAR: -1], [CHAR: 1], [NUMERIC: 2], [DECIMAL: 3], [INTEGER: 4], [SMALLINT: 5] [FLOAT: 6], [REAL: 7], [DOUBLE: 8], [VARCHAR: 12], [DATE: 91], [TIME: 92], [TIMESTAMP: 93], [VARCHAR: 12], [CLOB: 2005], [NCLOB: 2011]</description><expressionLanguageScope>NONE</expressionLanguageScope></dynamicProperty><dynamicProperty><name>sql.args.N.value</name><value>Argument to be supplied</value><description>Incoming FlowFiles are expected to be parametrized SQL statements. The value of the Parameters are specified as sql.args.1.value, sql.args.2.value, sql.args.3.value, and so on. The type of the sql.args.1.value Parameter is specified by the sql.args.1.type attribute.</description><expressionLanguageScope>NONE</expressionLanguageScope></dynamicProperty><dynamicProperty><name>sql.args.N.format</name><value>SQL format argument to be supplied</value><description>This attribute is always optional, but default options may not always work for your data. Incoming FlowFiles are expected to be parametrized SQL statements. In some cases a format option needs to be specified, currently this is only applicable for binary data types, dates, times and timestamps. Binary Data Types (defaults to 'ascii') - ascii: each string character in your attribute value represents a single byte. This is the format provided by Avro Processors. base64: the string is a Base64 encoded string that can be decoded to bytes. hex: the string is hex encoded with all letters in upper case and no '0x' at the beginning. Dates/Times/Timestamps - Date, Time and Timestamp formats all support both custom formats or named format ('yyyy-MM-dd','ISO_OFFSET_DATE_TIME') as specified according to java.time.format.DateTimeFormatter. If not specified, a long value input is expected to be an unix epoch (milli seconds from 1970/1/1), or a string value in 'yyyy-MM-dd' format for Date, 'HH:mm:ss.SSS' for Time (some database engines e.g. Derby or MySQL do not support milliseconds and will truncate milliseconds), 'yyyy-MM-dd HH:mm:ss.SSS' for Timestamp is used.</description><expressionLanguageScope>NONE</expressionLanguageScope></dynamicProperty></dynamicProperties><supportsSensitiveDynamicProperties>true</supportsSensitiveDynamicProperties><relationships><relationship><name>failure</name><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>Successfully created FlowFile from SQL query result set.</description><autoTerminated>false</autoTerminated></relationship></relationships><readsAttributes><readsAttribute><name>sql.args.N.type</name><description>Incoming FlowFiles are expected to be parametrized SQL statements. The type of each Parameter is specified as an integer that represents the JDBC Type of the parameter. The following types are accepted: [LONGNVARCHAR: -16], [BIT: -7], [BOOLEAN: 16], [TINYINT: -6], [BIGINT: -5], [LONGVARBINARY: -4], [VARBINARY: -3], [BINARY: -2], [LONGVARCHAR: -1], [CHAR: 1], [NUMERIC: 2], [DECIMAL: 3], [INTEGER: 4], [SMALLINT: 5] [FLOAT: 6], [REAL: 7], [DOUBLE: 8], [VARCHAR: 12], [DATE: 91], [TIME: 92], [TIMESTAMP: 93], [VARCHAR: 12], [CLOB: 2005], [NCLOB: 2011]</description></readsAttribute><readsAttribute><name>sql.args.N.value</name><description>Incoming FlowFiles are expected to be parametrized SQL statements. The value of the Parameters are specified as sql.args.1.value, sql.args.2.value, sql.args.3.value, and so on. The type of the sql.args.1.value Parameter is specified by the sql.args.1.type attribute.</description></readsAttribute><readsAttribute><name>sql.args.N.format</name><description>This attribute is always optional, but default options may not always work for your data. Incoming FlowFiles are expected to be parametrized SQL statements. In some cases a format option needs to be specified, currently this is only applicable for binary data types, dates, times and timestamps. Binary Data Types (defaults to 'ascii') - ascii: each string character in your attribute value represents a single byte. This is the format provided by Avro Processors. base64: the string is a Base64 encoded string that can be decoded to bytes. hex: the string is hex encoded with all letters in upper case and no '0x' at the beginning. Dates/Times/Timestamps - Date, Time and Timestamp formats all support both custom formats or named format ('yyyy-MM-dd','ISO_OFFSET_DATE_TIME') as specified according to java.time.format.DateTimeFormatter. If not specified, a long value input is expected to be an unix epoch (milli seconds from 1970/1/1), or a string value in 'yyyy-MM-dd' format for Date, 'HH:mm:ss.SSS' for Time (some database engines e.g. Derby or MySQL do not support milliseconds and will truncate milliseconds), 'yyyy-MM-dd HH:mm:ss.SSS' for Timestamp is used.</description></readsAttribute></readsAttributes><writesAttributes><writesAttribute><name>executesql.row.count</name><description>Contains the number of rows returned in the select query</description></writesAttribute><writesAttribute><name>executesql.query.duration</name><description>Combined duration of the query execution time and fetch time in milliseconds</description></writesAttribute><writesAttribute><name>executesql.query.executiontime</name><description>Duration of the query execution time in milliseconds</description></writesAttribute><writesAttribute><name>executesql.query.fetchtime</name><description>Duration of the result set fetch time in milliseconds</description></writesAttribute><writesAttribute><name>executesql.resultset.index</name><description>Assuming multiple result sets are returned, the zero based index of this result set.</description></writesAttribute><writesAttribute><name>executesql.error.message</name><description>If processing an incoming flow file causes an Exception, the Flow File is routed to failure and this attribute is set to the exception message.</description></writesAttribute><writesAttribute><name>fragment.identifier</name><description>If 'Max Rows Per Flow File' is set then all FlowFiles from the same query result set will have the same value for the fragment.identifier attribute. This can then be used to correlate the results.</description></writesAttribute><writesAttribute><name>fragment.count</name><description>If 'Max Rows Per Flow File' is set then this is the total number of  FlowFiles produced by a single ResultSet. This can be used in conjunction with the fragment.identifier attribute in order to know how many FlowFiles belonged to the same incoming ResultSet. If Output Batch Size is set, then this attribute will not be populated.</description></writesAttribute><writesAttribute><name>fragment.index</name><description>If 'Max Rows Per Flow File' is set then the position of this FlowFile in the list of outgoing FlowFiles that were all derived from the same result set FlowFile. This can be used in conjunction with the fragment.identifier attribute to know which FlowFiles originated from the same query result set and in what order  FlowFiles were produced</description></writesAttribute><writesAttribute><name>input.flowfile.uuid</name><description>If the processor has an incoming connection, outgoing FlowFiles will have this attribute set to the value of the input FlowFile's UUID. If there is no incoming connection, the attribute will not be added.</description></writesAttribute><writesAttribute><name>mime.type</name><description>Sets the mime.type attribute to the MIME Type specified by the Record Writer.</description></writesAttribute><writesAttribute><name>record.count</name><description>The number of records output by the Record Writer.</description></writesAttribute></writesAttributes><inputRequirement>INPUT_ALLOWED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.ExecuteStreamCommand</name><type>PROCESSOR</type><description>The ExecuteStreamCommand processor provides a flexible way to integrate external commands and scripts into NiFi data flows. ExecuteStreamCommand can pass the incoming FlowFile's content to the command that it executes similarly how piping works.</description><tags><tag>command execution</tag><tag>command</tag><tag>stream</tag><tag>execute</tag></tags><properties><property><name>Working Directory</name><displayName>Working Directory</displayName><description>The directory to use as the current working directory when executing the command</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Command Path</name><displayName>Command Path</displayName><description>Specifies the command to be executed; if just the name of an executable is provided, it must be in the user's environment PATH.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>argumentsStrategy</name><displayName>Command Arguments Strategy</displayName><description>Strategy for configuring arguments to be supplied to the command.</description><defaultValue>Command Arguments Property</defaultValue><allowableValues><allowableValue><displayName>Command Arguments Property</displayName><value>Command Arguments Property</value><description>Arguments to be supplied to the executable are taken from the Command Arguments property</description></allowableValue><allowableValue><displayName>Dynamic Property Arguments</displayName><value>Dynamic Property Arguments</value><description>Arguments to be supplied to the executable are taken from dynamic properties with pattern of 'command.argument.&lt;commandIndex&gt;'</description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Command Arguments</name><displayName>Command Arguments</displayName><description>The arguments to supply to the executable delimited by the ';' character.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>argumentsStrategy</propertyName><propertyDisplayName>Command Arguments Strategy</propertyDisplayName><dependentValues><dependentValue>Command Arguments Property</dependentValue></dependentValues></dependency></dependencies></property><property><name>Argument Delimiter</name><displayName>Argument Delimiter</displayName><description>Delimiter to use to separate arguments for a command [default: ;]. Must be a single character</description><defaultValue>;</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>argumentsStrategy</propertyName><propertyDisplayName>Command Arguments Strategy</propertyDisplayName><dependentValues><dependentValue>Command Arguments Property</dependentValue></dependentValues></dependency></dependencies></property><property><name>Ignore STDIN</name><displayName>Ignore STDIN</displayName><description>If true, the contents of the incoming flowfile will not be passed to the executing command</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Output Destination Attribute</name><displayName>Output Destination Attribute</displayName><description>If set, the output of the stream command will be put into an attribute of the original FlowFile instead of a separate FlowFile. There will no longer be a relationship for 'output stream' or 'nonzero status'. The value of this property will be the key for the output attribute.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Attribute Length</name><displayName>Max Attribute Length</displayName><description>If routing the output of the stream command to an attribute, the number of characters put to the attribute value will be at most this amount. This is important because attributes are held in memory and large attributes will quickly cause out of memory issues. If the output goes longer than this value, it will truncated to fit. Consider making this smaller if able.</description><defaultValue>256</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Output MIME Type</name><displayName>Output MIME Type</displayName><description>Specifies the value to set for the "mime.type" attribute. This property is ignored if 'Output Destination Attribute' is set.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>An environment variable name</name><value>An environment variable value</value><description>These environment variables are passed to the process spawned by this Processor</description><expressionLanguageScope>NONE</expressionLanguageScope></dynamicProperty><dynamicProperty><name>command.argument.&lt;commandIndex&gt;</name><value>Argument to be supplied to the command</value><description>These arguments are supplied to the process spawned by this Processor when using the Command Arguments Strategy : Dynamic Property Arguments. &lt;commandIndex&gt; is a number and it will determine the order.</description><expressionLanguageScope>NONE</expressionLanguageScope></dynamicProperty></dynamicProperties><supportsSensitiveDynamicProperties>true</supportsSensitiveDynamicProperties><relationships><relationship><name>nonzero status</name><description>The destination path for the flow file created from the command's output, if the returned status code is non-zero. All flow files routed to this relationship will be penalized.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>original</name><description>The original FlowFile will be routed. It will have new attributes detailing the result of the script execution.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>output stream</name><description>The destination path for the flow file created from the command's output, if the returned status code is zero.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>execution.command</name><description>The name of the command executed</description></writesAttribute><writesAttribute><name>execution.command.args</name><description>The semi-colon delimited list of arguments. Sensitive properties will be masked</description></writesAttribute><writesAttribute><name>execution.status</name><description>The exit status code returned from executing the command</description></writesAttribute><writesAttribute><name>execution.error</name><description>Any error messages returned from executing the command</description></writesAttribute><writesAttribute><name>mime.type</name><description>Sets the MIME type of the output if the 'Output MIME Type' property is set and 'Output Destination Attribute' is not set</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><restricted><restrictions><restriction><requiredPermission>execute code</requiredPermission><explanation>Provides operator the ability to execute arbitrary code assuming all permissions that NiFi has.</explanation></restriction></restrictions></restricted><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.ExtractGrok</name><type>PROCESSOR</type><description>Evaluates one or more Grok Expressions against the content of a FlowFile, adding the results as attributes or replacing the content of the FlowFile with a JSON notation of the matched content</description><tags><tag>grok</tag><tag>log</tag><tag>text</tag><tag>parse</tag><tag>delimit</tag><tag>extract</tag></tags><properties><property><name>Grok Expression</name><displayName>Grok Expression</displayName><description>Grok expression. If other Grok expressions are referenced in this expression, they must be provided in the Grok Pattern File if set or exist in the default Grok patterns</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Grok Pattern file</name><displayName>Grok Patterns</displayName><description>Custom Grok pattern definitions. These definitions will be loaded after the default Grok patterns. The Grok Parser will use the default Grok patterns when this property is not configured.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType><resourceType>TEXT</resourceType><resourceType>URL</resourceType></resourceTypes></resourceDefinition></property><property><name>Destination</name><displayName>Destination</displayName><description>Control if Grok output value is written as a new flowfile attributes, in this case each of the Grok identifier that is matched in the flowfile will be added as an attribute, prefixed with "grok." or written in the flowfile content. Writing to flowfile content will overwrite any existing flowfile content.</description><defaultValue>flowfile-attribute</defaultValue><allowableValues><allowableValue><displayName>flowfile-attribute</displayName><value>flowfile-attribute</value><description></description></allowableValue><allowableValue><displayName>flowfile-content</displayName><value>flowfile-content</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Character Set</name><displayName>Character Set</displayName><description>The Character Set in which the file is encoded</description><defaultValue>UTF-8</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum Buffer Size</name><displayName>Maximum Buffer Size</displayName><description>Specifies the maximum amount of data to buffer (per file) in order to apply the Grok expressions. Files larger than the specified maximum will not be fully evaluated.</description><defaultValue>1 MB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Named captures only</name><displayName>Named captures only</displayName><description>Only store named captures from grok</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Keep Empty Captures</name><displayName>Keep Empty Captures</displayName><description>If true, then empty capture values will be included in the returned capture map.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>matched</name><description>FlowFiles are routed to this relationship when the Grok Expression is successfully evaluated and the FlowFile is modified as a result</description><autoTerminated>false</autoTerminated></relationship><relationship><name>unmatched</name><description>FlowFiles are routed to this relationship when no provided Grok Expression matches the content of the FlowFile</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>grok.XXX</name><description>When operating in flowfile-attribute mode, each of the Grok identifier that is matched in the flowfile will be added as an attribute, prefixed with "grok." For example,if the grok identifier "timestamp" is matched, then the value will be added to an attribute named "grok.timestamp"</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><restricted><restrictions><restriction><requiredPermission>reference remote resources</requiredPermission><explanation>Patterns can reference resources over HTTP</explanation></restriction></restrictions></restricted><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.ExtractRecordSchema</name><type>PROCESSOR</type><description>Extracts the record schema from the FlowFile using the supplied Record Reader and writes it to the `avro.schema` attribute.</description><tags><tag>record</tag><tag>generic</tag><tag>schema</tag><tag>json</tag><tag>csv</tag><tag>avro</tag><tag>freeform</tag><tag>text</tag><tag>xml</tag></tags><properties><property><name>record-reader</name><displayName>Record Reader</displayName><description>Specifies the Controller Service to use for reading incoming data</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>cache-size</name><displayName>Schema Cache Size</displayName><description>Specifies the number of schemas to cache. This value should reflect the expected number of different schemas that may be in the incoming FlowFiles. This ensures more efficient retrieval of the schemas and thus the processor performance.</description><defaultValue>10</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>If a FlowFile's record schema cannot be extracted from the configured input format, the FlowFile will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>FlowFiles whose record schemas are successfully extracted will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>record.error.message</name><description>This attribute provides on failure the error message encountered by the Reader.</description></writesAttribute><writesAttribute><name>avro.schema</name><description>This attribute provides the schema extracted from the input FlowFile using the provided RecordReader.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.ExtractText</name><type>PROCESSOR</type><description>Evaluates one or more Regular Expressions against the content of a FlowFile.  The results of those Regular Expressions are assigned to FlowFile Attributes.  Regular Expressions are entered by adding user-defined properties; the name of the property maps to the Attribute Name into which the result will be placed.  The attributes are generated differently based on the enabling of named capture groups.  If named capture groups are not enabled:  The first capture group, if any found, will be placed into that attribute name.But all capture groups, including the matching string sequence itself will also be provided at that attribute name with an index value provided, with the exception of a capturing group that is optional and does not match - for example, given the attribute name "regex" and expression "abc(def)?(g)" we would add an attribute "regex.1" with a value of "def" if the "def" matched. If the "def" did not match, no attribute named "regex.1" would be added but an attribute named "regex.2" with a value of "g" will be added regardless.If named capture groups are enabled:  Each named capture group, if found will be placed into the attributes name with the name provided.  If enabled the matching string sequence itself will be placed into the attribute name.  If multiple matches are enabled, and index will be applied after the first set of matches. The exception is a capturing group that is optional and does not match  For example, given the attribute name "regex" and expression "abc(?&lt;NAMED&gt;def)?(?&lt;NAMED-TWO&gt;g)"  we would add an attribute "regex.NAMED" with the value of "def" if the "def" matched.  We would   add an attribute "regex.NAMED-TWO" with the value of "g" if the "g" matched regardless.  The value of the property must be a valid Regular Expressions with one or more capturing groups. If named capture groups are enabled, all capture groups must be named.  If they are not, then the  processor configuration will fail validation.  If the Regular Expression matches more than once, only the first match will be used unless the property enabling repeating capture group is set to true. If any provided Regular Expression matches, the FlowFile(s) will be routed to 'matched'. If no provided Regular Expression matches, the FlowFile will be routed to 'unmatched' and no attributes will be applied to the FlowFile.</description><tags><tag>evaluate</tag><tag>extract</tag><tag>Text</tag><tag>Regular Expression</tag><tag>regex</tag></tags><properties><property><name>Character Set</name><displayName>Character Set</displayName><description>The Character Set in which the file is encoded</description><defaultValue>UTF-8</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum Buffer Size</name><displayName>Maximum Buffer Size</displayName><description>Specifies the maximum amount of data to buffer (per FlowFile) in order to apply the regular expressions. FlowFiles larger than the specified maximum will not be fully evaluated.</description><defaultValue>1 MB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum Capture Group Length</name><displayName>Maximum Capture Group Length</displayName><description>Specifies the maximum number of characters a given capture group value can have. Any characters beyond the max will be truncated.</description><defaultValue>1024</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Enable Canonical Equivalence</name><displayName>Enable Canonical Equivalence</displayName><description>Indicates that two characters match only when their full canonical decompositions match.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Enable Case-insensitive Matching</name><displayName>Enable Case-insensitive Matching</displayName><description>Indicates that two characters match even if they are in a different case.  Can also be specified via the embedded flag (?i).</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Permit Whitespace and Comments in Pattern</name><displayName>Permit Whitespace and Comments in Pattern</displayName><description>In this mode, whitespace is ignored, and embedded comments starting with # are ignored until the end of a line.  Can also be specified via the embedded flag (?x).</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Enable DOTALL Mode</name><displayName>Enable DOTALL Mode</displayName><description>Indicates that the expression '.' should match any character, including a line terminator.  Can also be specified via the embedded flag (?s).</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Enable Literal Parsing of the Pattern</name><displayName>Enable Literal Parsing of the Pattern</displayName><description>Indicates that Metacharacters and escape characters should be given no special meaning.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Enable Multiline Mode</name><displayName>Enable Multiline Mode</displayName><description>Indicates that '^' and '$' should match just after and just before a line terminator or end of sequence, instead of only the beginning or end of the entire input.  Can also be specified via the embeded flag (?m).</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Enable Unicode-aware Case Folding</name><displayName>Enable Unicode-aware Case Folding</displayName><description>When used with 'Enable Case-insensitive Matching', matches in a manner consistent with the Unicode Standard.  Can also be specified via the embedded flag (?u).</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Enable Unicode Predefined Character Classes</name><displayName>Enable Unicode Predefined Character Classes</displayName><description>Specifies conformance with the Unicode Technical Standard #18: Unicode Regular Expression Annex C: Compatibility Properties.  Can also be specified via the embedded flag (?U).</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Enable Unix Lines Mode</name><displayName>Enable Unix Lines Mode</displayName><description>Indicates that only the '
' line terminator is recognized in the behavior of '.', '^', and '$'.  Can also be specified via the embedded flag (?d).</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Include Capture Group 0</name><displayName>Include Capture Group 0</displayName><description>Indicates that Capture Group 0 should be included as an attribute. Capture Group 0 represents the entirety of the regular expression match, is typically not used, and could have considerable length.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Enable repeating capture group</name><displayName>Enable repeating capture group</displayName><description>If set to true, every string matching the capture groups will be extracted. Otherwise, if the Regular Expression matches more than once, only the first match will be extracted.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Enable named group support</name><displayName>Enable named group support</displayName><description>If set to true, when named groups are present in the regular expression, the name of the
group will be used in the attribute name as opposed to the group index.  All capturing groups
must be named, if the number of groups (not including capture group 0) does not equal the
number of named groups validation will fail.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>A FlowFile attribute</name><value>A Regular Expression with one or more capturing group</value><description>The first capture group, if any found, will be placed into that attribute name.But all capture groups, including the matching string sequence itself will also be provided at that attribute name with an index value provided.</description><expressionLanguageScope>NONE</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>matched</name><description>FlowFiles are routed to this relationship when the Regular Expression is successfully evaluated and the FlowFile is modified as a result</description><autoTerminated>false</autoTerminated></relationship><relationship><name>unmatched</name><description>FlowFiles are routed to this relationship when no provided Regular Expression matches the content of the FlowFile</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.FetchDistributedMapCache</name><type>PROCESSOR</type><description>Computes cache key(s) from FlowFile attributes, for each incoming FlowFile, and fetches the value(s) from the Distributed Map Cache associated with each key. If configured without a destination attribute, the incoming FlowFile's content is replaced with the binary data received by the Distributed Map Cache. If there is no value stored under that key then the flow file will be routed to 'not-found'. Note that the processor will always attempt to read the entire cached value into memory before placing it in it's destination. This could be potentially problematic if the cached value is very large.</description><tags><tag>map</tag><tag>cache</tag><tag>fetch</tag><tag>distributed</tag></tags><properties><property><name>Cache Entry Identifier</name><displayName>Cache Entry Identifier</displayName><description>A comma-delimited list of FlowFile attributes, or the results of Attribute Expression Language statements, which will be evaluated against a FlowFile in order to determine the value(s) used to identify duplicates; it is these values that are cached. NOTE: Only a single Cache Entry Identifier is allowed unless Put Cache Value In Attribute is specified. Multiple cache lookups are only supported when the destination is a set of attributes (see the documentation for 'Put Cache Value In Attribute' for more details including naming convention.</description><defaultValue>${hash.value}</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Distributed Cache Service</name><displayName>Distributed Cache Service</displayName><description>The Controller Service that is used to get the cached values.</description><controllerServiceDefinition><className>org.apache.nifi.distributed.cache.client.DistributedMapCacheClient</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Put Cache Value In Attribute</name><displayName>Put Cache Value In Attribute</displayName><description>If set, the cache value received will be put into an attribute of the FlowFile instead of a the content of theFlowFile. The attribute key to put to is determined by evaluating value of this property. If multiple Cache Entry Identifiers are selected, multiple attributes will be written, using the evaluated value of this property, appended by a period (.) and the name of the cache entry identifier.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Length To Put In Attribute</name><displayName>Max Length To Put In Attribute</displayName><description>If routing the cache value to an attribute of the FlowFile (by setting the "Put Cache Value in attribute" property), the number of characters put to the attribute value will be at most this amount. This is important because attributes are held in memory and large attributes will quickly cause out of memory issues. If the output goes longer than this value, it will be truncated to fit. Consider making this smaller if able.</description><defaultValue>256</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Character Set</name><displayName>Character Set</displayName><description>The Character Set in which the cached value is encoded. This will only be used when routing to an attribute.</description><defaultValue>UTF-8</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>If unable to communicate with the cache or if the cache entry is evaluated to be blank, the FlowFile will be penalized and routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>not-found</name><description>If a FlowFile's Cache Entry Identifier was not found in the cache, it will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>If the cache was successfully communicated with it will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>user-defined</name><description>If the 'Put Cache Value In Attribute' property is set then whatever it is set to will become the attribute key and the value would be whatever the response was from the Distributed Map Cache. If multiple cache entry identifiers are selected, multiple attributes will be written, using the evaluated value of this property, appended by a period (.) and the name of the cache entry identifier. For example, if the Cache Entry Identifier property is set to 'id,name', and the user-defined property is named 'fetched', then two attributes will be written, fetched.id and fetched.name, containing their respective values.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_REQUIRED</inputRequirement><seeAlso><see>org.apache.nifi.distributed.cache.client.DistributedMapCacheClientService</see><see>org.apache.nifi.distributed.cache.server.map.DistributedMapCacheServer</see><see>org.apache.nifi.processors.standard.PutDistributedMapCache</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.FetchFTP</name><type>PROCESSOR</type><description>Fetches the content of a file from a remote FTP server and overwrites the contents of an incoming FlowFile with the content of the remote file.</description><tags><tag>ftp</tag><tag>get</tag><tag>retrieve</tag><tag>files</tag><tag>fetch</tag><tag>remote</tag><tag>ingest</tag><tag>source</tag><tag>input</tag></tags><properties><property><name>Hostname</name><displayName>Hostname</displayName><description>The fully-qualified hostname or IP address of the host to fetch the data from</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Port</name><displayName>Port</displayName><description>The port to connect to on the remote host to fetch the data from</description><defaultValue>21</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Username</name><displayName>Username</displayName><description>Username</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Password</name><displayName>Password</displayName><description>Password for the user account</description><required>false</required><sensitive>true</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Remote File</name><displayName>Remote File</displayName><description>The fully qualified filename on the remote system</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Completion Strategy</name><displayName>Completion Strategy</displayName><description>Specifies what to do with the original file on the server once it has been pulled into NiFi. If the Completion Strategy fails, a warning will be logged but the data will still be transferred.</description><defaultValue>None</defaultValue><allowableValues><allowableValue><displayName>None</displayName><value>None</value><description>Leave the file as-is</description></allowableValue><allowableValue><displayName>Move File</displayName><value>Move File</value><description>Move the file to the directory specified by the &lt;Move Destination Directory&gt; property</description></allowableValue><allowableValue><displayName>Delete File</displayName><value>Delete File</value><description>Deletes the original file from the remote system</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Move Destination Directory</name><displayName>Move Destination Directory</displayName><description>The directory on the remote server to move the original file to once it has been ingested into NiFi. This property is ignored unless the Completion Strategy is set to 'Move File'. The specified directory must already exist on the remote system if 'Create Directory' is disabled, or the rename will fail.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Create Directory</name><displayName>Create Directory</displayName><description>Used when 'Completion Strategy' is 'Move File'. Specifies whether or not the remote directory should be created if it does not exist.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Connection Timeout</name><displayName>Connection Timeout</displayName><description>Amount of time to wait before timing out while creating a connection</description><defaultValue>30 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Data Timeout</name><displayName>Data Timeout</displayName><description>When transferring a file between the local and remote system, this value specifies how long is allowed to elapse without any data being transferred between systems</description><defaultValue>30 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Use Compression</name><displayName>Use Compression</displayName><description>Indicates whether or not ZLIB compression should be used when transferring files</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Connection Mode</name><displayName>Connection Mode</displayName><description>The FTP Connection Mode</description><defaultValue>Passive</defaultValue><allowableValues><allowableValue><displayName>Active</displayName><value>Active</value><description></description></allowableValue><allowableValue><displayName>Passive</displayName><value>Passive</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Transfer Mode</name><displayName>Transfer Mode</displayName><description>The FTP Transfer Mode</description><defaultValue>Binary</defaultValue><allowableValues><allowableValue><displayName>Binary</displayName><value>Binary</value><description></description></allowableValue><allowableValue><displayName>ASCII</displayName><value>ASCII</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>proxy-configuration-service</name><displayName>Proxy Configuration Service</displayName><description>Specifies the Proxy Configuration Controller Service to proxy network requests. Supported proxies: HTTP + AuthN, SOCKS + AuthN</description><controllerServiceDefinition><className>org.apache.nifi.proxy.ProxyConfigurationService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Internal Buffer Size</name><displayName>Internal Buffer Size</displayName><description>Set the internal buffer size for buffered data streams</description><defaultValue>16KB</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>fetchfiletransfer-notfound-loglevel</name><displayName>Log level when file not found</displayName><description>Log level to use in case the file does not exist when the processor is triggered</description><defaultValue>ERROR</defaultValue><allowableValues><allowableValue><displayName>TRACE</displayName><value>TRACE</value><description></description></allowableValue><allowableValue><displayName>DEBUG</displayName><value>DEBUG</value><description></description></allowableValue><allowableValue><displayName>INFO</displayName><value>INFO</value><description></description></allowableValue><allowableValue><displayName>WARN</displayName><value>WARN</value><description></description></allowableValue><allowableValue><displayName>ERROR</displayName><value>ERROR</value><description></description></allowableValue><allowableValue><displayName>FATAL</displayName><value>FATAL</value><description></description></allowableValue><allowableValue><displayName>NONE</displayName><value>NONE</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>ftp-use-utf8</name><displayName>Use UTF-8 Encoding</displayName><description>Tells the client to use UTF-8 encoding when processing files and filenames. If set to true, the server must also support UTF-8 encoding.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>comms.failure</name><description>Any FlowFile that could not be fetched from the remote server due to a communications failure will be transferred to this Relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>not.found</name><description>Any FlowFile for which we receive a 'Not Found' message from the remote server will be transferred to this Relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>permission.denied</name><description>Any FlowFile that could not be fetched from the remote server due to insufficient permissions will be transferred to this Relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>All FlowFiles that are received are routed to success</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>ftp.remote.host</name><description>The hostname or IP address from which the file was pulled</description></writesAttribute><writesAttribute><name>ftp.remote.port</name><description>The port that was used to communicate with the remote FTP server</description></writesAttribute><writesAttribute><name>ftp.remote.filename</name><description>The name of the remote file that was pulled</description></writesAttribute><writesAttribute><name>filename</name><description>The filename is updated to point to the filename fo the remote file</description></writesAttribute><writesAttribute><name>path</name><description>If the Remote File contains a directory name, that directory name will be added to the FlowFile using the 'path' attribute</description></writesAttribute><writesAttribute><name>fetch.failure.reason</name><description>The name of the failure relationship applied when routing to any failure relationship</description></writesAttribute></writesAttributes><inputRequirement>INPUT_REQUIRED</inputRequirement><multiProcessorUseCases><multiProcessorUseCase><description>Retrieve all files in a directory of an FTP Server</description><notes></notes><keywords><keyword>ftp</keyword><keyword>file</keyword><keyword>transform</keyword><keyword>state</keyword><keyword>retrieve</keyword><keyword>fetch</keyword><keyword>all</keyword><keyword>stream</keyword></keywords><processorConfigurations><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.ListFTP</processorClassName><configuration>The "Hostname" property should be set to the fully qualified hostname of the FTP Server. It's a good idea to parameterize     this property by setting it to something like `#{FTP_SERVER}`.
The "Remote Path" property must be set to the directory on the FTP Server where the files reside. If the flow being built is to be reused elsewhere,     it's a good idea to parameterize this property by setting it to something like `#{FTP_REMOTE_PATH}`.
Configure the "Username" property to the appropriate username for logging into the FTP Server. It's usually a good idea to parameterize this property     by setting it to something like `#{FTP_USERNAME}`.
Configure the "Password" property to the appropriate password for the provided username. It's usually a good idea to parameterize this property     by setting it to something like `#{FTP_PASSWORD}`.

The 'success' Relationship of this Processor is then connected to FetchFTP.
</configuration></processorConfiguration><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.FetchFTP</processorClassName><configuration>"Hostname" = "${ftp.remote.host}"
"Remote File" = "${path}/${filename}"
"Username" = "${ftp.listing.user}"
"Password" = "#{FTP_PASSWORD}"
</configuration></processorConfiguration></processorConfigurations></multiProcessorUseCase></multiProcessorUseCases><seeAlso><see>org.apache.nifi.processors.standard.GetSFTP</see><see>org.apache.nifi.processors.standard.PutSFTP</see><see>org.apache.nifi.processors.standard.GetFTP</see><see>org.apache.nifi.processors.standard.PutFTP</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.FetchFile</name><type>PROCESSOR</type><description>Reads the contents of a file from disk and streams it into the contents of an incoming FlowFile. Once this is done, the file is optionally moved elsewhere or deleted to help keep the file system organized.</description><tags><tag>local</tag><tag>files</tag><tag>filesystem</tag><tag>ingest</tag><tag>ingress</tag><tag>get</tag><tag>source</tag><tag>input</tag><tag>fetch</tag></tags><properties><property><name>File to Fetch</name><displayName>File to Fetch</displayName><description>The fully-qualified filename of the file to fetch from the file system</description><defaultValue>${absolute.path}/${filename}</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Completion Strategy</name><displayName>Completion Strategy</displayName><description>Specifies what to do with the original file on the file system once it has been pulled into NiFi</description><defaultValue>None</defaultValue><allowableValues><allowableValue><displayName>None</displayName><value>None</value><description>Leave the file as-is</description></allowableValue><allowableValue><displayName>Move File</displayName><value>Move File</value><description>Moves the file to the directory specified by the &lt;Move Destination Directory&gt; property</description></allowableValue><allowableValue><displayName>Delete File</displayName><value>Delete File</value><description>Deletes the original file from the file system</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Move Destination Directory</name><displayName>Move Destination Directory</displayName><description>The directory to the move the original file to once it has been fetched from the file system. This property is ignored unless the Completion Strategy is set to "Move File". If the directory does not exist, it will be created.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Move Conflict Strategy</name><displayName>Move Conflict Strategy</displayName><description>If Completion Strategy is set to Move File and a file already exists in the destination directory with the same name, this property specifies how that naming conflict should be resolved</description><defaultValue>Rename</defaultValue><allowableValues><allowableValue><displayName>Rename</displayName><value>Rename</value><description>The existing destination file should remain intact. The newly ingested file should be moved to the destination directory but be renamed to a random filename</description></allowableValue><allowableValue><displayName>Replace File</displayName><value>Replace File</value><description>The newly ingested file should replace the existing file in the Destination Directory</description></allowableValue><allowableValue><displayName>Keep Existing</displayName><value>Keep Existing</value><description>The existing file should in the Destination Directory should stay intact and the newly ingested file should be deleted</description></allowableValue><allowableValue><displayName>Fail</displayName><value>Fail</value><description>The existing destination file should remain intact and the incoming FlowFile should be routed to failure</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Log level when file not found</name><displayName>Log level when file not found</displayName><description>Log level to use in case the file does not exist when the processor is triggered</description><defaultValue>ERROR</defaultValue><allowableValues><allowableValue><displayName>TRACE</displayName><value>TRACE</value><description></description></allowableValue><allowableValue><displayName>DEBUG</displayName><value>DEBUG</value><description></description></allowableValue><allowableValue><displayName>INFO</displayName><value>INFO</value><description></description></allowableValue><allowableValue><displayName>WARN</displayName><value>WARN</value><description></description></allowableValue><allowableValue><displayName>ERROR</displayName><value>ERROR</value><description></description></allowableValue><allowableValue><displayName>FATAL</displayName><value>FATAL</value><description></description></allowableValue><allowableValue><displayName>NONE</displayName><value>NONE</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Log level when permission denied</name><displayName>Log level when permission denied</displayName><description>Log level to use in case user mangal does not have sufficient permissions to read the file</description><defaultValue>ERROR</defaultValue><allowableValues><allowableValue><displayName>TRACE</displayName><value>TRACE</value><description></description></allowableValue><allowableValue><displayName>DEBUG</displayName><value>DEBUG</value><description></description></allowableValue><allowableValue><displayName>INFO</displayName><value>INFO</value><description></description></allowableValue><allowableValue><displayName>WARN</displayName><value>WARN</value><description></description></allowableValue><allowableValue><displayName>ERROR</displayName><value>ERROR</value><description></description></allowableValue><allowableValue><displayName>FATAL</displayName><value>FATAL</value><description></description></allowableValue><allowableValue><displayName>NONE</displayName><value>NONE</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>Any FlowFile that could not be fetched from the file system for any reason other than insufficient permissions or the file not existing will be transferred to this Relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>not.found</name><description>Any FlowFile that could not be fetched from the file system because the file could not be found will be transferred to this Relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>permission.denied</name><description>Any FlowFile that could not be fetched from the file system due to the user running NiFi not having sufficient permissions will be transferred to this Relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>Any FlowFile that is successfully fetched from the file system will be transferred to this Relationship.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><restricted><restrictions><restriction><requiredPermission>read filesystem</requiredPermission><explanation>Provides operator the ability to read from any file that NiFi has access to.</explanation></restriction><restriction><requiredPermission>write filesystem</requiredPermission><explanation>Provides operator the ability to delete any file that NiFi has access to.</explanation></restriction></restrictions></restricted><inputRequirement>INPUT_REQUIRED</inputRequirement><multiProcessorUseCases><multiProcessorUseCase><description>Ingest all files from a directory into NiFi</description><notes></notes><keywords><keyword>local</keyword><keyword>files</keyword><keyword>filesystem</keyword><keyword>ingest</keyword><keyword>ingress</keyword><keyword>get</keyword><keyword>source</keyword><keyword>input</keyword><keyword>fetch</keyword></keywords><processorConfigurations><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.ListFile</processorClassName><configuration>Configure the "Input Directory" property to point to the directory that you want to ingest files from.
Set the "Input Directory Location" property to "Local"
Optionally, set "Minimum File Age" to a small value such as "1 min" to avoid ingesting files that are still being written to.

Connect the 'success' Relationship to the FetchFile processor.
</configuration></processorConfiguration><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.FetchFile</processorClassName><configuration>Set the "File to Fetch" property to `${absolute.path}/${filename}`
Set the "Completion Strategy" property to `None`
</configuration></processorConfiguration></processorConfigurations></multiProcessorUseCase><multiProcessorUseCase><description>Ingest specific files from a directory into NiFi, filtering on filename</description><notes></notes><keywords><keyword>local</keyword><keyword>files</keyword><keyword>filesystem</keyword><keyword>ingest</keyword><keyword>ingress</keyword><keyword>get</keyword><keyword>source</keyword><keyword>input</keyword><keyword>fetch</keyword><keyword>filter</keyword></keywords><processorConfigurations><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.ListFile</processorClassName><configuration>Configure the "Input Directory" property to point to the directory that you want to ingest files from.
Set the "Input Directory Location" property to "Local"
Set the "File Filter" property to a Regular Expression that matches the filename (without path) of the files that you want to ingest. For example, to ingest all .jpg files, set the value to `.*\.jpg`
Optionally, set "Minimum File Age" to a small value such as "1 min" to avoid ingesting files that are still being written to.

Connect the 'success' Relationship to the FetchFile processor.
</configuration></processorConfiguration><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.FetchFile</processorClassName><configuration>Set the "File to Fetch" property to `${absolute.path}/${filename}`
Set the "Completion Strategy" property to `None`
</configuration></processorConfiguration></processorConfigurations></multiProcessorUseCase></multiProcessorUseCases><seeAlso><see>org.apache.nifi.processors.standard.GetFile</see><see>org.apache.nifi.processors.standard.PutFile</see><see>org.apache.nifi.processors.standard.ListFile</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.FetchSFTP</name><type>PROCESSOR</type><description>Fetches the content of a file from a remote SFTP server and overwrites the contents of an incoming FlowFile with the content of the remote file.</description><tags><tag>sftp</tag><tag>get</tag><tag>retrieve</tag><tag>files</tag><tag>fetch</tag><tag>remote</tag><tag>ingest</tag><tag>source</tag><tag>input</tag></tags><properties><property><name>Hostname</name><displayName>Hostname</displayName><description>The fully-qualified hostname or IP address of the host to fetch the data from</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Port</name><displayName>Port</displayName><description>The port to connect to on the remote host to fetch the data from</description><defaultValue>22</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Username</name><displayName>Username</displayName><description>Username</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Password</name><displayName>Password</displayName><description>Password for the user account</description><required>false</required><sensitive>true</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Private Key Path</name><displayName>Private Key Path</displayName><description>The fully qualified path to the Private Key file</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType></resourceTypes></resourceDefinition></property><property><name>Private Key Passphrase</name><displayName>Private Key Passphrase</displayName><description>Password for the private key</description><required>false</required><sensitive>true</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Remote File</name><displayName>Remote File</displayName><description>The fully qualified filename on the remote system</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Completion Strategy</name><displayName>Completion Strategy</displayName><description>Specifies what to do with the original file on the server once it has been pulled into NiFi. If the Completion Strategy fails, a warning will be logged but the data will still be transferred.</description><defaultValue>None</defaultValue><allowableValues><allowableValue><displayName>None</displayName><value>None</value><description>Leave the file as-is</description></allowableValue><allowableValue><displayName>Move File</displayName><value>Move File</value><description>Move the file to the directory specified by the &lt;Move Destination Directory&gt; property</description></allowableValue><allowableValue><displayName>Delete File</displayName><value>Delete File</value><description>Deletes the original file from the remote system</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Move Destination Directory</name><displayName>Move Destination Directory</displayName><description>The directory on the remote server to move the original file to once it has been ingested into NiFi. This property is ignored unless the Completion Strategy is set to 'Move File'. The specified directory must already exist on the remote system if 'Create Directory' is disabled, or the rename will fail.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Create Directory</name><displayName>Create Directory</displayName><description>Used when 'Completion Strategy' is 'Move File'. Specifies whether or not the remote directory should be created if it does not exist.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Disable Directory Listing</name><displayName>Disable Directory Listing</displayName><description>Control how 'Move Destination Directory' is created when 'Completion Strategy' is 'Move File' and 'Create Directory' is enabled. If set to 'true', directory listing is not performed prior to create missing directories. By default, this processor executes a directory listing command to see target directory existence before creating missing directories. However, there are situations that you might need to disable the directory listing such as the following. Directory listing might fail with some permission setups (e.g. chmod 100) on a directory. Also, if any other SFTP client created the directory after this processor performed a listing and before a directory creation request by this processor is finished, then an error is returned because the directory already exists.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Connection Timeout</name><displayName>Connection Timeout</displayName><description>Amount of time to wait before timing out while creating a connection</description><defaultValue>30 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Data Timeout</name><displayName>Data Timeout</displayName><description>When transferring a file between the local and remote system, this value specifies how long is allowed to elapse without any data being transferred between systems</description><defaultValue>30 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Send Keep Alive On Timeout</name><displayName>Send Keep Alive On Timeout</displayName><description>Send a Keep Alive message every 5 seconds up to 5 times for an overall timeout of 25 seconds.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Host Key File</name><displayName>Host Key File</displayName><description>If supplied, the given file will be used as the Host Key; otherwise, if 'Strict Host Key Checking' property is applied (set to true) then uses the 'known_hosts' and 'known_hosts2' files from ~/.ssh directory else no host key file will be used</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType></resourceTypes></resourceDefinition></property><property><name>Strict Host Key Checking</name><displayName>Strict Host Key Checking</displayName><description>Indicates whether or not strict enforcement of hosts keys should be applied</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Use Compression</name><displayName>Use Compression</displayName><description>Indicates whether or not ZLIB compression should be used when transferring files</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>proxy-configuration-service</name><displayName>Proxy Configuration Service</displayName><description>Specifies the Proxy Configuration Controller Service to proxy network requests. Supported proxies: HTTP + AuthN, SOCKS + AuthN</description><controllerServiceDefinition><className>org.apache.nifi.proxy.ProxyConfigurationService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>fetchfiletransfer-notfound-loglevel</name><displayName>Log level when file not found</displayName><description>Log level to use in case the file does not exist when the processor is triggered</description><defaultValue>ERROR</defaultValue><allowableValues><allowableValue><displayName>TRACE</displayName><value>TRACE</value><description></description></allowableValue><allowableValue><displayName>DEBUG</displayName><value>DEBUG</value><description></description></allowableValue><allowableValue><displayName>INFO</displayName><value>INFO</value><description></description></allowableValue><allowableValue><displayName>WARN</displayName><value>WARN</value><description></description></allowableValue><allowableValue><displayName>ERROR</displayName><value>ERROR</value><description></description></allowableValue><allowableValue><displayName>FATAL</displayName><value>FATAL</value><description></description></allowableValue><allowableValue><displayName>NONE</displayName><value>NONE</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Ciphers Allowed</name><displayName>Ciphers Allowed</displayName><description>A comma-separated list of Ciphers allowed for SFTP connections. Leave unset to allow all. Available options are: 3des-cbc, 3des-ctr, aes128-cbc, aes128-ctr, aes128-gcm@openssh.com, aes192-cbc, aes192-ctr, aes256-cbc, aes256-ctr, aes256-gcm@openssh.com, arcfour, arcfour128, arcfour256, blowfish-cbc, blowfish-ctr, cast128-cbc, cast128-ctr, chacha20-poly1305@openssh.com, idea-cbc, idea-ctr, serpent128-cbc, serpent128-ctr, serpent192-cbc, serpent192-ctr, serpent256-cbc, serpent256-ctr, twofish-cbc, twofish128-cbc, twofish128-ctr, twofish192-cbc, twofish192-ctr, twofish256-cbc, twofish256-ctr</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Key Algorithms Allowed</name><displayName>Key Algorithms Allowed</displayName><description>A comma-separated list of Key Algorithms allowed for SFTP connections. Leave unset to allow all. Available options are: ecdsa-sha2-nistp256, ecdsa-sha2-nistp256-cert-v01@openssh.com, ecdsa-sha2-nistp384, ecdsa-sha2-nistp384-cert-v01@openssh.com, ecdsa-sha2-nistp521, ecdsa-sha2-nistp521-cert-v01@openssh.com, rsa-sha2-256, rsa-sha2-512, ssh-dss, ssh-dss-cert-v01@openssh.com, ssh-ed25519, ssh-ed25519-cert-v01@openssh.com, ssh-rsa, ssh-rsa-cert-v01@openssh.com</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Key Exchange Algorithms Allowed</name><displayName>Key Exchange Algorithms Allowed</displayName><description>A comma-separated list of Key Exchange Algorithms allowed for SFTP connections. Leave unset to allow all. Available options are: curve25519-sha256, curve25519-sha256@libssh.org, diffie-hellman-group-exchange-sha1, diffie-hellman-group-exchange-sha256, diffie-hellman-group1-sha1, diffie-hellman-group14-sha1, diffie-hellman-group14-sha256, diffie-hellman-group14-sha256@ssh.com, diffie-hellman-group15-sha256, diffie-hellman-group15-sha256@ssh.com, diffie-hellman-group15-sha384@ssh.com, diffie-hellman-group15-sha512, diffie-hellman-group16-sha256, diffie-hellman-group16-sha384@ssh.com, diffie-hellman-group16-sha512, diffie-hellman-group16-sha512@ssh.com, diffie-hellman-group17-sha512, diffie-hellman-group18-sha512, diffie-hellman-group18-sha512@ssh.com, ecdh-sha2-nistp256, ecdh-sha2-nistp384, ecdh-sha2-nistp521, ext-info-c</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Message Authentication Codes Allowed</name><displayName>Message Authentication Codes Allowed</displayName><description>A comma-separated list of Message Authentication Codes allowed for SFTP connections. Leave unset to allow all. Available options are: hmac-md5, hmac-md5-96, hmac-md5-96-etm@openssh.com, hmac-md5-etm@openssh.com, hmac-ripemd160, hmac-ripemd160-96, hmac-ripemd160-etm@openssh.com, hmac-ripemd160@openssh.com, hmac-sha1, hmac-sha1-96, hmac-sha1-96@openssh.com, hmac-sha1-etm@openssh.com, hmac-sha2-256, hmac-sha2-256-etm@openssh.com, hmac-sha2-512, hmac-sha2-512-etm@openssh.com</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>comms.failure</name><description>Any FlowFile that could not be fetched from the remote server due to a communications failure will be transferred to this Relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>not.found</name><description>Any FlowFile for which we receive a 'Not Found' message from the remote server will be transferred to this Relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>permission.denied</name><description>Any FlowFile that could not be fetched from the remote server due to insufficient permissions will be transferred to this Relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>All FlowFiles that are received are routed to success</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>sftp.remote.host</name><description>The hostname or IP address from which the file was pulled</description></writesAttribute><writesAttribute><name>sftp.remote.port</name><description>The port that was used to communicate with the remote SFTP server</description></writesAttribute><writesAttribute><name>sftp.remote.filename</name><description>The name of the remote file that was pulled</description></writesAttribute><writesAttribute><name>filename</name><description>The filename is updated to point to the filename fo the remote file</description></writesAttribute><writesAttribute><name>path</name><description>If the Remote File contains a directory name, that directory name will be added to the FlowFile using the 'path' attribute</description></writesAttribute><writesAttribute><name>fetch.failure.reason</name><description>The name of the failure relationship applied when routing to any failure relationship</description></writesAttribute></writesAttributes><inputRequirement>INPUT_REQUIRED</inputRequirement><multiProcessorUseCases><multiProcessorUseCase><description>Retrieve all files in a directory of an SFTP Server</description><notes></notes><keywords><keyword>sftp</keyword><keyword>secure</keyword><keyword>file</keyword><keyword>transform</keyword><keyword>state</keyword><keyword>retrieve</keyword><keyword>fetch</keyword><keyword>all</keyword><keyword>stream</keyword></keywords><processorConfigurations><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.ListSFTP</processorClassName><configuration>The "Hostname" property should be set to the fully qualified hostname of the FTP Server. It's a good idea to parameterize     this property by setting it to something like `#{SFTP_SERVER}`.
The "Remote Path" property must be set to the directory on the FTP Server where the files reside. If the flow being built is to be reused elsewhere,     it's a good idea to parameterize this property by setting it to something like `#{SFTP_REMOTE_PATH}`.
Configure the "Username" property to the appropriate username for logging into the FTP Server. It's usually a good idea to parameterize this property     by setting it to something like `#{SFTP_USERNAME}`.
Configure the "Password" property to the appropriate password for the provided username. It's usually a good idea to parameterize this property     by setting it to something like `#{SFTP_PASSWORD}`.

The 'success' Relationship of this Processor is then connected to FetchSFTP.
</configuration></processorConfiguration><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.FetchSFTP</processorClassName><configuration>"Hostname" = "${sftp.remote.host}"
"Remote File" = "${path}/${filename}"
"Username" = "${sftp.listing.user}"
"Password" = "#{SFTP_PASSWORD}"
</configuration></processorConfiguration></processorConfigurations></multiProcessorUseCase></multiProcessorUseCases><seeAlso><see>org.apache.nifi.processors.standard.GetSFTP</see><see>org.apache.nifi.processors.standard.PutSFTP</see><see>org.apache.nifi.processors.standard.GetFTP</see><see>org.apache.nifi.processors.standard.PutFTP</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.FilterAttribute</name><type>PROCESSOR</type><description>Filters the attributes of a FlowFile by retaining specified attributes and removing the rest or by removing specified attributes and retaining the rest.</description><tags><tag>attributes</tag><tag>modification</tag><tag>filter</tag><tag>retain</tag><tag>remove</tag><tag>delete</tag><tag>regex</tag><tag>regular expression</tag><tag>Attribute Expression Language</tag></tags><properties><property><name>Filter Mode</name><displayName>Filter Mode</displayName><description>Specifies the strategy to apply on filtered attributes. Either 'Remove' or 'Retain' only the matching attributes.</description><defaultValue>Retain</defaultValue><allowableValues><allowableValue><displayName>Retain</displayName><value>Retain</value><description>Retains only the attributes matching the filter, all other attributes are removed.</description></allowableValue><allowableValue><displayName>Remove</displayName><value>Remove</value><description>Removes the attributes matching the filter, all other attributes are retained.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Attribute Matching Strategy</name><displayName>Attribute Matching Strategy</displayName><description>Specifies the strategy to filter attributes by.</description><defaultValue>Enumerate attributes</defaultValue><allowableValues><allowableValue><displayName>Enumerate attributes</displayName><value>Enumerate attributes</value><description>Provides a set of attribute keys to filter for, separated by a comma delimiter ','.</description></allowableValue><allowableValue><displayName>Use regular expression</displayName><value>Use regular expression</value><description>Provides a regular expression to match keys of attributes to filter for.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Filtered Attributes</name><displayName>Filtered Attributes</displayName><description>A set of attribute names to filter from FlowFiles. Each attribute name is separated by the comma delimiter ','.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Attribute Matching Strategy</propertyName><propertyDisplayName>Attribute Matching Strategy</propertyDisplayName><dependentValues><dependentValue>Enumerate attributes</dependentValue></dependentValues></dependency></dependencies></property><property><name>Filtered Attributes Pattern</name><displayName>Filtered Attributes Pattern</displayName><description>A regular expression to match names of attributes to filter from FlowFiles.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Attribute Matching Strategy</propertyName><propertyDisplayName>Attribute Matching Strategy</propertyDisplayName><dependentValues><dependentValue>Use regular expression</dependentValue></dependentValues></dependency></dependencies></property></properties><relationships><relationship><name>success</name><description>All successful FlowFiles are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><useCases><useCase><description>Retain all FlowFile attributes matching a regular expression</description><notes></notes><keywords></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>Set "Filter Mode" to "Retain".
Set "Attribute Matching Strategy" to "Use regular expression".
Specify the "Filtered Attributes Pattern", e.g. "my-property|a-prefix[.].*".
</configuration></useCase><useCase><description>Remove only a specified set of FlowFile attributes</description><notes></notes><keywords></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>Set "Filter Mode" to "Remove".
Set "Attribute Matching Strategy" to "Enumerate attributes".
Specify the set of "Filtered Attributes" using the delimiter comma ',', e.g. "my-property,other,filename".
</configuration></useCase></useCases></extension><extension><name>org.apache.nifi.processors.standard.FlattenJson</name><type>PROCESSOR</type><description>Provides the user with the ability to take a nested JSON document and flatten it into a simple key/value pair document. The keys are combined at each level with a user-defined separator that defaults to '.'. This Processor also allows to unflatten back the flattened json. It supports four kinds of flatten mode such as normal, keep-arrays, dot notation for MongoDB query and keep-primitive-arrays. Default flatten mode is 'keep-arrays'.</description><tags><tag>json</tag><tag>flatten</tag><tag>unflatten</tag></tags><properties><property><name>flatten-json-separator</name><displayName>Separator</displayName><description>The separator character used for joining keys. Must be a JSON-legal character.</description><defaultValue>.</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>flatten-mode</name><displayName>Flatten Mode</displayName><description>Specifies how json should be flattened/unflattened</description><defaultValue>keep arrays</defaultValue><allowableValues><allowableValue><displayName>normal</displayName><value>normal</value><description>Flattens every objects into a single level json</description></allowableValue><allowableValue><displayName>keep arrays</displayName><value>keep arrays</value><description>Flattens every objects and keep arrays format</description></allowableValue><allowableValue><displayName>dot notation</displayName><value>dot notation</value><description>Conforms to MongoDB dot notation to update also nested documents</description></allowableValue><allowableValue><displayName>keep primitive arrays</displayName><value>keep primitive arrays</value><description>Flattens every objects except arrays which contain only primitive types (strings, numbers, booleans and null)</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>ignore-reserved-characters</name><displayName>Ignore Reserved Characters</displayName><description>If true, reserved characters in keys will be ignored</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>flatten-json-return-type</name><displayName>Return Type</displayName><description>Specifies the desired return type of json such as flatten/unflatten</description><defaultValue>flatten</defaultValue><allowableValues><allowableValue><displayName>flatten</displayName><value>flatten</value><description></description></allowableValue><allowableValue><displayName>unflatten</displayName><value>unflatten</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>flatten-json-character-set</name><displayName>Character Set</displayName><description>The Character Set in which file is encoded</description><defaultValue>UTF-8</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>flatten-json-pretty-print-json</name><displayName>Pretty Print JSON</displayName><description>Specifies whether or not resulted json should be pretty printed</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>Files that cannot be flattened/unflattened go to this relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>Successfully flattened/unflattened files go to this relationship.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.ForkEnrichment</name><type>PROCESSOR</type><description>Used in conjunction with the JoinEnrichment processor, this processor is responsible for adding the attributes that are necessary for the JoinEnrichment processor to perform its function. Each incoming FlowFile will be cloned. The original FlowFile will have appropriate attributes added and then be transferred to the 'original' relationship. The clone will have appropriate attributes added and then be routed to the 'enrichment' relationship. See the documentation for the JoinEnrichment processor (and especially its Additional Details) for more information on how these Processors work together and how to perform enrichment tasks in NiFi by using these Processors.</description><tags><tag>fork</tag><tag>join</tag><tag>enrich</tag><tag>record</tag></tags><relationships><relationship><name>enrichment</name><description>A clone of the incoming FlowFile will be routed to this relationship, after adding appropriate attributes.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>original</name><description>The incoming FlowFile will be routed to this relationship, after adding appropriate attributes.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>enrichment.group.id</name><description>The Group ID to use in order to correlate the 'original' FlowFile with the 'enrichment' FlowFile.</description></writesAttribute><writesAttribute><name>enrichment.role</name><description>The role to use for enrichment. This will either be ORIGINAL or ENRICHMENT.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.JoinEnrichment</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.ForkRecord</name><type>PROCESSOR</type><description>This processor allows the user to fork a record into multiple records. The user must specify at least one Record Path, as a dynamic property, pointing to a field of type ARRAY containing RECORD objects. The processor accepts two modes: 'split' and 'extract'. In both modes, there is one record generated per element contained in the designated array. In the 'split' mode, each generated record will preserve the same schema as given in the input but the array will contain only one element. In the 'extract' mode, the element of the array must be of record type and will be the generated record. Additionally, in the 'extract' mode, it is possible to specify if each generated record should contain all the fields of the parent records from the root level to the extracted record. This assumes that the fields to add in the record are defined in the schema of the Record Writer controller service. See examples in the additional details documentation of this processor.</description><tags><tag>fork</tag><tag>record</tag><tag>content</tag><tag>array</tag><tag>stream</tag><tag>event</tag></tags><properties><property><name>record-reader</name><displayName>Record Reader</displayName><description>Specifies the Controller Service to use for reading incoming data</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>record-writer</name><displayName>Record Writer</displayName><description>Specifies the Controller Service to use for writing out the records</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>fork-mode</name><displayName>Mode</displayName><description>Specifies the forking mode of the processor</description><defaultValue>split</defaultValue><allowableValues><allowableValue><displayName>Extract</displayName><value>extract</value><description>Generated records will be the elements of the array</description></allowableValue><allowableValue><displayName>Split</displayName><value>split</value><description>Generated records will preserve the input schema and will contain a one-element array</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>include-parent-fields</name><displayName>Include Parent Fields</displayName><description>This parameter is only valid with the 'extract' mode. If set to true, all the fields from the root level to the given array will be added as fields of each element of the array to fork.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>Record Path property</name><value>The Record Path value</value><description>A Record Path value, pointing to a field of type ARRAY containing RECORD objects</description><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>failure</name><description>In case a FlowFile generates an error during the fork operation, it will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>fork</name><description>The FlowFiles containing the forked records will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>original</name><description>The original FlowFiles will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>record.count</name><description>The generated FlowFile will have a 'record.count' attribute indicating the number of records that were written to the FlowFile.</description></writesAttribute><writesAttribute><name>mime.type</name><description>The MIME Type indicated by the Record Writer</description></writesAttribute><writesAttribute><name>&lt;Attributes from Record Writer&gt;</name><description>Any Attribute that the configured Record Writer returns will be added to the FlowFile.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.GenerateFlowFile</name><type>PROCESSOR</type><description>This processor creates FlowFiles with random data or custom content. GenerateFlowFile is useful for load testing, configuration, and simulation. Also see DuplicateFlowFile for additional load testing.</description><tags><tag>test</tag><tag>random</tag><tag>generate</tag><tag>load</tag></tags><properties><property><name>File Size</name><displayName>File Size</displayName><description>The size of the file that will be used</description><defaultValue>0B</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Batch Size</name><displayName>Batch Size</displayName><description>The number of FlowFiles to be transferred in each invocation</description><defaultValue>1</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Data Format</name><displayName>Data Format</displayName><description>Specifies whether the data should be Text or Binary</description><defaultValue>Text</defaultValue><allowableValues><allowableValue><displayName>Binary</displayName><value>Binary</value><description></description></allowableValue><allowableValue><displayName>Text</displayName><value>Text</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Unique FlowFiles</name><displayName>Unique FlowFiles</displayName><description>If true, each FlowFile that is generated will be unique. If false, a random value will be generated and all FlowFiles will get the same content but this offers much higher throughput</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>generate-ff-custom-text</name><displayName>Custom Text</displayName><description>If Data Format is text and if Unique FlowFiles is false, then this custom text will be used as content of the generated FlowFiles and the File Size will be ignored. Finally, if Expression Language is used, evaluation will be performed only once per batch of generated FlowFiles</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>character-set</name><displayName>Character Set</displayName><description>Specifies the character set to use when writing the bytes of Custom Text to a flow file.</description><defaultValue>UTF-8</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>mime-type</name><displayName>Mime Type</displayName><description>Specifies the value to set for the "mime.type" attribute.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>Generated FlowFile attribute name</name><value>Generated FlowFile attribute value</value><description>Specifies an attribute on generated FlowFiles defined by the Dynamic Property's key and value. If Expression Language is used, evaluation will be performed only once per batch of generated FlowFiles.</description><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>success</name><description></description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>mime.type</name><description>Sets the MIME type of the output if the 'Mime Type' property is set</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_FORBIDDEN</inputRequirement><defaultSchedule><strategy>TIMER_DRIVEN</strategy><period>1 min</period><concurrentTasks>1</concurrentTasks></defaultSchedule></extension><extension><name>org.apache.nifi.processors.standard.GenerateRecord</name><type>PROCESSOR</type><description>This processor creates FlowFiles with records having random value for the specified fields. GenerateRecord is useful for testing, configuration, and simulation. It uses either user-defined properties to define a record schema or a provided schema and generates the specified number of records using random data for the fields in the schema.</description><tags><tag>test</tag><tag>random</tag><tag>generate</tag><tag>fake</tag></tags><properties><property><name>record-writer</name><displayName>Record Writer</displayName><description>Specifies the Controller Service to use for writing out the records</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>number-of-records</name><displayName>Number of Records</displayName><description>Specifies how many records will be generated for each outgoing FlowFile.</description><defaultValue>100</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>nullable-fields</name><displayName>Nullable Fields</displayName><description>Whether the generated fields will be nullable. Note that this property is ignored if Schema Text is set. Also it only affects the schema of the generated data, not whether any values will be null. If this property is true, see 'Null Value Percentage' to set the probability that any generated field will be null.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>null-percentage</name><displayName>Null Value Percentage</displayName><description>The percent probability (0-100%) that a generated value for any nullable field will be null. Set this property to zero to have no null values, or 100 to have all null values.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>nullable-fields</propertyName><propertyDisplayName>Nullable Fields</propertyDisplayName><dependentValues><dependentValue>true</dependentValue></dependentValues></dependency></dependencies></property><property><name>schema-text</name><displayName>Schema Text</displayName><description>The text of an Avro-formatted Schema used to generate record data. If this property is set, any user-defined properties are ignored.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>Field name in generated record</name><value>Faker category for generated record values</value><description>Custom properties define the generated record schema using configured field names and value data types in absence of the Schema Text property</description><expressionLanguageScope>NONE</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>success</name><description>FlowFiles that are successfully created will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>mime.type</name><description>Sets the mime.type attribute to the MIME Type specified by the Record Writer</description></writesAttribute><writesAttribute><name>record.count</name><description>The number of records in the FlowFile</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_FORBIDDEN</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.GenerateTableFetch</name><type>PROCESSOR</type><description>Generates SQL select queries that fetch "pages" of rows from a table. The partition size property, along with the table's row count, determine the size and number of pages and generated FlowFiles. In addition, incremental fetching can be achieved by setting Maximum-Value Columns, which causes the processor to track the columns' maximum values, thus only fetching rows whose columns' values exceed the observed maximums. This processor is intended to be run on the Primary Node only.

This processor can accept incoming connections; the behavior of the processor is different whether incoming connections are provided:
  - If no incoming connection(s) are specified, the processor will generate SQL queries on the specified processor schedule. Expression Language is supported for many fields, but no FlowFile attributes are available. However the properties will be evaluated using the Environment/System properties.
  - If incoming connection(s) are specified and no FlowFile is available to a processor task, no work will be performed.
  - If incoming connection(s) are specified and a FlowFile is available to a processor task, the FlowFile's attributes may be used in Expression Language for such fields as Table Name and others. However, the Max-Value Columns and Columns to Return fields must be empty or refer to columns that are available in each specified table.</description><tags><tag>sql</tag><tag>select</tag><tag>jdbc</tag><tag>query</tag><tag>database</tag><tag>fetch</tag><tag>generate</tag></tags><properties><property><name>Database Connection Pooling Service</name><displayName>Database Connection Pooling Service</displayName><description>The Controller Service that is used to obtain a connection to the database.</description><controllerServiceDefinition><className>org.apache.nifi.dbcp.DBCPService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>db-fetch-db-type</name><displayName>Database Type</displayName><description>Database Type for generating statements specific to a particular service or vendor.
The Generic Type supports most cases but selecting a specific type enables optimal processing
or additional features.
</description><defaultValue>Generic</defaultValue><allowableValues><allowableValue><displayName>Database Dialect Service</displayName><value>Database Dialect Service</value><description>Requires configuring a Database Dialect Service for SQL statements</description></allowableValue><allowableValue><displayName>Generic</displayName><value>Generic</value><description>Generates ANSI SQL</description></allowableValue><allowableValue><displayName>Oracle</displayName><value>Oracle</value><description>Generates Oracle compliant SQL</description></allowableValue><allowableValue><displayName>Oracle 12+</displayName><value>Oracle 12+</value><description>Generates Oracle compliant SQL for version 12 or greater</description></allowableValue><allowableValue><displayName>MS SQL 2012+</displayName><value>MS SQL 2012+</value><description>Generates MS SQL Compatible SQL, for version 2012 or greater</description></allowableValue><allowableValue><displayName>MS SQL 2008</displayName><value>MS SQL 2008</value><description>Generates MS SQL Compatible SQL for version 2008</description></allowableValue><allowableValue><displayName>MySQL</displayName><value>MySQL</value><description>Generates MySQL compatible SQL</description></allowableValue><allowableValue><displayName>PostgreSQL</displayName><value>PostgreSQL</value><description>Generates PostgreSQL compatible SQL</description></allowableValue><allowableValue><displayName>Phoenix</displayName><value>Phoenix</value><description>Generates Phoenix compliant SQL</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Database Dialect Service</name><displayName>Database Dialect Service</displayName><description>Database Dialect Service for generating statements specific to a particular service or vendor.</description><controllerServiceDefinition><className>org.apache.nifi.database.dialect.service.api.DatabaseDialectService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>db-fetch-db-type</propertyName><propertyDisplayName>Database Type</propertyDisplayName><dependentValues><dependentValue>Database Dialect Service</dependentValue></dependentValues></dependency></dependencies></property><property><name>Table Name</name><displayName>Table Name</displayName><description>The name of the database table to be queried.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Columns to Return</name><displayName>Columns to Return</displayName><description>A comma-separated list of column names to be used in the query. If your database requires special treatment of the names (quoting, e.g.), each name should include such treatment. If no column names are supplied, all columns in the specified table will be returned. NOTE: It is important to use consistent column names for a given table for incremental fetch to work properly.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum-value Columns</name><displayName>Maximum-value Columns</displayName><description>A comma-separated list of column names. The processor will keep track of the maximum value for each column that has been returned since the processor started running. Using multiple columns implies an order to the column list, and each column's values are expected to increase more slowly than the previous columns' values. Thus, using multiple columns implies a hierarchical structure of columns, which is usually used for partitioning tables. This processor can be used to retrieve only those rows that have been added/updated since the last retrieval. Note that some JDBC types such as bit/boolean are not conducive to maintaining maximum value, so columns of these types should not be listed in this property, and will result in error(s) during processing. If no columns are provided, all rows from the table will be considered, which could have a performance impact. NOTE: It is important to use consistent max-value column names for a given table for incremental fetch to work properly.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Wait Time</name><displayName>Max Wait Time</displayName><description>The maximum amount of time allowed for a running SQL select query , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><defaultValue>0 seconds</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>gen-table-fetch-partition-size</name><displayName>Partition Size</displayName><description>The number of result rows to be fetched by each generated SQL statement. The total number of rows in the table divided by the partition size gives the number of SQL statements (i.e. FlowFiles) generated. A value of zero indicates that a single FlowFile is to be generated whose SQL statement will fetch all rows in the table.</description><defaultValue>10000</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>gen-table-column-for-val-partitioning</name><displayName>Column for Value Partitioning</displayName><description>The name of a column whose values will be used for partitioning. The default behavior is to use row numbers on the result set for partitioning into 'pages' to be fetched from the database, using an offset/limit strategy. However for certain databases, it can be more efficient under the right circumstances to use the column values themselves to define the 'pages'. This property should only be used when the default queries are not performing well, when there is no maximum-value column or a single maximum-value column whose type can be coerced to a long integer (i.e. not date or timestamp), and the column values are evenly distributed and not sparse, for best performance.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>db-fetch-where-clause</name><displayName>Additional WHERE clause</displayName><description>A custom clause to be added in the WHERE condition when building SQL queries.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>gen-table-custom-orderby-column</name><displayName>Custom ORDER BY Column</displayName><description>The name of a column to be used for ordering the results if Max-Value Columns are not provided and partitioning is enabled. This property is ignored if either Max-Value Columns is set or Partition Size = 0. NOTE: If neither Max-Value Columns nor Custom ORDER BY Column is set, then depending on the the database/driver, the processor may report an error and/or the generated SQL may result in missing and/or duplicate rows. This is because without an explicit ordering, fetching each partition is done using an arbitrary ordering.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>gen-table-output-flowfile-on-zero-results</name><displayName>Output Empty FlowFile on Zero Results</displayName><description>Depending on the specified properties, an execution of this processor may not result in any SQL statements generated. When this property is true, an empty FlowFile will be generated (having the parent of the incoming FlowFile if present) and transferred to the 'success' relationship. When this property is false, no output FlowFiles will be generated.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>initial.maxvalue.&lt;max_value_column&gt;</name><value>Initial maximum value for the specified column</value><description>Specifies an initial max value for max value columns. Properties should be added in the format `initial.maxvalue.&lt;max_value_column&gt;`. This value is only used the first time the table is accessed (when a Maximum Value Column is specified). In the case of incoming connections, the value is only used the first time for each table specified in the FlowFiles.</description><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>failure</name><description>This relationship is only used when SQL query execution (using an incoming FlowFile) failed. The incoming FlowFile will be penalized and routed to this relationship. If no incoming connection(s) are specified, this relationship is unused.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>Successfully created FlowFile from SQL query result set.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>generatetablefetch.sql.error</name><description>If the processor has incoming connections, and processing an incoming FlowFile causes a SQL Exception, the FlowFile is routed to failure and this attribute is set to the exception message.</description></writesAttribute><writesAttribute><name>generatetablefetch.tableName</name><description>The name of the database table to be queried.</description></writesAttribute><writesAttribute><name>generatetablefetch.columnNames</name><description>The comma-separated list of column names used in the query.</description></writesAttribute><writesAttribute><name>generatetablefetch.whereClause</name><description>Where clause used in the query to get the expected rows.</description></writesAttribute><writesAttribute><name>generatetablefetch.maxColumnNames</name><description>The comma-separated list of column names used to keep track of data that has been returned since the processor started running.</description></writesAttribute><writesAttribute><name>generatetablefetch.limit</name><description>The number of result rows to be fetched by the SQL statement.</description></writesAttribute><writesAttribute><name>generatetablefetch.offset</name><description>Offset to be used to retrieve the corresponding partition.</description></writesAttribute><writesAttribute><name>fragment.identifier</name><description>All FlowFiles generated from the same query result set will have the same value for the fragment.identifier attribute. This can then be used to correlate the results.</description></writesAttribute><writesAttribute><name>fragment.count</name><description>This is the total number of  FlowFiles produced by a single ResultSet. This can be used in conjunction with the fragment.identifier attribute in order to know how many FlowFiles belonged to the same incoming ResultSet.</description></writesAttribute><writesAttribute><name>fragment.index</name><description>This is the position of this FlowFile in the list of outgoing FlowFiles that were all generated from the same execution. This can be used in conjunction with the fragment.identifier attribute to know which FlowFiles originated from the same execution and in what order  FlowFiles were produced</description></writesAttribute></writesAttributes><triggerSerially>true</triggerSerially><stateful><description>After performing a query on the specified table, the maximum values for the specified column(s) will be retained for use in future executions of the query. This allows the Processor to fetch only those records that have max values greater than the retained values. This can be used for incremental fetching, fetching of newly added rows, etc. To clear the maximum values, clear the state of the processor per the State Management documentation</description><scopes><scope>CLUSTER</scope></scopes></stateful><inputRequirement>INPUT_ALLOWED</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.QueryDatabaseTable</see><see>org.apache.nifi.processors.standard.ExecuteSQL</see><see>org.apache.nifi.processors.standard.ListDatabaseTables</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.GetFTP</name><type>PROCESSOR</type><description>Fetches files from an FTP Server and creates FlowFiles from them</description><tags><tag>FTP</tag><tag>get</tag><tag>retrieve</tag><tag>files</tag><tag>fetch</tag><tag>remote</tag><tag>ingest</tag><tag>source</tag><tag>input</tag></tags><properties><property><name>Hostname</name><displayName>Hostname</displayName><description>The fully qualified hostname or IP address of the remote system</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Port</name><displayName>Port</displayName><description>The port that the remote system is listening on for file transfers</description><defaultValue>21</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Username</name><displayName>Username</displayName><description>Username</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Password</name><displayName>Password</displayName><description>Password for the user account</description><required>false</required><sensitive>true</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Connection Mode</name><displayName>Connection Mode</displayName><description>The FTP Connection Mode</description><defaultValue>Passive</defaultValue><allowableValues><allowableValue><displayName>Active</displayName><value>Active</value><description></description></allowableValue><allowableValue><displayName>Passive</displayName><value>Passive</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Transfer Mode</name><displayName>Transfer Mode</displayName><description>The FTP Transfer Mode</description><defaultValue>Binary</defaultValue><allowableValues><allowableValue><displayName>Binary</displayName><value>Binary</value><description></description></allowableValue><allowableValue><displayName>ASCII</displayName><value>ASCII</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Remote Path</name><displayName>Remote Path</displayName><description>The path on the remote system from which to pull or push files</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>File Filter Regex</name><displayName>File Filter Regex</displayName><description>Provides a Java Regular Expression for filtering Filenames; if a filter is supplied, only files whose names match that Regular Expression will be fetched</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Path Filter Regex</name><displayName>Path Filter Regex</displayName><description>When Search Recursively is true, then only subdirectories whose path matches the given Regular Expression will be scanned</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Polling Interval</name><displayName>Polling Interval</displayName><description>Determines how long to wait between fetching the listing for new files</description><defaultValue>60 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Search Recursively</name><displayName>Search Recursively</displayName><description>If true, will pull files from arbitrarily nested subdirectories; otherwise, will not traverse subdirectories</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>follow-symlink</name><displayName>Follow symlink</displayName><description>If true, will pull even symbolic files and also nested symbolic subdirectories; otherwise, will not read symbolic files and will not traverse symbolic link subdirectories</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Ignore Dotted Files</name><displayName>Ignore Dotted Files</displayName><description>If true, files whose names begin with a dot (".") will be ignored</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Delete Original</name><displayName>Delete Original</displayName><description>Determines whether or not the file is deleted from the remote system after it has been successfully transferred</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Connection Timeout</name><displayName>Connection Timeout</displayName><description>Amount of time to wait before timing out while creating a connection</description><defaultValue>30 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Data Timeout</name><displayName>Data Timeout</displayName><description>When transferring a file between the local and remote system, this value specifies how long is allowed to elapse without any data being transferred between systems</description><defaultValue>30 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Selects</name><displayName>Max Selects</displayName><description>The maximum number of files to pull in a single connection</description><defaultValue>100</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Remote Poll Batch Size</name><displayName>Remote Poll Batch Size</displayName><description>The value specifies how many file paths to find in a given directory on the remote system when doing a file listing. This value in general should not need to be modified but when polling against a remote system with a tremendous number of files this value can be critical.  Setting this value too high can result very poor performance and setting it too low can cause the flow to be slower than normal.</description><defaultValue>5000</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Use Natural Ordering</name><displayName>Use Natural Ordering</displayName><description>If true, will pull files in the order in which they are naturally listed; otherwise, the order in which the files will be pulled is not defined</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>proxy-configuration-service</name><displayName>Proxy Configuration Service</displayName><description>Specifies the Proxy Configuration Controller Service to proxy network requests. Supported proxies: HTTP + AuthN, SOCKS + AuthN</description><controllerServiceDefinition><className>org.apache.nifi.proxy.ProxyConfigurationService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Internal Buffer Size</name><displayName>Internal Buffer Size</displayName><description>Set the internal buffer size for buffered data streams</description><defaultValue>16KB</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>ftp-use-utf8</name><displayName>Use UTF-8 Encoding</displayName><description>Tells the client to use UTF-8 encoding when processing files and filenames. If set to true, the server must also support UTF-8 encoding.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>success</name><description>All FlowFiles that are received are routed to success</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>filename</name><description>The filename is set to the name of the file on the remote server</description></writesAttribute><writesAttribute><name>path</name><description>The path is set to the path of the file's directory on the remote server. For example, if the &lt;Remote Path&gt; property is set to /tmp, files picked up from /tmp will have the path attribute set to /tmp. If the &lt;Search Recursively&gt; property is set to true and a file is picked up from /tmp/abc/1/2/3, then the path attribute will be set to /tmp/abc/1/2/3</description></writesAttribute><writesAttribute><name>file.lastModifiedTime</name><description>The date and time that the source file was last modified</description></writesAttribute><writesAttribute><name>file.lastAccessTime</name><description>The date and time that the file was last accessed. May not work on all file systems</description></writesAttribute><writesAttribute><name>file.owner</name><description>The numeric owner id of the source file</description></writesAttribute><writesAttribute><name>file.group</name><description>The numeric group id of the source file</description></writesAttribute><writesAttribute><name>file.permissions</name><description>The read/write/execute permissions of the source file</description></writesAttribute><writesAttribute><name>absolute.path</name><description>The full/absolute path from where a file was picked up. The current 'path' attribute is still populated, but may be a relative path</description></writesAttribute></writesAttributes><inputRequirement>INPUT_FORBIDDEN</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.PutFTP</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.GetFile</name><type>PROCESSOR</type><description>Creates FlowFiles from files in a directory.  NiFi will ignore files it doesn't have at least read permissions for.</description><tags><tag>local</tag><tag>files</tag><tag>filesystem</tag><tag>ingest</tag><tag>ingress</tag><tag>get</tag><tag>source</tag><tag>input</tag></tags><properties><property><name>Input Directory</name><displayName>Input Directory</displayName><description>The input directory from which to pull files</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>File Filter</name><displayName>File Filter</displayName><description>Only files whose names match the given regular expression will be picked up</description><defaultValue>[^\.].*</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Path Filter</name><displayName>Path Filter</displayName><description>When Recurse Subdirectories is true, then only subdirectories whose path matches the given regular expression will be scanned</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Batch Size</name><displayName>Batch Size</displayName><description>The maximum number of files to pull in each invocation of the processor</description><defaultValue>10</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Keep Source File</name><displayName>Keep Source File</displayName><description>If true, the file is not deleted after it has been copied to the Content Repository; this causes the file to be picked up continually and is useful for testing purposes.  If not keeping original NiFi will need write permissions on the directory it is pulling from otherwise it will ignore the file.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Recurse Subdirectories</name><displayName>Recurse Subdirectories</displayName><description>Indicates whether or not to pull files from subdirectories</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Polling Interval</name><displayName>Polling Interval</displayName><description>Indicates how long to wait before performing a directory listing</description><defaultValue>0 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Ignore Hidden Files</name><displayName>Ignore Hidden Files</displayName><description>Indicates whether or not hidden files should be ignored</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Minimum File Age</name><displayName>Minimum File Age</displayName><description>The minimum age that a file must be in order to be pulled; any file younger than this amount of time (according to last modification date) will be ignored</description><defaultValue>0 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum File Age</name><displayName>Maximum File Age</displayName><description>The maximum age that a file must be in order to be pulled; any file older than this amount of time (according to last modification date) will be ignored</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Minimum File Size</name><displayName>Minimum File Size</displayName><description>The minimum size that a file must be in order to be pulled</description><defaultValue>0 B</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum File Size</name><displayName>Maximum File Size</displayName><description>The maximum size that a file can be in order to be pulled</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>success</name><description>All files are routed to success</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>filename</name><description>The filename is set to the name of the file on disk</description></writesAttribute><writesAttribute><name>path</name><description>The path is set to the relative path of the file's directory on disk. For example, if the &lt;Input Directory&gt; property is set to /tmp, files picked up from /tmp will have the path attribute set to ./. If the &lt;Recurse Subdirectories&gt; property is set to true and a file is picked up from /tmp/abc/1/2/3, then the path attribute will be set to abc/1/2/3</description></writesAttribute><writesAttribute><name>file.creationTime</name><description>The date and time that the file was created. May not work on all file systems</description></writesAttribute><writesAttribute><name>file.lastModifiedTime</name><description>The date and time that the file was last modified. May not work on all file systems</description></writesAttribute><writesAttribute><name>file.lastAccessTime</name><description>The date and time that the file was last accessed. May not work on all file systems</description></writesAttribute><writesAttribute><name>file.owner</name><description>The owner of the file. May not work on all file systems</description></writesAttribute><writesAttribute><name>file.group</name><description>The group owner of the file. May not work on all file systems</description></writesAttribute><writesAttribute><name>file.permissions</name><description>The read/write/execute permissions of the file. May not work on all file systems</description></writesAttribute><writesAttribute><name>absolute.path</name><description>The full/absolute path from where a file was picked up. The current 'path' attribute is still populated, but may be a relative path</description></writesAttribute></writesAttributes><triggerWhenEmpty>true</triggerWhenEmpty><restricted><restrictions><restriction><requiredPermission>read filesystem</requiredPermission><explanation>Provides operator the ability to read from any file that NiFi has access to.</explanation></restriction><restriction><requiredPermission>write filesystem</requiredPermission><explanation>Provides operator the ability to delete any file that NiFi has access to.</explanation></restriction></restrictions></restricted><inputRequirement>INPUT_FORBIDDEN</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.PutFile</see><see>org.apache.nifi.processors.standard.FetchFile</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.GetFileResource</name><type>PROCESSOR</type><description>This processor creates FlowFiles with the content of the configured File Resource. GetFileResource
is useful for load testing, configuration, and simulation.
</description><tags><tag>test</tag><tag>file</tag><tag>generate</tag><tag>load</tag></tags><properties><property><name>File Resource</name><displayName>File Resource</displayName><description>Location of the File Resource (Local File or URL). This file will be used as content of the generated FlowFiles.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType><resourceType>URL</resourceType></resourceTypes></resourceDefinition></property><property><name>MIME Type</name><displayName>MIME Type</displayName><description>Specifies the value to set for the [mime.type] attribute.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>Generated FlowFile attribute name</name><value>Generated FlowFile attribute value</value><description>Specifies an attribute on generated FlowFiles defined by the Dynamic Property's key and value.</description><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>success</name><description></description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>mime.type</name><description>Sets the MIME type of the output if the 'MIME Type' property is set</description></writesAttribute><writesAttribute><name>Dynamic property key</name><description>Value for the corresponding dynamic property, if any is set</description></writesAttribute></writesAttributes><restricted><restrictions><restriction><requiredPermission>read filesystem</requiredPermission><explanation>Provides operator the ability to read from any file that NiFi has access to.</explanation></restriction><restriction><requiredPermission>reference remote resources</requiredPermission><explanation>File Resource can reference resources over HTTP/HTTPS</explanation></restriction></restrictions></restricted><inputRequirement>INPUT_FORBIDDEN</inputRequirement><defaultSchedule><strategy>TIMER_DRIVEN</strategy><period>1 min</period><concurrentTasks>1</concurrentTasks></defaultSchedule></extension><extension><name>org.apache.nifi.processors.standard.GetSFTP</name><type>PROCESSOR</type><description>Fetches files from an SFTP Server and creates FlowFiles from them</description><tags><tag>sftp</tag><tag>get</tag><tag>retrieve</tag><tag>files</tag><tag>fetch</tag><tag>remote</tag><tag>ingest</tag><tag>source</tag><tag>input</tag></tags><properties><property><name>Hostname</name><displayName>Hostname</displayName><description>The fully qualified hostname or IP address of the remote system</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Port</name><displayName>Port</displayName><description>The port that the remote system is listening on for file transfers</description><defaultValue>22</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Username</name><displayName>Username</displayName><description>Username</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Password</name><displayName>Password</displayName><description>Password for the user account</description><required>false</required><sensitive>true</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Private Key Path</name><displayName>Private Key Path</displayName><description>The fully qualified path to the Private Key file</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType></resourceTypes></resourceDefinition></property><property><name>Private Key Passphrase</name><displayName>Private Key Passphrase</displayName><description>Password for the private key</description><required>false</required><sensitive>true</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Remote Path</name><displayName>Remote Path</displayName><description>The path on the remote system from which to pull or push files</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>File Filter Regex</name><displayName>File Filter Regex</displayName><description>Provides a Java Regular Expression for filtering Filenames; if a filter is supplied, only files whose names match that Regular Expression will be fetched</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Path Filter Regex</name><displayName>Path Filter Regex</displayName><description>When Search Recursively is true, then only subdirectories whose path matches the given Regular Expression will be scanned</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Polling Interval</name><displayName>Polling Interval</displayName><description>Determines how long to wait between fetching the listing for new files</description><defaultValue>60 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Search Recursively</name><displayName>Search Recursively</displayName><description>If true, will pull files from arbitrarily nested subdirectories; otherwise, will not traverse subdirectories</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>follow-symlink</name><displayName>Follow symlink</displayName><description>If true, will pull even symbolic files and also nested symbolic subdirectories; otherwise, will not read symbolic files and will not traverse symbolic link subdirectories</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Ignore Dotted Files</name><displayName>Ignore Dotted Files</displayName><description>If true, files whose names begin with a dot (".") will be ignored</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Delete Original</name><displayName>Delete Original</displayName><description>Determines whether or not the file is deleted from the remote system after it has been successfully transferred</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Connection Timeout</name><displayName>Connection Timeout</displayName><description>Amount of time to wait before timing out while creating a connection</description><defaultValue>30 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Data Timeout</name><displayName>Data Timeout</displayName><description>When transferring a file between the local and remote system, this value specifies how long is allowed to elapse without any data being transferred between systems</description><defaultValue>30 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Host Key File</name><displayName>Host Key File</displayName><description>If supplied, the given file will be used as the Host Key; otherwise, if 'Strict Host Key Checking' property is applied (set to true) then uses the 'known_hosts' and 'known_hosts2' files from ~/.ssh directory else no host key file will be used</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType></resourceTypes></resourceDefinition></property><property><name>Max Selects</name><displayName>Max Selects</displayName><description>The maximum number of files to pull in a single connection</description><defaultValue>100</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Remote Poll Batch Size</name><displayName>Remote Poll Batch Size</displayName><description>The value specifies how many file paths to find in a given directory on the remote system when doing a file listing. This value in general should not need to be modified but when polling against a remote system with a tremendous number of files this value can be critical.  Setting this value too high can result very poor performance and setting it too low can cause the flow to be slower than normal.</description><defaultValue>5000</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Strict Host Key Checking</name><displayName>Strict Host Key Checking</displayName><description>Indicates whether or not strict enforcement of hosts keys should be applied</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Send Keep Alive On Timeout</name><displayName>Send Keep Alive On Timeout</displayName><description>Send a Keep Alive message every 5 seconds up to 5 times for an overall timeout of 25 seconds.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Use Compression</name><displayName>Use Compression</displayName><description>Indicates whether or not ZLIB compression should be used when transferring files</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Use Natural Ordering</name><displayName>Use Natural Ordering</displayName><description>If true, will pull files in the order in which they are naturally listed; otherwise, the order in which the files will be pulled is not defined</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>proxy-configuration-service</name><displayName>Proxy Configuration Service</displayName><description>Specifies the Proxy Configuration Controller Service to proxy network requests. Supported proxies: HTTP + AuthN, SOCKS + AuthN</description><controllerServiceDefinition><className>org.apache.nifi.proxy.ProxyConfigurationService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Ciphers Allowed</name><displayName>Ciphers Allowed</displayName><description>A comma-separated list of Ciphers allowed for SFTP connections. Leave unset to allow all. Available options are: 3des-cbc, 3des-ctr, aes128-cbc, aes128-ctr, aes128-gcm@openssh.com, aes192-cbc, aes192-ctr, aes256-cbc, aes256-ctr, aes256-gcm@openssh.com, arcfour, arcfour128, arcfour256, blowfish-cbc, blowfish-ctr, cast128-cbc, cast128-ctr, chacha20-poly1305@openssh.com, idea-cbc, idea-ctr, serpent128-cbc, serpent128-ctr, serpent192-cbc, serpent192-ctr, serpent256-cbc, serpent256-ctr, twofish-cbc, twofish128-cbc, twofish128-ctr, twofish192-cbc, twofish192-ctr, twofish256-cbc, twofish256-ctr</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Key Algorithms Allowed</name><displayName>Key Algorithms Allowed</displayName><description>A comma-separated list of Key Algorithms allowed for SFTP connections. Leave unset to allow all. Available options are: ecdsa-sha2-nistp256, ecdsa-sha2-nistp256-cert-v01@openssh.com, ecdsa-sha2-nistp384, ecdsa-sha2-nistp384-cert-v01@openssh.com, ecdsa-sha2-nistp521, ecdsa-sha2-nistp521-cert-v01@openssh.com, rsa-sha2-256, rsa-sha2-512, ssh-dss, ssh-dss-cert-v01@openssh.com, ssh-ed25519, ssh-ed25519-cert-v01@openssh.com, ssh-rsa, ssh-rsa-cert-v01@openssh.com</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Key Exchange Algorithms Allowed</name><displayName>Key Exchange Algorithms Allowed</displayName><description>A comma-separated list of Key Exchange Algorithms allowed for SFTP connections. Leave unset to allow all. Available options are: curve25519-sha256, curve25519-sha256@libssh.org, diffie-hellman-group-exchange-sha1, diffie-hellman-group-exchange-sha256, diffie-hellman-group1-sha1, diffie-hellman-group14-sha1, diffie-hellman-group14-sha256, diffie-hellman-group14-sha256@ssh.com, diffie-hellman-group15-sha256, diffie-hellman-group15-sha256@ssh.com, diffie-hellman-group15-sha384@ssh.com, diffie-hellman-group15-sha512, diffie-hellman-group16-sha256, diffie-hellman-group16-sha384@ssh.com, diffie-hellman-group16-sha512, diffie-hellman-group16-sha512@ssh.com, diffie-hellman-group17-sha512, diffie-hellman-group18-sha512, diffie-hellman-group18-sha512@ssh.com, ecdh-sha2-nistp256, ecdh-sha2-nistp384, ecdh-sha2-nistp521, ext-info-c</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Message Authentication Codes Allowed</name><displayName>Message Authentication Codes Allowed</displayName><description>A comma-separated list of Message Authentication Codes allowed for SFTP connections. Leave unset to allow all. Available options are: hmac-md5, hmac-md5-96, hmac-md5-96-etm@openssh.com, hmac-md5-etm@openssh.com, hmac-ripemd160, hmac-ripemd160-96, hmac-ripemd160-etm@openssh.com, hmac-ripemd160@openssh.com, hmac-sha1, hmac-sha1-96, hmac-sha1-96@openssh.com, hmac-sha1-etm@openssh.com, hmac-sha2-256, hmac-sha2-256-etm@openssh.com, hmac-sha2-512, hmac-sha2-512-etm@openssh.com</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>success</name><description>All FlowFiles that are received are routed to success</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>filename</name><description>The filename is set to the name of the file on the remote server</description></writesAttribute><writesAttribute><name>path</name><description>The path is set to the path of the file's directory on the remote server. For example, if the &lt;Remote Path&gt; property is set to /tmp, files picked up from /tmp will have the path attribute set to /tmp. If the &lt;Search Recursively&gt; property is set to true and a file is picked up from /tmp/abc/1/2/3, then the path attribute will be set to /tmp/abc/1/2/3</description></writesAttribute><writesAttribute><name>file.lastModifiedTime</name><description>The date and time that the source file was last modified</description></writesAttribute><writesAttribute><name>file.owner</name><description>The numeric owner id of the source file</description></writesAttribute><writesAttribute><name>file.group</name><description>The numeric group id of the source file</description></writesAttribute><writesAttribute><name>file.permissions</name><description>The read/write/execute permissions of the source file</description></writesAttribute><writesAttribute><name>absolute.path</name><description>The full/absolute path from where a file was picked up. The current 'path' attribute is still populated, but may be a relative path</description></writesAttribute></writesAttributes><inputRequirement>INPUT_FORBIDDEN</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.PutSFTP</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.HandleHttpRequest</name><type>PROCESSOR</type><description>Starts an HTTP Server and listens for HTTP Requests. For each request, creates a FlowFile and transfers to 'success'. This Processor is designed to be used in conjunction with the HandleHttpResponse Processor in order to create a Web Service. In case  of a multipart request, one FlowFile is generated for each part.</description><tags><tag>http</tag><tag>https</tag><tag>request</tag><tag>listen</tag><tag>ingress</tag><tag>web service</tag></tags><properties><property><name>Listening Port</name><displayName>Listening Port</displayName><description>The Port to listen on for incoming HTTP requests</description><defaultValue>80</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Hostname</name><displayName>Hostname</displayName><description>The Hostname to bind to. If not specified, will bind to all hosts</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>SSL Context Service</name><displayName>SSL Context Service</displayName><description>The SSL Context Service to use in order to secure the server. If specified, the server will accept only HTTPS requests; otherwise, the server will accept only HTTP requests</description><controllerServiceDefinition><className>org.apache.nifi.ssl.RestrictedSSLContextService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>HTTP Protocols</name><displayName>HTTP Protocols</displayName><description>HTTP Protocols supported for Application Layer Protocol Negotiation with TLS</description><defaultValue>HTTP_1_1</defaultValue><allowableValues><allowableValue><displayName>http/1.1</displayName><value>HTTP_1_1</value><description>HTTP/1.1</description></allowableValue><allowableValue><displayName>h2 http/1.1</displayName><value>H2_HTTP_1_1</value><description>HTTP/2 and HTTP/1.1 negotiated based on requested protocols</description></allowableValue><allowableValue><displayName>h2</displayName><value>H2</value><description>HTTP/2</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>SSL Context Service</propertyName><propertyDisplayName>SSL Context Service</propertyDisplayName></dependency></dependencies></property><property><name>HTTP Context Map</name><displayName>HTTP Context Map</displayName><description>The HTTP Context Map Controller Service to use for caching the HTTP Request Information</description><controllerServiceDefinition><className>org.apache.nifi.http.HttpContextMap</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Allowed Paths</name><displayName>Allowed Paths</displayName><description>A Regular Expression that specifies the valid HTTP Paths that are allowed in the incoming URL Requests. If this value is specified and the path of the HTTP Requests does not match this Regular Expression, the Processor will respond with a 404: NotFound</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Default URL Character Set</name><displayName>Default URL Character Set</displayName><description>The character set to use for decoding URL parameters if the HTTP Request does not supply one</description><defaultValue>UTF-8</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Allow GET</name><displayName>Allow GET</displayName><description>Allow HTTP GET Method</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Allow POST</name><displayName>Allow POST</displayName><description>Allow HTTP POST Method</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Allow PUT</name><displayName>Allow PUT</displayName><description>Allow HTTP PUT Method</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Allow DELETE</name><displayName>Allow DELETE</displayName><description>Allow HTTP DELETE Method</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Allow HEAD</name><displayName>Allow HEAD</displayName><description>Allow HTTP HEAD Method</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Allow OPTIONS</name><displayName>Allow OPTIONS</displayName><description>Allow HTTP OPTIONS Method</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum Threads</name><displayName>Maximum Threads</displayName><description>The maximum number of threads that the embedded HTTP server will use for handling requests.</description><defaultValue>200</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Request Header Maximum Size</name><displayName>Request Header Maximum Size</displayName><description>The maximum supported size of HTTP headers in requests sent to this processor</description><defaultValue>8 KB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Additional HTTP Methods</name><displayName>Additional HTTP Methods</displayName><description>A comma-separated list of non-standard HTTP Methods that should be allowed</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Client Authentication</name><displayName>Client Authentication</displayName><description>Specifies whether or not the Processor should authenticate clients. This value is ignored if the &lt;SSL Context Service&gt; Property is not specified or the SSL Context provided uses only a KeyStore and not a TrustStore.</description><defaultValue>No Authentication</defaultValue><allowableValues><allowableValue><displayName>No Authentication</displayName><value>No Authentication</value><description>Processor will not authenticate clients. Anyone can communicate with this Processor anonymously</description></allowableValue><allowableValue><displayName>Want Authentication</displayName><value>Want Authentication</value><description>Processor will try to verify the client but if unable to verify will allow the client to communicate anonymously</description></allowableValue><allowableValue><displayName>Need Authentication</displayName><value>Need Authentication</value><description>Processor will reject communications from any client unless the client provides a certificate that is trusted by the TrustStorespecified in the SSL Context Service</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>container-queue-size</name><displayName>Container Queue Size</displayName><description>The size of the queue for Http Request Containers</description><defaultValue>50</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>multipart-request-max-size</name><displayName>Multipart Request Max Size</displayName><description>The max size of the request. Only applies for requests with Content-Type: multipart/form-data, and is used to prevent denial of service type of attacks, to prevent filling up the heap or disk space</description><defaultValue>1 MB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>multipart-read-buffer-size</name><displayName>Multipart Read Buffer Size</displayName><description>The threshold size, at which the contents of an incoming file would be written to disk. Only applies for requests with Content-Type: multipart/form-data. It is used to prevent denial of service type of attacks, to prevent filling up the heap or disk space.</description><defaultValue>512 KB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>parameters-to-attributes</name><displayName>Parameters to Attributes List</displayName><description>A comma-separated list of HTTP parameters or form data to output as attributes</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>success</name><description>All content that is received is routed to the 'success' relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>http.context.identifier</name><description>An identifier that allows the HandleHttpRequest and HandleHttpResponse to coordinate which FlowFile belongs to which HTTP Request/Response.</description></writesAttribute><writesAttribute><name>mime.type</name><description>The MIME Type of the data, according to the HTTP Header "Content-Type"</description></writesAttribute><writesAttribute><name>http.servlet.path</name><description>The part of the request URL that is considered the Servlet Path</description></writesAttribute><writesAttribute><name>http.context.path</name><description>The part of the request URL that is considered to be the Context Path</description></writesAttribute><writesAttribute><name>http.method</name><description>The HTTP Method that was used for the request, such as GET or POST</description></writesAttribute><writesAttribute><name>http.local.name</name><description>IP address/hostname of the server</description></writesAttribute><writesAttribute><name>http.server.port</name><description>Listening port of the server</description></writesAttribute><writesAttribute><name>http.query.string</name><description>The query string portion of the Request URL</description></writesAttribute><writesAttribute><name>http.remote.host</name><description>The hostname of the requestor</description></writesAttribute><writesAttribute><name>http.remote.addr</name><description>The hostname:port combination of the requestor</description></writesAttribute><writesAttribute><name>http.remote.user</name><description>The username of the requestor</description></writesAttribute><writesAttribute><name>http.protocol</name><description>The protocol used to communicate</description></writesAttribute><writesAttribute><name>http.request.uri</name><description>The full Request URL</description></writesAttribute><writesAttribute><name>http.auth.type</name><description>The type of HTTP Authorization used</description></writesAttribute><writesAttribute><name>http.principal.name</name><description>The name of the authenticated user making the request</description></writesAttribute><writesAttribute><name>http.query.param.XXX</name><description>Each of query parameters in the request will be added as an attribute, prefixed with "http.query.param."</description></writesAttribute><writesAttribute><name>http.param.XXX</name><description>Form parameters in the request that are configured by "Parameters to Attributes List" will be added as an attribute, prefixed with "http.param.". Putting form parameters of large size is not recommended.</description></writesAttribute><writesAttribute><name>http.subject.dn</name><description>The Distinguished Name of the requestor. This value will not be populated unless the Processor is configured to use an SSLContext Service</description></writesAttribute><writesAttribute><name>http.issuer.dn</name><description>The Distinguished Name of the entity that issued the Subject's certificate. This value will not be populated unless the Processor is configured to use an SSLContext Service</description></writesAttribute><writesAttribute><name>http.certificate.sans.N.name</name><description>X.509 Client Certificate Subject Alternative Name value from mutual TLS authentication. The attribute name has a zero-based index ordered according to the content of Client Certificate</description></writesAttribute><writesAttribute><name>http.certificate.sans.N.nameType</name><description>X.509 Client Certificate Subject Alternative Name type from mutual TLS authentication. The attribute name has a zero-based index ordered according to the content of Client Certificate. The attribute value is one of the General Names from RFC 3280 Section 4.1.2.7</description></writesAttribute><writesAttribute><name>http.headers.XXX</name><description>Each of the HTTP Headers that is received in the request will be added as an attribute, prefixed with "http.headers." For example, if the request contains an HTTP Header named "x-my-header", then the value will be added to an attribute named "http.headers.x-my-header"</description></writesAttribute><writesAttribute><name>http.headers.multipart.XXX</name><description>Each of the HTTP Headers that is received in the multipart request will be added as an attribute, prefixed with "http.headers.multipart." For example, if the multipart request contains an HTTP Header named "content-disposition", then the value will be added to an attribute named "http.headers.multipart.content-disposition"</description></writesAttribute><writesAttribute><name>http.multipart.size</name><description>For requests with Content-Type "multipart/form-data", the part's content size is recorded into this attribute</description></writesAttribute><writesAttribute><name>http.multipart.content.type</name><description>For requests with Content-Type "multipart/form-data", the part's content type is recorded into this attribute</description></writesAttribute><writesAttribute><name>http.multipart.name</name><description>For requests with Content-Type "multipart/form-data", the part's name is recorded into this attribute</description></writesAttribute><writesAttribute><name>http.multipart.filename</name><description>For requests with Content-Type "multipart/form-data", when the part contains an uploaded file, the name of the file is recorded into this attribute. Files are stored temporarily at the default temporary-file directory specified in "java.io.File" Java Docs)</description></writesAttribute><writesAttribute><name>http.multipart.fragments.sequence.number</name><description>For requests with Content-Type "multipart/form-data", the part's index is recorded into this attribute. The index starts with 1.</description></writesAttribute><writesAttribute><name>http.multipart.fragments.total.number</name><description>For requests with Content-Type "multipart/form-data", the count of all parts is recorded into this attribute.</description></writesAttribute></writesAttributes><inputRequirement>INPUT_FORBIDDEN</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.HandleHttpResponse</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.HandleHttpResponse</name><type>PROCESSOR</type><description>Sends an HTTP Response to the Requestor that generated a FlowFile. This Processor is designed to be used in conjunction with the HandleHttpRequest in order to create a web service.</description><tags><tag>http</tag><tag>https</tag><tag>response</tag><tag>egress</tag><tag>web service</tag></tags><properties><property><name>HTTP Status Code</name><displayName>HTTP Status Code</displayName><description>The HTTP Status Code to use when responding to the HTTP Request. See Section 10 of RFC 2616 for more information.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>HTTP Context Map</name><displayName>HTTP Context Map</displayName><description>The HTTP Context Map Controller Service to use for caching the HTTP Request Information</description><controllerServiceDefinition><className>org.apache.nifi.http.HttpContextMap</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Attributes to add to the HTTP Response (Regex)</name><displayName>Attributes to add to the HTTP Response (Regex)</displayName><description>Specifies the Regular Expression that determines the names of FlowFile attributes that should be added to the HTTP response</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>An HTTP header name</name><value>An HTTP header value</value><description>These HTTPHeaders are set in the HTTP Response</description><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>failure</name><description>FlowFiles will be routed to this Relationship if the Processor is unable to respond to the requestor. This may happen, for instance, if the connection times out or if NiFi is restarted before responding to the HTTP Request.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>FlowFiles will be routed to this Relationship after the response has been successfully sent to the requestor</description><autoTerminated>false</autoTerminated></relationship></relationships><readsAttributes><readsAttribute><name>http.context.identifier</name><description>The value of this attribute is used to lookup the HTTP Response so that the proper message can be sent back to the requestor. If this attribute is missing, the FlowFile will be routed to 'failure.'</description></readsAttribute><readsAttribute><name>http.request.uri</name><description>Value of the URI requested by the client. Used for provenance event.</description></readsAttribute><readsAttribute><name>http.remote.host</name><description>IP address of the client. Used for provenance event.</description></readsAttribute><readsAttribute><name>http.local.name</name><description>IP address/hostname of the server. Used for provenance event.</description></readsAttribute><readsAttribute><name>http.server.port</name><description>Listening port of the server. Used for provenance event.</description></readsAttribute><readsAttribute><name>http.subject.dn</name><description>SSL distinguished name (if any). Used for provenance event.</description></readsAttribute></readsAttributes><writesAttributes></writesAttributes><inputRequirement>INPUT_REQUIRED</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.HandleHttpRequest</see><see>org.apache.nifi.http.StandardHttpContextMap</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.IdentifyMimeType</name><type>PROCESSOR</type><description>Attempts to identify the MIME Type used for a FlowFile. If the MIME Type can be identified, an attribute with the name 'mime.type' is added with the value being the MIME Type. If the MIME Type cannot be determined, the value will be set to 'application/octet-stream'. In addition, the attribute 'mime.extension' will be set if a common file extension for the MIME Type is known. If the MIME Type detected is of type text/*, attempts to identify the charset used and an attribute with the name 'mime.charset' is added with the value being the charset.</description><tags><tag>compression</tag><tag>gzip</tag><tag>bzip2</tag><tag>zip</tag><tag>MIME</tag><tag>mime.type</tag><tag>file</tag><tag>identify</tag></tags><properties><property><name>use-filename-in-detection</name><displayName>Use Filename In Detection</displayName><description>If true will pass the filename to Tika to aid in detection.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>config-strategy</name><displayName>Config Strategy</displayName><description>Select the loading strategy for MIME Type configuration to be used.</description><defaultValue>Preset</defaultValue><allowableValues><allowableValue><displayName>Preset</displayName><value>Preset</value><description>Use default NiFi MIME Types.</description></allowableValue><allowableValue><displayName>Replace</displayName><value>Replace</value><description>Use custom MIME types configuration only.</description></allowableValue><allowableValue><displayName>Merge</displayName><value>Merge</value><description>Use custom MIME types configuration together with default NiFi MIME types.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Custom MIME Configuration</name><displayName>Custom MIME Configuration</displayName><description>A URL or file path to a custom Tika Mime type configuration or the actual content of a custom Tika Mime type configuration.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType><resourceType>TEXT</resourceType><resourceType>URL</resourceType></resourceTypes></resourceDefinition><dependencies><dependency><propertyName>config-strategy</propertyName><propertyDisplayName>Config Strategy</propertyDisplayName><dependentValues><dependentValue>Merge</dependentValue><dependentValue>Replace</dependentValue></dependentValues></dependency></dependencies></property></properties><relationships><relationship><name>success</name><description>All FlowFiles are routed to success</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>mime.type</name><description>This Processor sets the FlowFile's mime.type attribute to the detected MIME Type. If unable to detect the MIME Type, the attribute's value will be set to application/octet-stream</description></writesAttribute><writesAttribute><name>mime.extension</name><description>This Processor sets the FlowFile's mime.extension attribute to the file extension associated with the detected MIME Type. If there is no correlated extension, the attribute's value will be empty</description></writesAttribute><writesAttribute><name>mime.charset</name><description>This Processor sets the FlowFile's mime.charset attribute to the detected charset. If unable to detect the charset or the detected MIME type is not of type text/*, the attribute will not be set</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.InvokeHTTP</name><type>PROCESSOR</type><description>An HTTP client processor which can interact with a configurable HTTP Endpoint. The destination URL and HTTP Method are configurable. When the HTTP Method is PUT, POST or PATCH, the FlowFile contents are included as the body of the request and FlowFile attributes are converted to HTTP headers, optionally, based on configuration properties.</description><tags><tag>http</tag><tag>https</tag><tag>rest</tag><tag>client</tag></tags><properties><property><name>HTTP Method</name><displayName>HTTP Method</displayName><description>HTTP request method (GET, POST, PUT, PATCH, DELETE, HEAD, OPTIONS). Arbitrary methods are also supported. Methods other than POST, PUT and PATCH will be sent without a message body.</description><defaultValue>GET</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>HTTP URL</name><displayName>HTTP URL</displayName><description>HTTP remote URL including a scheme of http or https, as well as a hostname or IP address with optional port and path elements. Any encoding of the URL must be done by the user.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>HTTP/2 Disabled</name><displayName>HTTP/2 Disabled</displayName><description>Disable negotiation of HTTP/2 protocol. HTTP/2 requires TLS. HTTP/1.1 protocol supported is required when HTTP/2 is disabled.</description><defaultValue>False</defaultValue><allowableValues><allowableValue><displayName>True</displayName><value>True</value><description></description></allowableValue><allowableValue><displayName>False</displayName><value>False</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>SSL Context Service</name><displayName>SSL Context Service</displayName><description>SSL Context Service provides trusted certificates and client certificates for TLS communication.</description><controllerServiceDefinition><className>org.apache.nifi.ssl.SSLContextProvider</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Connection Timeout</name><displayName>Connection Timeout</displayName><description>Maximum time to wait for initial socket connection to the HTTP URL.</description><defaultValue>5 secs</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Socket Read Timeout</name><displayName>Socket Read Timeout</displayName><description>Maximum time to wait for receiving responses from a socket connection to the HTTP URL.</description><defaultValue>15 secs</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Socket Write Timeout</name><displayName>Socket Write Timeout</displayName><description>Maximum time to wait for write operations while sending requests from a socket connection to the HTTP URL.</description><defaultValue>15 secs</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Socket Idle Timeout</name><displayName>Socket Idle Timeout</displayName><description>Maximum time to wait before closing idle connections to the HTTP URL.</description><defaultValue>5 mins</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Socket Idle Connections</name><displayName>Socket Idle Connections</displayName><description>Maximum number of idle connections to the HTTP URL.</description><defaultValue>5</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>proxy-configuration-service</name><displayName>Proxy Configuration Service</displayName><description>Specifies the Proxy Configuration Controller Service to proxy network requests. Supported proxies: HTTP + AuthN, SOCKS In case of SOCKS, it is not guaranteed that the selected SOCKS Version will be used by the processor.</description><controllerServiceDefinition><className>org.apache.nifi.proxy.ProxyConfigurationService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Request OAuth2 Access Token Provider</name><displayName>Request OAuth2 Access Token Provider</displayName><description>Enables managed retrieval of OAuth2 Bearer Token applied to HTTP requests using the Authorization Header.</description><controllerServiceDefinition><className>org.apache.nifi.oauth2.OAuth2AccessTokenProvider</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>OAuth2 Access Token Refresh Strategy</name><displayName>OAuth2 Access Token Refresh Strategy</displayName><description>Specifies which strategy should be used to refresh the OAuth2 Access Token.</description><defaultValue>ON_TOKEN_EXPIRATION</defaultValue><allowableValues><allowableValue><displayName>ON_TOKEN_EXPIRATION</displayName><value>ON_TOKEN_EXPIRATION</value><description>The token will be refreshed based on its expiration time and the configured refresh window</description></allowableValue><allowableValue><displayName>ON_UNAUTHORIZED_RESPONSE</displayName><value>ON_UNAUTHORIZED_RESPONSE</value><description>A new token will be requested in case of a non-authorized request (HTTP 401) even if the current token has not expired</description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Request OAuth2 Access Token Provider</propertyName><propertyDisplayName>Request OAuth2 Access Token Provider</propertyDisplayName></dependency></dependencies></property><property><name>Request Username</name><displayName>Request Username</displayName><description>The username provided for authentication of HTTP requests. Encoded using Base64 for HTTP Basic Authentication as described in RFC 7617.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Request Password</name><displayName>Request Password</displayName><description>The password provided for authentication of HTTP requests. Encoded using Base64 for HTTP Basic Authentication as described in RFC 7617.</description><required>false</required><sensitive>true</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Request Digest Authentication Enabled</name><displayName>Request Digest Authentication Enabled</displayName><description>Enable Digest Authentication on HTTP requests with Username and Password credentials as described in RFC 7616.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Request Username</propertyName><propertyDisplayName>Request Username</propertyDisplayName></dependency></dependencies></property><property><name>Request Failure Penalization Enabled</name><displayName>Request Failure Penalization Enabled</displayName><description>Enable penalization of request FlowFiles when receiving HTTP response with a status code between 400 and 499.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Request Body Enabled</name><displayName>Request Body Enabled</displayName><description>Enable sending HTTP request body for PATCH, POST, or PUT methods.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>HTTP Method</propertyName><propertyDisplayName>HTTP Method</propertyDisplayName><dependentValues><dependentValue>PATCH</dependentValue><dependentValue>POST</dependentValue><dependentValue>PUT</dependentValue></dependentValues></dependency></dependencies></property><property><name>Request Multipart Form-Data Name</name><displayName>Request Multipart Form-Data Name</displayName><description>Enable sending HTTP request body formatted using multipart/form-data and using the form name configured.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Request Body Enabled</propertyName><propertyDisplayName>Request Body Enabled</propertyDisplayName><dependentValues><dependentValue>true</dependentValue></dependentValues></dependency></dependencies></property><property><name>Request Multipart Form-Data Filename Enabled</name><displayName>Request Multipart Form-Data Filename Enabled</displayName><description>Enable sending the FlowFile filename attribute as the filename parameter in the Content-Disposition Header for multipart/form-data HTTP requests.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Request Multipart Form-Data Name</propertyName><propertyDisplayName>Request Multipart Form-Data Name</propertyDisplayName></dependency></dependencies></property><property><name>Request Chunked Transfer-Encoding Enabled</name><displayName>Request Chunked Transfer-Encoding Enabled</displayName><description>Enable sending HTTP requests with the Transfer-Encoding Header set to chunked, and disable sending the Content-Length Header. Transfer-Encoding applies to the body in HTTP/1.1 requests as described in RFC 7230 Section 3.3.1</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>HTTP Method</propertyName><propertyDisplayName>HTTP Method</propertyDisplayName><dependentValues><dependentValue>PATCH</dependentValue><dependentValue>POST</dependentValue><dependentValue>PUT</dependentValue></dependentValues></dependency></dependencies></property><property><name>Request Content-Encoding</name><displayName>Request Content-Encoding</displayName><description>HTTP Content-Encoding applied to request body during transmission. The receiving server must support the selected encoding to avoid request failures.</description><defaultValue>DISABLED</defaultValue><allowableValues><allowableValue><displayName>DISABLED</displayName><value>DISABLED</value><description>Content encoding not applied during transmission</description></allowableValue><allowableValue><displayName>GZIP</displayName><value>GZIP</value><description>Gzip content encoding and HTTP Content-Encoding header applied during transmission</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>HTTP Method</propertyName><propertyDisplayName>HTTP Method</propertyDisplayName><dependentValues><dependentValue>PATCH</dependentValue><dependentValue>POST</dependentValue><dependentValue>PUT</dependentValue></dependentValues></dependency></dependencies></property><property><name>Request Content-Type</name><displayName>Request Content-Type</displayName><description>HTTP Content-Type Header applied to when sending an HTTP request body for PATCH, POST, or PUT methods. The Content-Type defaults to application/octet-stream when not configured.</description><defaultValue>${mime.type}</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>HTTP Method</propertyName><propertyDisplayName>HTTP Method</propertyDisplayName><dependentValues><dependentValue>PATCH</dependentValue><dependentValue>POST</dependentValue><dependentValue>PUT</dependentValue></dependentValues></dependency></dependencies></property><property><name>Request Date Header Enabled</name><displayName>Request Date Header Enabled</displayName><description>Enable sending HTTP Date Header on HTTP requests as described in RFC 7231 Section 7.1.1.2.</description><defaultValue>True</defaultValue><allowableValues><allowableValue><displayName>True</displayName><value>True</value><description></description></allowableValue><allowableValue><displayName>False</displayName><value>False</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Request Header Attributes Pattern</name><displayName>Request Header Attributes Pattern</displayName><description>Regular expression that defines which FlowFile attributes to send as HTTP headers in the request. If not defined, no attributes are sent as headers. Dynamic properties will be always be sent as headers. The dynamic property name will be the header key and the dynamic property value, interpreted as Expression Language, will be the header value. Attributes and their values are limited to ASCII characters due to the requirement of the HTTP protocol.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Request User-Agent</name><displayName>Request User-Agent</displayName><description>HTTP User-Agent Header applied to requests. RFC 7231 Section 5.5.3 describes recommend formatting.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Response Body Attribute Name</name><displayName>Response Body Attribute Name</displayName><description>FlowFile attribute name used to write an HTTP response body for FlowFiles transferred to the Original relationship.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Response Body Attribute Size</name><displayName>Response Body Attribute Size</displayName><description>Maximum size in bytes applied when writing an HTTP response body to a FlowFile attribute. Attributes exceeding the maximum will be truncated.</description><defaultValue>256</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Response Body Attribute Name</propertyName><propertyDisplayName>Response Body Attribute Name</propertyDisplayName></dependency></dependencies></property><property><name>Response Body Ignored</name><displayName>Response Body Ignored</displayName><description>Disable writing HTTP response FlowFiles to Response relationship</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Response Cache Enabled</name><displayName>Response Cache Enabled</displayName><description>Enable HTTP response caching described in RFC 7234. Caching responses considers ETag and other headers.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Response Cache Size</name><displayName>Response Cache Size</displayName><description>Maximum size of HTTP response cache in bytes. Caching responses considers ETag and other headers.</description><defaultValue>10MB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Response Cache Enabled</propertyName><propertyDisplayName>Response Cache Enabled</propertyDisplayName><dependentValues><dependentValue>true</dependentValue></dependentValues></dependency></dependencies></property><property><name>Response Cookie Strategy</name><displayName>Response Cookie Strategy</displayName><description>Strategy for accepting and persisting HTTP cookies. Accepting cookies enables persistence across multiple requests.</description><defaultValue>DISABLED</defaultValue><allowableValues><allowableValue><displayName>DISABLED</displayName><value>DISABLED</value><description></description></allowableValue><allowableValue><displayName>ACCEPT_ALL</displayName><value>ACCEPT_ALL</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Response Generation Required</name><displayName>Response Generation Required</displayName><description>Enable generation and transfer of a FlowFile to the Response relationship regardless of HTTP response received.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Response FlowFile Naming Strategy</name><displayName>Response FlowFile Naming Strategy</displayName><description>Determines the strategy used for setting the filename attribute of FlowFiles transferred to the Response relationship.</description><defaultValue>RANDOM</defaultValue><allowableValues><allowableValue><displayName>RANDOM</displayName><value>RANDOM</value><description>FlowFile filename attribute will be a random value.</description></allowableValue><allowableValue><displayName>URL_PATH</displayName><value>URL_PATH</value><description>FlowFile filename attribute will be extracted from the remote URL path. The attribute may contain URL encoded characters. If the path doesn't exist, the attribute will be a random value.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Response Header Request Attributes Enabled</name><displayName>Response Header Request Attributes Enabled</displayName><description>Enable adding HTTP response headers as attributes to FlowFiles transferred to the Original, Retry or No Retry relationships.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Response Header Request Attributes Prefix</name><displayName>Response Header Request Attributes Prefix</displayName><description>Prefix to HTTP response headers when included as attributes to FlowFiles transferred to the Original, Retry or No Retry relationships.  It is recommended to end with a separator character like '.' or '-'.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Response Header Request Attributes Enabled</propertyName><propertyDisplayName>Response Header Request Attributes Enabled</propertyDisplayName><dependentValues><dependentValue>true</dependentValue></dependentValues></dependency></dependencies></property><property><name>Response Redirects Enabled</name><displayName>Response Redirects Enabled</displayName><description>Enable following HTTP redirects sent with HTTP 300 series responses as described in RFC 7231 Section 6.4.</description><defaultValue>True</defaultValue><allowableValues><allowableValue><displayName>True</displayName><value>True</value><description></description></allowableValue><allowableValue><displayName>False</displayName><value>False</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>Header Name</name><value>Attribute Expression Language</value><description>Send request header with a key matching the Dynamic Property Key and a value created by evaluating the Attribute Expression Language set in the value of the Dynamic Property.</description><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope></dynamicProperty><dynamicProperty><name>post:form:&lt;NAME&gt;</name><value>Attribute Expression Language</value><description>When the HTTP Method is POST, dynamic properties with the property name in the form of post:form:&lt;NAME&gt;, where the &lt;NAME&gt; will be the form data name, will be used to fill out the multipart form parts.  If send message body is false, the flowfile will not be sent, but any other form data will be.</description><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope></dynamicProperty></dynamicProperties><supportsSensitiveDynamicProperties>true</supportsSensitiveDynamicProperties><relationships><relationship><name>Failure</name><description>Request FlowFiles transferred when receiving socket communication errors.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>No Retry</name><description>Request FlowFiles transferred when receiving HTTP responses with a status code between 400 an 499.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>Original</name><description>Request FlowFiles transferred when receiving HTTP responses with a status code between 200 and 299.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>Response</name><description>Response FlowFiles transferred when receiving HTTP responses with a status code between 200 and 299.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>Retry</name><description>Request FlowFiles transferred when receiving HTTP responses with a status code between 500 and 599.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>invokehttp.status.code</name><description>The status code that is returned</description></writesAttribute><writesAttribute><name>invokehttp.status.message</name><description>The status message that is returned</description></writesAttribute><writesAttribute><name>invokehttp.response.body</name><description>In the instance where the status code received is not a success (2xx) then the response body will be put to the 'invokehttp.response.body' attribute of the request FlowFile.</description></writesAttribute><writesAttribute><name>invokehttp.request.url</name><description>The original request URL</description></writesAttribute><writesAttribute><name>invokehttp.request.duration</name><description>Duration (in milliseconds) of the HTTP call to the external endpoint</description></writesAttribute><writesAttribute><name>invokehttp.response.url</name><description>The URL that was ultimately requested after any redirects were followed</description></writesAttribute><writesAttribute><name>invokehttp.tx.id</name><description>The transaction ID that is returned after reading the response</description></writesAttribute><writesAttribute><name>invokehttp.remote.dn</name><description>The DN of the remote server</description></writesAttribute><writesAttribute><name>invokehttp.java.exception.class</name><description>The Java exception class raised when the processor fails</description></writesAttribute><writesAttribute><name>invokehttp.java.exception.message</name><description>The Java exception message raised when the processor fails</description></writesAttribute><writesAttribute><name>user-defined</name><description>If the 'Put Response Body In Attribute' property is set then whatever it is set to will become the attribute key and the value would be the body of the HTTP response.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_ALLOWED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.JoinEnrichment</name><type>PROCESSOR</type><description>Joins together Records from two different FlowFiles where one FlowFile, the 'original' contains arbitrary records and the second FlowFile, the 'enrichment' contains additional data that should be used to enrich the first. See Additional Details for more information on how to configure this processor and the different use cases that it aims to accomplish.</description><tags><tag>fork</tag><tag>join</tag><tag>enrichment</tag><tag>record</tag><tag>sql</tag><tag>wrap</tag><tag>recordpath</tag><tag>merge</tag><tag>combine</tag><tag>streams</tag></tags><properties><property><name>Original Record Reader</name><displayName>Original Record Reader</displayName><description>The Record Reader for reading the 'original' FlowFile</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Enrichment Record Reader</name><displayName>Enrichment Record Reader</displayName><description>The Record Reader for reading the 'enrichment' FlowFile</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Record Writer</name><displayName>Record Writer</displayName><description>The Record Writer to use for writing the results. If the Record Writer is configured to inherit the schema from the Record, the schema that it will inherit will be the result of merging both the 'original' record schema and the 'enrichment' record schema.</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Join Strategy</name><displayName>Join Strategy</displayName><description>Specifies how to join the two FlowFiles into a single FlowFile</description><defaultValue>Wrapper</defaultValue><allowableValues><allowableValue><displayName>Wrapper</displayName><value>Wrapper</value><description>The output is a Record that contains two fields: (1) 'original', containing the Record from the original FlowFile and (2) 'enrichment' containing the corresponding Record from the enrichment FlowFile. Records will be correlated based on their index in the FlowFile. If one FlowFile has more Records than the other, a null value will be used.</description></allowableValue><allowableValue><displayName>SQL</displayName><value>SQL</value><description>The output is derived by evaluating a SQL SELECT statement that allows for two tables: 'original' and 'enrichment'. This allows for SQL JOIN statements to be used in order to correlate the Records of the two FlowFiles, so the index in which the Record is encountered in the FlowFile does not matter.</description></allowableValue><allowableValue><displayName>Insert Enrichment Fields</displayName><value>Insert Enrichment Fields</value><description>The enrichment is joined together with the original FlowFile by placing all fields of the enrichment Record into the corresponding Record from the original FlowFile. Records will be correlated based on their index in the FlowFile.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>SQL</name><displayName>SQL</displayName><description>The SQL SELECT statement to evaluate. Expression Language may be provided, but doing so may result in poorer performance. Because this Processor is dealing with two FlowFiles at a time, it's also important to understand how attributes will be referenced. If both FlowFiles have an attribute with the same name but different values, the Expression Language will resolve to the value provided by the 'enrichment' FlowFile.</description><defaultValue>SELECT original.*, enrichment.* 
FROM original 
LEFT OUTER JOIN enrichment 
ON original.id = enrichment.id</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Join Strategy</propertyName><propertyDisplayName>Join Strategy</propertyDisplayName><dependentValues><dependentValue>SQL</dependentValue></dependentValues></dependency></dependencies></property><property><name>dbf-default-precision</name><displayName>Default Decimal Precision</displayName><description>When a DECIMAL/NUMBER value is written as a 'decimal' Avro logical type, a specific 'precision' denoting number of available digits is required. Generally, precision is defined by column data type definition or database engines default. However undefined precision (0) can be returned from some database engines. 'Default Decimal Precision' is used when writing those undefined precision numbers.</description><defaultValue>10</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Join Strategy</propertyName><propertyDisplayName>Join Strategy</propertyDisplayName><dependentValues><dependentValue>SQL</dependentValue></dependentValues></dependency></dependencies></property><property><name>dbf-default-scale</name><displayName>Default Decimal Scale</displayName><description>When a DECIMAL/NUMBER value is written as a 'decimal' Avro logical type, a specific 'scale' denoting number of available decimal digits is required. Generally, scale is defined by column data type definition or database engines default. However when undefined precision (0) is returned, scale can also be uncertain with some database engines. 'Default Decimal Scale' is used when writing those undefined numbers. If a value has more decimals than specified scale, then the value will be rounded-up, e.g. 1.53 becomes 2 with scale 0, and 1.5 with scale 1.</description><defaultValue>0</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Join Strategy</propertyName><propertyDisplayName>Join Strategy</propertyDisplayName><dependentValues><dependentValue>SQL</dependentValue></dependentValues></dependency></dependencies></property><property><name>Insertion Record Path</name><displayName>Insertion Record Path</displayName><description>Specifies where in the 'original' Record the 'enrichment' Record's fields should be inserted. Note that if the RecordPath does not point to any existing field in the original Record, the enrichment will not be inserted.</description><defaultValue>/</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Join Strategy</propertyName><propertyDisplayName>Join Strategy</propertyDisplayName><dependentValues><dependentValue>Insert Enrichment Fields</dependentValue></dependentValues></dependency></dependencies></property><property><name>Maximum number of Bins</name><displayName>Maximum number of Bins</displayName><description>Specifies the maximum number of bins that can be held in memory at any one time</description><defaultValue>10000</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Timeout</name><displayName>Timeout</displayName><description>Specifies the maximum amount of time to wait for the second FlowFile once the first arrives at the processor, after which point the first FlowFile will be routed to the 'timeout' relationship.</description><defaultValue>10 min</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>If both the 'original' and 'enrichment' FlowFiles arrive at the processor but there was a failure in joining the records, both of those FlowFiles will be routed to this relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>joined</name><description>The resultant FlowFile with Records joined together from both the original and enrichment FlowFiles will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>original</name><description>Both of the incoming FlowFiles ('original' and 'enrichment') will be routed to this Relationship. I.e., this is the 'original' version of both of these FlowFiles.</description><autoTerminated>true</autoTerminated></relationship><relationship><name>timeout</name><description>If one of the incoming FlowFiles (i.e., the 'original' FlowFile or the 'enrichment' FlowFile) arrives to this Processor but the other does not arrive within the configured Timeout period, the FlowFile that did arrive is routed to this relationship.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>mime.type</name><description>Sets the mime.type attribute to the MIME Type specified by the Record Writer</description></writesAttribute><writesAttribute><name>record.count</name><description>The number of records in the FlowFile</description></writesAttribute></writesAttributes><triggerWhenEmpty>true</triggerWhenEmpty><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><systemResourceConsiderations><systemResourceConsideration><resource>MEMORY</resource><description>This Processor will load into heap all FlowFiles that are on its incoming queues. While it loads the FlowFiles themselves, and not their content, the FlowFile attributes can be very memory intensive. Additionally, if the Join Strategy is set to SQL, the SQL engine may require buffering the entire contents of the enrichment FlowFile for each concurrent task. See Processor's Additional Details for more details and for steps on how to mitigate these concerns.</description></systemResourceConsideration></systemResourceConsiderations><seeAlso><see>org.apache.nifi.processors.standard.ForkEnrichment</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.ListDatabaseTables</name><type>PROCESSOR</type><description>Generates a set of flow files, each containing attributes corresponding to metadata about a table from a database connection. Once metadata about a table has been fetched, it will not be fetched again until the Refresh Interval (if set) has elapsed, or until state has been manually cleared.</description><tags><tag>sql</tag><tag>list</tag><tag>jdbc</tag><tag>table</tag><tag>database</tag></tags><properties><property><name>list-db-tables-db-connection</name><displayName>Database Connection Pooling Service</displayName><description>The Controller Service that is used to obtain connection to database</description><controllerServiceDefinition><className>org.apache.nifi.dbcp.DBCPService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>list-db-tables-catalog</name><displayName>Catalog</displayName><description>The name of a catalog from which to list database tables. The name must match the catalog name as it is stored in the database. If the property is not set, the catalog name will not be used to narrow the search for tables. If the property is set to an empty string, tables without a catalog will be listed.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>list-db-tables-schema-pattern</name><displayName>Schema Pattern</displayName><description>A pattern for matching schemas in the database. Within a pattern, "%" means match any substring of 0 or more characters, and "_" means match any one character. The pattern must match the schema name as it is stored in the database. If the property is not set, the schema name will not be used to narrow the search for tables. If the property is set to an empty string, tables without a schema will be listed.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>list-db-tables-name-pattern</name><displayName>Table Name Pattern</displayName><description>A pattern for matching tables in the database. Within a pattern, "%" means match any substring of 0 or more characters, and "_" means match any one character. The pattern must match the table name as it is stored in the database. If the property is not set, all tables will be retrieved.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>list-db-tables-types</name><displayName>Table Types</displayName><description>A comma-separated list of table types to include. For example, some databases support TABLE and VIEW types. If the property is not set, tables of all types will be returned.</description><defaultValue>TABLE</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>list-db-include-count</name><displayName>Include Count</displayName><description>Whether to include the table's row count as a flow file attribute. This affects performance as a database query will be generated for each table in the retrieved list.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>record-writer</name><displayName>Record Writer</displayName><description>Specifies the Record Writer to use for creating the listing. If not specified, one FlowFile will be created for each entity that is listed. If the Record Writer is specified, all entities will be written to a single FlowFile instead of adding attributes to individual FlowFiles.</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>list-db-refresh-interval</name><displayName>Refresh Interval</displayName><description>The amount of time to elapse before resetting the processor state, thereby causing all current tables to be listed. During this interval, the processor may continue to run, but tables that have already been listed will not be re-listed. However new/added tables will be listed as the processor runs. A value of zero means the state will never be automatically reset, the user must Clear State manually.</description><defaultValue>0 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>success</name><description>All FlowFiles that are received are routed to success</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>db.table.name</name><description>Contains the name of a database table from the connection</description></writesAttribute><writesAttribute><name>db.table.catalog</name><description>Contains the name of the catalog to which the table belongs (may be null)</description></writesAttribute><writesAttribute><name>db.table.schema</name><description>Contains the name of the schema to which the table belongs (may be null)</description></writesAttribute><writesAttribute><name>db.table.fullname</name><description>Contains the fully-qualifed table name (possibly including catalog, schema, etc.)</description></writesAttribute><writesAttribute><name>db.table.type</name><description>Contains the type of the database table from the connection. Typical types are "TABLE", "VIEW", "SYSTEM TABLE", "GLOBAL TEMPORARY", "LOCAL TEMPORARY", "ALIAS", "SYNONYM"</description></writesAttribute><writesAttribute><name>db.table.remarks</name><description>Contains the name of a database table from the connection</description></writesAttribute><writesAttribute><name>db.table.count</name><description>Contains the number of rows in the table</description></writesAttribute></writesAttributes><triggerSerially>true</triggerSerially><primaryNodeOnly>true</primaryNodeOnly><stateful><description>After performing a listing of tables, the timestamp of the query is stored. This allows the Processor to not re-list tables the next time that the Processor is run. Specifying the refresh interval in the processor properties will indicate that when the processor detects the interval has elapsed, the state will be reset and tables will be re-listed as a result. This processor is meant to be run on the primary node only.</description><scopes><scope>CLUSTER</scope></scopes></stateful><inputRequirement>INPUT_FORBIDDEN</inputRequirement><multiProcessorUseCases><multiProcessorUseCase><description>Perform a full load of a database, retrieving all rows from all tables, or a specific set of tables.</description><notes></notes><keywords><keyword>full load</keyword><keyword>rdbms</keyword><keyword>jdbc</keyword><keyword>database</keyword></keywords><processorConfigurations><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.ListDatabaseTables</processorClassName><configuration>Configure the "Database Connection Pooling Service" property to specify a Connection Pool that is applicable for interacting with your database.
Leave the RecordWriter property unset.

Set the "Catalog" property to the name of the database Catalog; leave it empty to include all catalogs.
Set the "Schema Pattern" property to a Java Regular Expression that matches all database Schemas that should be included; leave it empty to include all Schemas.
Set the "Table Name Pattern" property to a Java Regular Expression that matches the names of all tables that should be included; leave it empty to include all Tables.

Connect the "success" relationship to GenerateTableFetch.
</configuration></processorConfiguration><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.GenerateTableFetch</processorClassName><configuration>Configure the "Database Connection Pooling Service" property to specify the same Connection Pool that was used in ListDatabaseTables.
Set the "Database Type" property to match the appropriate value for your RDBMS vendor.
Set "Table Name" to `${db.table.fullname}`
Leave the RecordWriter property unset.

Connect the "success" relationship to ExecuteSQLRecord.
</configuration></processorConfiguration><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.ExecuteSQLRecord</processorClassName><configuration>Configure the "Database Connection Pooling Service" property to specify the same Connection Pool that was used in ListDatabaseTables.
Configure the "Record Writer" property to specify a Record Writer that is appropriate for the desired output data type.
Leave the "SQL select query" unset.

Connect the "success" relationship to the next Processor in the flow.
</configuration></processorConfiguration></processorConfigurations></multiProcessorUseCase></multiProcessorUseCases><defaultSchedule><strategy>TIMER_DRIVEN</strategy><period>1 min</period><concurrentTasks>1</concurrentTasks></defaultSchedule></extension><extension><name>org.apache.nifi.processors.standard.ListFTP</name><type>PROCESSOR</type><description>Performs a listing of the files residing on an FTP server. For each file that is found on the remote server, a new FlowFile will be created with the filename attribute set to the name of the file on the remote server. This can then be used in conjunction with FetchFTP in order to fetch those files.</description><tags><tag>list</tag><tag>ftp</tag><tag>remote</tag><tag>ingest</tag><tag>source</tag><tag>input</tag><tag>files</tag></tags><properties><property><name>listing-strategy</name><displayName>Listing Strategy</displayName><description>Specify how to determine new/updated entities. See each strategy descriptions for detail.</description><defaultValue>timestamps</defaultValue><allowableValues><allowableValue><displayName>Tracking Timestamps</displayName><value>timestamps</value><description>This strategy tracks the latest timestamp of listed entity to determine new/updated entities. Since it only tracks few timestamps, it can manage listing state efficiently. However, any newly added, or updated entity having timestamp older than the tracked latest timestamp can not be picked by this strategy. For example, such situation can happen in a file system if a file with old timestamp is copied or moved into the target directory without its last modified timestamp being updated. Also may miss files when multiple subdirectories are being written at the same time while listing is running.</description></allowableValue><allowableValue><displayName>Tracking Entities</displayName><value>entities</value><description>This strategy tracks information of all the listed entities within the latest 'Entity Tracking Time Window' to determine new/updated entities. This strategy can pick entities having old timestamp that can be missed with 'Tracking Timestamps'. Works even when multiple subdirectories are being written at the same time while listing is running. However additional DistributedMapCache controller service is required and more JVM heap memory is used. See the description of 'Entity Tracking Time Window' property for further details on how it works.</description></allowableValue><allowableValue><displayName>No Tracking</displayName><value>none</value><description>This strategy lists an entity without any tracking. The same entity will be listed each time on executing this processor. It is recommended to change the default run schedule value. Any property that related to the persisting state will be disregarded.</description></allowableValue><allowableValue><displayName>Time Window</displayName><value>time-window</value><description>This strategy uses a sliding time window. The window starts where the previous window ended and ends with the 'current time'. One cycle will list files with modification time falling within the time window. Works even when multiple subdirectories are being written at the same time while listing is running. IMPORTANT: This strategy works properly only if the time on both the system hosting NiFi and the one hosting the files are accurate.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Hostname</name><displayName>Hostname</displayName><description>The fully qualified hostname or IP address of the remote system</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Port</name><displayName>Port</displayName><description>The port to connect to on the remote host to fetch the data from</description><defaultValue>21</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Username</name><displayName>Username</displayName><description>Username</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Password</name><displayName>Password</displayName><description>Password for the user account</description><required>false</required><sensitive>true</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Remote Path</name><displayName>Remote Path</displayName><description>The path on the remote system from which to pull or push files</description><defaultValue>.</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>record-writer</name><displayName>Record Writer</displayName><description>Specifies the Record Writer to use for creating the listing. If not specified, one FlowFile will be created for each entity that is listed. If the Record Writer is specified, all entities will be written to a single FlowFile instead of adding attributes to individual FlowFiles.</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Search Recursively</name><displayName>Search Recursively</displayName><description>If true, will pull files from arbitrarily nested subdirectories; otherwise, will not traverse subdirectories</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>follow-symlink</name><displayName>Follow symlink</displayName><description>If true, will pull even symbolic files and also nested symbolic subdirectories; otherwise, will not read symbolic files and will not traverse symbolic link subdirectories</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>File Filter Regex</name><displayName>File Filter Regex</displayName><description>Provides a Java Regular Expression for filtering Filenames; if a filter is supplied, only files whose names match that Regular Expression will be fetched</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Path Filter Regex</name><displayName>Path Filter Regex</displayName><description>When Search Recursively is true, then only subdirectories whose path matches the given Regular Expression will be scanned</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Ignore Dotted Files</name><displayName>Ignore Dotted Files</displayName><description>If true, files whose names begin with a dot (".") will be ignored</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Remote Poll Batch Size</name><displayName>Remote Poll Batch Size</displayName><description>The value specifies how many file paths to find in a given directory on the remote system when doing a file listing. This value in general should not need to be modified but when polling against a remote system with a tremendous number of files this value can be critical.  Setting this value too high can result very poor performance and setting it too low can cause the flow to be slower than normal.</description><defaultValue>5000</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Connection Timeout</name><displayName>Connection Timeout</displayName><description>Amount of time to wait before timing out while creating a connection</description><defaultValue>30 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Data Timeout</name><displayName>Data Timeout</displayName><description>When transferring a file between the local and remote system, this value specifies how long is allowed to elapse without any data being transferred between systems</description><defaultValue>30 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Connection Mode</name><displayName>Connection Mode</displayName><description>The FTP Connection Mode</description><defaultValue>Passive</defaultValue><allowableValues><allowableValue><displayName>Active</displayName><value>Active</value><description></description></allowableValue><allowableValue><displayName>Passive</displayName><value>Passive</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Transfer Mode</name><displayName>Transfer Mode</displayName><description>The FTP Transfer Mode</description><defaultValue>Binary</defaultValue><allowableValues><allowableValue><displayName>Binary</displayName><value>Binary</value><description></description></allowableValue><allowableValue><displayName>ASCII</displayName><value>ASCII</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>proxy-configuration-service</name><displayName>Proxy Configuration Service</displayName><description>Specifies the Proxy Configuration Controller Service to proxy network requests. Supported proxies: HTTP + AuthN, SOCKS + AuthN</description><controllerServiceDefinition><className>org.apache.nifi.proxy.ProxyConfigurationService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Internal Buffer Size</name><displayName>Internal Buffer Size</displayName><description>Set the internal buffer size for buffered data streams</description><defaultValue>16KB</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>target-system-timestamp-precision</name><displayName>Target System Timestamp Precision</displayName><description>Specify timestamp precision at the target system. Since this processor uses timestamp of entities to decide which should be listed, it is crucial to use the right timestamp precision.</description><defaultValue>auto-detect</defaultValue><allowableValues><allowableValue><displayName>Auto Detect</displayName><value>auto-detect</value><description>Automatically detect time unit deterministically based on candidate entries timestamp. Please note that this option may take longer to list entities unnecessarily, if none of entries has a precise precision timestamp. E.g. even if a target system supports millis, if all entries only have timestamps without millis, such as '2017-06-16 09:06:34.000', then its precision is determined as 'seconds'.</description></allowableValue><allowableValue><displayName>Milliseconds</displayName><value>millis</value><description>This option provides the minimum latency for an entry from being available to being listed if target system supports millis, if not, use other options.</description></allowableValue><allowableValue><displayName>Seconds</displayName><value>seconds</value><description>For a target system that does not have millis precision, but has in seconds.</description></allowableValue><allowableValue><displayName>Minutes</displayName><value>minutes</value><description>For a target system that only supports precision in minutes.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>et-state-cache</name><displayName>Entity Tracking State Cache</displayName><description>Listed entities are stored in the specified cache storage so that this processor can resume listing across NiFi restart or in case of primary node change. 'Tracking Entities' strategy require tracking information of all listed entities within the last 'Tracking Time Window'. To support large number of entities, the strategy uses DistributedMapCache instead of managed state. Cache key format is 'ListedEntities::{processorId}(::{nodeId})'. If it tracks per node listed entities, then the optional '::{nodeId}' part is added to manage state separately. E.g. cluster wide cache key = 'ListedEntities::8dda2321-0164-1000-50fa-3042fe7d6a7b', per node cache key = 'ListedEntities::8dda2321-0164-1000-50fa-3042fe7d6a7b::nifi-node3' The stored cache content is Gzipped JSON string. The cache key will be deleted when target listing configuration is changed. Used by 'Tracking Entities' strategy.</description><controllerServiceDefinition><className>org.apache.nifi.distributed.cache.client.DistributedMapCacheClient</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>et-time-window</name><displayName>Entity Tracking Time Window</displayName><description>Specify how long this processor should track already-listed entities. 'Tracking Entities' strategy can pick any entity whose timestamp is inside the specified time window. For example, if set to '30 minutes', any entity having timestamp in recent 30 minutes will be the listing target when this processor runs. A listed entity is considered 'new/updated' and a FlowFile is emitted if one of following condition meets: 1. does not exist in the already-listed entities, 2. has newer timestamp than the cached entity, 3. has different size than the cached entity. If a cached entity's timestamp becomes older than specified time window, that entity will be removed from the cached already-listed entities. Used by 'Tracking Entities' strategy.</description><defaultValue>3 hours</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>et-initial-listing-target</name><displayName>Entity Tracking Initial Listing Target</displayName><description>Specify how initial listing should be handled. Used by 'Tracking Entities' strategy.</description><defaultValue>all</defaultValue><allowableValues><allowableValue><displayName>Tracking Time Window</displayName><value>window</value><description>Ignore entities having timestamp older than the specified 'Tracking Time Window' at the initial listing activity.</description></allowableValue><allowableValue><displayName>All Available</displayName><value>all</value><description>Regardless of entities timestamp, all existing entities will be listed at the initial listing activity.</description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>ftp-use-utf8</name><displayName>Use UTF-8 Encoding</displayName><description>Tells the client to use UTF-8 encoding when processing files and filenames. If set to true, the server must also support UTF-8 encoding.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>success</name><description>All FlowFiles that are received are routed to success</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>ftp.remote.host</name><description>The hostname of the FTP Server</description></writesAttribute><writesAttribute><name>ftp.remote.port</name><description>The port that was connected to on the FTP Server</description></writesAttribute><writesAttribute><name>ftp.listing.user</name><description>The username of the user that performed the FTP Listing</description></writesAttribute><writesAttribute><name>file.owner</name><description>The numeric owner id of the source file</description></writesAttribute><writesAttribute><name>file.group</name><description>The numeric group id of the source file</description></writesAttribute><writesAttribute><name>file.permissions</name><description>The read/write/execute permissions of the source file</description></writesAttribute><writesAttribute><name>file.size</name><description>The number of bytes in the source file</description></writesAttribute><writesAttribute><name>file.lastModifiedTime</name><description>The timestamp of when the file in the filesystem waslast modified as 'yyyy-MM-dd'T'HH:mm:ssZ'</description></writesAttribute><writesAttribute><name>filename</name><description>The name of the file on the FTP Server</description></writesAttribute><writesAttribute><name>path</name><description>The fully qualified name of the directory on the FTP Server from which the file was pulled</description></writesAttribute></writesAttributes><triggerSerially>true</triggerSerially><primaryNodeOnly>true</primaryNodeOnly><stateful><description>After performing a listing of files, the timestamp of the newest file is stored. This allows the Processor to list only files that have been added or modified after this date the next time that the Processor is run. State is stored across the cluster so that this Processor can be run on Primary Node only and if a new Primary Node is selected, the new node will not duplicate the data that was listed by the previous Primary Node.</description><scopes><scope>CLUSTER</scope></scopes></stateful><inputRequirement>INPUT_FORBIDDEN</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.FetchFTP</see><see>org.apache.nifi.processors.standard.GetFTP</see><see>org.apache.nifi.processors.standard.PutFTP</see></seeAlso><defaultSchedule><strategy>TIMER_DRIVEN</strategy><period>1 min</period><concurrentTasks>1</concurrentTasks></defaultSchedule></extension><extension><name>org.apache.nifi.processors.standard.ListFile</name><type>PROCESSOR</type><description>Retrieves a listing of files from the input directory. For each file listed, creates a FlowFile that represents the file so that it can be fetched in conjunction with FetchFile. This Processor is designed to run on Primary Node only in a cluster when 'Input Directory Location' is set to 'Remote'. If the primary node changes, the new Primary Node will pick up where the previous node left off without duplicating all the data. When 'Input Directory Location' is 'Local', the 'Execution' mode can be anything, and synchronization won't happen. Unlike GetFile, this Processor does not delete any data from the local filesystem.</description><tags><tag>file</tag><tag>get</tag><tag>list</tag><tag>ingest</tag><tag>source</tag><tag>filesystem</tag></tags><properties><property><name>Input Directory</name><displayName>Input Directory</displayName><description>The input directory from which files to pull files</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>listing-strategy</name><displayName>Listing Strategy</displayName><description>Specify how to determine new/updated entities. See each strategy descriptions for detail.</description><defaultValue>timestamps</defaultValue><allowableValues><allowableValue><displayName>Tracking Timestamps</displayName><value>timestamps</value><description>This strategy tracks the latest timestamp of listed entity to determine new/updated entities. Since it only tracks few timestamps, it can manage listing state efficiently. However, any newly added, or updated entity having timestamp older than the tracked latest timestamp can not be picked by this strategy. For example, such situation can happen in a file system if a file with old timestamp is copied or moved into the target directory without its last modified timestamp being updated. Also may miss files when multiple subdirectories are being written at the same time while listing is running.</description></allowableValue><allowableValue><displayName>Tracking Entities</displayName><value>entities</value><description>This strategy tracks information of all the listed entities within the latest 'Entity Tracking Time Window' to determine new/updated entities. This strategy can pick entities having old timestamp that can be missed with 'Tracking Timestamps'. Works even when multiple subdirectories are being written at the same time while listing is running. However additional DistributedMapCache controller service is required and more JVM heap memory is used. See the description of 'Entity Tracking Time Window' property for further details on how it works.</description></allowableValue><allowableValue><displayName>No Tracking</displayName><value>none</value><description>This strategy lists an entity without any tracking. The same entity will be listed each time on executing this processor. It is recommended to change the default run schedule value. Any property that related to the persisting state will be disregarded.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Recurse Subdirectories</name><displayName>Recurse Subdirectories</displayName><description>Indicates whether to list files from subdirectories of the directory</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>record-writer</name><displayName>Record Writer</displayName><description>Specifies the Record Writer to use for creating the listing. If not specified, one FlowFile will be created for each entity that is listed. If the Record Writer is specified, all entities will be written to a single FlowFile instead of adding attributes to individual FlowFiles.</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Input Directory Location</name><displayName>Input Directory Location</displayName><description>Specifies where the Input Directory is located. This is used to determine whether state should be stored locally or across the cluster.</description><defaultValue>Local</defaultValue><allowableValues><allowableValue><displayName>Local</displayName><value>Local</value><description>Input Directory is located on a local disk. State will be stored locally on each node in the cluster.</description></allowableValue><allowableValue><displayName>Remote</displayName><value>Remote</value><description>Input Directory is located on a remote system. State will be stored across the cluster so that the listing can be performed on Primary Node Only and another node can pick up where the last node left off, if the Primary Node changes</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>File Filter</name><displayName>File Filter</displayName><description>Only files whose names match the given regular expression will be picked up</description><defaultValue>[^\.].*</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Path Filter</name><displayName>Path Filter</displayName><description>When Recurse Subdirectories is true, then only subdirectories whose path matches the given regular expression will be scanned</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Include File Attributes</name><displayName>Include File Attributes</displayName><description>Whether or not to include information such as the file's Last Modified Time and Owner as FlowFile Attributes. Depending on the File System being used, gathering this information can be expensive and as a result should be disabled. This is especially true of remote file shares.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Minimum File Age</name><displayName>Minimum File Age</displayName><description>The minimum age that a file must be in order to be pulled; any file younger than this amount of time (according to last modification date) will be ignored</description><defaultValue>0 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum File Age</name><displayName>Maximum File Age</displayName><description>The maximum age that a file must be in order to be pulled; any file older than this amount of time (according to last modification date) will be ignored</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Minimum File Size</name><displayName>Minimum File Size</displayName><description>The minimum size that a file must be in order to be pulled</description><defaultValue>0 B</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum File Size</name><displayName>Maximum File Size</displayName><description>The maximum size that a file can be in order to be pulled</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Ignore Hidden Files</name><displayName>Ignore Hidden Files</displayName><description>Indicates whether or not hidden files should be ignored</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>target-system-timestamp-precision</name><displayName>Target System Timestamp Precision</displayName><description>Specify timestamp precision at the target system. Since this processor uses timestamp of entities to decide which should be listed, it is crucial to use the right timestamp precision.</description><defaultValue>auto-detect</defaultValue><allowableValues><allowableValue><displayName>Auto Detect</displayName><value>auto-detect</value><description>Automatically detect time unit deterministically based on candidate entries timestamp. Please note that this option may take longer to list entities unnecessarily, if none of entries has a precise precision timestamp. E.g. even if a target system supports millis, if all entries only have timestamps without millis, such as '2017-06-16 09:06:34.000', then its precision is determined as 'seconds'.</description></allowableValue><allowableValue><displayName>Milliseconds</displayName><value>millis</value><description>This option provides the minimum latency for an entry from being available to being listed if target system supports millis, if not, use other options.</description></allowableValue><allowableValue><displayName>Seconds</displayName><value>seconds</value><description>For a target system that does not have millis precision, but has in seconds.</description></allowableValue><allowableValue><displayName>Minutes</displayName><value>minutes</value><description>For a target system that only supports precision in minutes.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>et-state-cache</name><displayName>Entity Tracking State Cache</displayName><description>Listed entities are stored in the specified cache storage so that this processor can resume listing across NiFi restart or in case of primary node change. 'Tracking Entities' strategy require tracking information of all listed entities within the last 'Tracking Time Window'. To support large number of entities, the strategy uses DistributedMapCache instead of managed state. Cache key format is 'ListedEntities::{processorId}(::{nodeId})'. If it tracks per node listed entities, then the optional '::{nodeId}' part is added to manage state separately. E.g. cluster wide cache key = 'ListedEntities::8dda2321-0164-1000-50fa-3042fe7d6a7b', per node cache key = 'ListedEntities::8dda2321-0164-1000-50fa-3042fe7d6a7b::nifi-node3' The stored cache content is Gzipped JSON string. The cache key will be deleted when target listing configuration is changed. Used by 'Tracking Entities' strategy.</description><controllerServiceDefinition><className>org.apache.nifi.distributed.cache.client.DistributedMapCacheClient</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>et-time-window</name><displayName>Entity Tracking Time Window</displayName><description>Specify how long this processor should track already-listed entities. 'Tracking Entities' strategy can pick any entity whose timestamp is inside the specified time window. For example, if set to '30 minutes', any entity having timestamp in recent 30 minutes will be the listing target when this processor runs. A listed entity is considered 'new/updated' and a FlowFile is emitted if one of following condition meets: 1. does not exist in the already-listed entities, 2. has newer timestamp than the cached entity, 3. has different size than the cached entity. If a cached entity's timestamp becomes older than specified time window, that entity will be removed from the cached already-listed entities. Used by 'Tracking Entities' strategy.</description><defaultValue>3 hours</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>et-initial-listing-target</name><displayName>Entity Tracking Initial Listing Target</displayName><description>Specify how initial listing should be handled. Used by 'Tracking Entities' strategy.</description><defaultValue>all</defaultValue><allowableValues><allowableValue><displayName>Tracking Time Window</displayName><value>window</value><description>Ignore entities having timestamp older than the specified 'Tracking Time Window' at the initial listing activity.</description></allowableValue><allowableValue><displayName>All Available</displayName><value>all</value><description>Regardless of entities timestamp, all existing entities will be listed at the initial listing activity.</description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>et-node-identifier</name><displayName>Entity Tracking Node Identifier</displayName><description>The configured value will be appended to the cache key so that listing state can be tracked per NiFi node rather than cluster wide when tracking state is scoped to LOCAL. Used by 'Tracking Entities' strategy.</description><defaultValue>${hostname()}</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>track-performance</name><displayName>Track Performance</displayName><description>Whether or not the Processor should track the performance of disk access operations. If true, all accesses to disk will be recorded, including the file being accessed, the information being obtained, and how long it takes. This is then logged periodically at a DEBUG level. While the amount of data will be capped, this option may still consume a significant amount of heap (controlled by the 'Maximum Number of Files to Track' property), but it can be very useful for troubleshooting purposes if performance is poor is degraded.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>max-performance-metrics</name><displayName>Maximum Number of Files to Track</displayName><description>If the 'Track Performance' property is set to 'true', this property indicates the maximum number of files whose performance metrics should be held onto. A smaller value for this property will result in less heap utilization, while a larger value may provide more accurate insights into how the disk access operations are performing</description><defaultValue>100000</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>max-operation-time</name><displayName>Max Disk Operation Time</displayName><description>The maximum amount of time that any single disk operation is expected to take. If any disk operation takes longer than this amount of time, a warning bulletin will be generated for each operation that exceeds this amount of time.</description><defaultValue>10 secs</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>max-listing-time</name><displayName>Max Directory Listing Time</displayName><description>The maximum amount of time that listing any single directory is expected to take. If the listing for the directory specified by the 'Input Directory' property, or the listing of any subdirectory (if 'Recurse' is set to true) takes longer than this amount of time, a warning bulletin will be generated for each directory listing that exceeds this amount of time.</description><defaultValue>3 mins</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>success</name><description>All FlowFiles that are received are routed to success</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>filename</name><description>The name of the file that was read from filesystem.</description></writesAttribute><writesAttribute><name>path</name><description>The path is set to the relative path of the file's directory on filesystem compared to the Input Directory property. For example, if Input Directory is set to /tmp, then files picked up from /tmp will have the path attribute set to "/". If the Recurse Subdirectories property is set to true and a file is picked up from /tmp/abc/1/2/3, then the path attribute will be set to "abc/1/2/3/".</description></writesAttribute><writesAttribute><name>absolute.path</name><description>The absolute.path is set to the absolute path of the file's directory on filesystem. For example, if the Input Directory property is set to /tmp, then files picked up from /tmp will have the path attribute set to "/tmp/". If the Recurse Subdirectories property is set to true and a file is picked up from /tmp/abc/1/2/3, then the path attribute will be set to "/tmp/abc/1/2/3/".</description></writesAttribute><writesAttribute><name>file.owner</name><description>The user that owns the file in filesystem</description></writesAttribute><writesAttribute><name>file.group</name><description>The group that owns the file in filesystem</description></writesAttribute><writesAttribute><name>file.size</name><description>The number of bytes in the file in filesystem</description></writesAttribute><writesAttribute><name>file.permissions</name><description>The permissions for the file in filesystem. This is formatted as 3 characters for the owner, 3 for the group, and 3 for other users. For example rw-rw-r--</description></writesAttribute><writesAttribute><name>file.lastModifiedTime</name><description>The timestamp of when the file in filesystem was last modified as 'yyyy-MM-dd'T'HH:mm:ssZ'</description></writesAttribute><writesAttribute><name>file.lastAccessTime</name><description>The timestamp of when the file in filesystem was last accessed as 'yyyy-MM-dd'T'HH:mm:ssZ'</description></writesAttribute><writesAttribute><name>file.creationTime</name><description>The timestamp of when the file in filesystem was created as 'yyyy-MM-dd'T'HH:mm:ssZ'</description></writesAttribute></writesAttributes><triggerSerially>true</triggerSerially><stateful><description>After performing a listing of files, the timestamp of the newest file is stored. This allows the Processor to list only files that have been added or modified after this date the next time that the Processor is run. Whether the state is stored with a Local or Cluster scope depends on the value of the &lt;Input Directory Location&gt; property.</description><scopes><scope>LOCAL</scope><scope>CLUSTER</scope></scopes></stateful><inputRequirement>INPUT_FORBIDDEN</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.GetFile</see><see>org.apache.nifi.processors.standard.PutFile</see><see>org.apache.nifi.processors.standard.FetchFile</see></seeAlso><defaultSchedule><strategy>TIMER_DRIVEN</strategy><period>1 min</period><concurrentTasks>1</concurrentTasks></defaultSchedule></extension><extension><name>org.apache.nifi.processors.standard.ListSFTP</name><type>PROCESSOR</type><description>Performs a listing of the files residing on an SFTP server. For each file that is found on the remote server, a new FlowFile will be created with the filename attribute set to the name of the file on the remote server. This can then be used in conjunction with FetchSFTP in order to fetch those files.</description><tags><tag>list</tag><tag>sftp</tag><tag>remote</tag><tag>ingest</tag><tag>source</tag><tag>input</tag><tag>files</tag></tags><properties><property><name>listing-strategy</name><displayName>Listing Strategy</displayName><description>Specify how to determine new/updated entities. See each strategy descriptions for detail.</description><defaultValue>timestamps</defaultValue><allowableValues><allowableValue><displayName>Tracking Timestamps</displayName><value>timestamps</value><description>This strategy tracks the latest timestamp of listed entity to determine new/updated entities. Since it only tracks few timestamps, it can manage listing state efficiently. However, any newly added, or updated entity having timestamp older than the tracked latest timestamp can not be picked by this strategy. For example, such situation can happen in a file system if a file with old timestamp is copied or moved into the target directory without its last modified timestamp being updated. Also may miss files when multiple subdirectories are being written at the same time while listing is running.</description></allowableValue><allowableValue><displayName>Tracking Entities</displayName><value>entities</value><description>This strategy tracks information of all the listed entities within the latest 'Entity Tracking Time Window' to determine new/updated entities. This strategy can pick entities having old timestamp that can be missed with 'Tracking Timestamps'. Works even when multiple subdirectories are being written at the same time while listing is running. However additional DistributedMapCache controller service is required and more JVM heap memory is used. See the description of 'Entity Tracking Time Window' property for further details on how it works.</description></allowableValue><allowableValue><displayName>No Tracking</displayName><value>none</value><description>This strategy lists an entity without any tracking. The same entity will be listed each time on executing this processor. It is recommended to change the default run schedule value. Any property that related to the persisting state will be disregarded.</description></allowableValue><allowableValue><displayName>Time Window</displayName><value>time-window</value><description>This strategy uses a sliding time window. The window starts where the previous window ended and ends with the 'current time'. One cycle will list files with modification time falling within the time window. Works even when multiple subdirectories are being written at the same time while listing is running. IMPORTANT: This strategy works properly only if the time on both the system hosting NiFi and the one hosting the files are accurate.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Hostname</name><displayName>Hostname</displayName><description>The fully qualified hostname or IP address of the remote system</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Port</name><displayName>Port</displayName><description>The port that the remote system is listening on for file transfers</description><defaultValue>22</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Username</name><displayName>Username</displayName><description>Username</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Password</name><displayName>Password</displayName><description>Password for the user account</description><required>false</required><sensitive>true</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Private Key Path</name><displayName>Private Key Path</displayName><description>The fully qualified path to the Private Key file</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType></resourceTypes></resourceDefinition></property><property><name>Private Key Passphrase</name><displayName>Private Key Passphrase</displayName><description>Password for the private key</description><required>false</required><sensitive>true</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Remote Path</name><displayName>Remote Path</displayName><description>The path on the remote system from which to pull or push files</description><defaultValue>.</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>record-writer</name><displayName>Record Writer</displayName><description>Specifies the Record Writer to use for creating the listing. If not specified, one FlowFile will be created for each entity that is listed. If the Record Writer is specified, all entities will be written to a single FlowFile instead of adding attributes to individual FlowFiles.</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Search Recursively</name><displayName>Search Recursively</displayName><description>If true, will pull files from arbitrarily nested subdirectories; otherwise, will not traverse subdirectories</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>follow-symlink</name><displayName>Follow symlink</displayName><description>If true, will pull even symbolic files and also nested symbolic subdirectories; otherwise, will not read symbolic files and will not traverse symbolic link subdirectories</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>File Filter Regex</name><displayName>File Filter Regex</displayName><description>Provides a Java Regular Expression for filtering Filenames; if a filter is supplied, only files whose names match that Regular Expression will be fetched</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Path Filter Regex</name><displayName>Path Filter Regex</displayName><description>When Search Recursively is true, then only subdirectories whose path matches the given Regular Expression will be scanned</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Ignore Dotted Files</name><displayName>Ignore Dotted Files</displayName><description>If true, files whose names begin with a dot (".") will be ignored</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Strict Host Key Checking</name><displayName>Strict Host Key Checking</displayName><description>Indicates whether or not strict enforcement of hosts keys should be applied</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Host Key File</name><displayName>Host Key File</displayName><description>If supplied, the given file will be used as the Host Key; otherwise, if 'Strict Host Key Checking' property is applied (set to true) then uses the 'known_hosts' and 'known_hosts2' files from ~/.ssh directory else no host key file will be used</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType></resourceTypes></resourceDefinition></property><property><name>Connection Timeout</name><displayName>Connection Timeout</displayName><description>Amount of time to wait before timing out while creating a connection</description><defaultValue>30 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Data Timeout</name><displayName>Data Timeout</displayName><description>When transferring a file between the local and remote system, this value specifies how long is allowed to elapse without any data being transferred between systems</description><defaultValue>30 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Send Keep Alive On Timeout</name><displayName>Send Keep Alive On Timeout</displayName><description>Send a Keep Alive message every 5 seconds up to 5 times for an overall timeout of 25 seconds.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>target-system-timestamp-precision</name><displayName>Target System Timestamp Precision</displayName><description>Specify timestamp precision at the target system. Since this processor uses timestamp of entities to decide which should be listed, it is crucial to use the right timestamp precision.</description><defaultValue>auto-detect</defaultValue><allowableValues><allowableValue><displayName>Auto Detect</displayName><value>auto-detect</value><description>Automatically detect time unit deterministically based on candidate entries timestamp. Please note that this option may take longer to list entities unnecessarily, if none of entries has a precise precision timestamp. E.g. even if a target system supports millis, if all entries only have timestamps without millis, such as '2017-06-16 09:06:34.000', then its precision is determined as 'seconds'.</description></allowableValue><allowableValue><displayName>Milliseconds</displayName><value>millis</value><description>This option provides the minimum latency for an entry from being available to being listed if target system supports millis, if not, use other options.</description></allowableValue><allowableValue><displayName>Seconds</displayName><value>seconds</value><description>For a target system that does not have millis precision, but has in seconds.</description></allowableValue><allowableValue><displayName>Minutes</displayName><value>minutes</value><description>For a target system that only supports precision in minutes.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Use Compression</name><displayName>Use Compression</displayName><description>Indicates whether or not ZLIB compression should be used when transferring files</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>proxy-configuration-service</name><displayName>Proxy Configuration Service</displayName><description>Specifies the Proxy Configuration Controller Service to proxy network requests. Supported proxies: HTTP + AuthN, SOCKS + AuthN</description><controllerServiceDefinition><className>org.apache.nifi.proxy.ProxyConfigurationService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>et-state-cache</name><displayName>Entity Tracking State Cache</displayName><description>Listed entities are stored in the specified cache storage so that this processor can resume listing across NiFi restart or in case of primary node change. 'Tracking Entities' strategy require tracking information of all listed entities within the last 'Tracking Time Window'. To support large number of entities, the strategy uses DistributedMapCache instead of managed state. Cache key format is 'ListedEntities::{processorId}(::{nodeId})'. If it tracks per node listed entities, then the optional '::{nodeId}' part is added to manage state separately. E.g. cluster wide cache key = 'ListedEntities::8dda2321-0164-1000-50fa-3042fe7d6a7b', per node cache key = 'ListedEntities::8dda2321-0164-1000-50fa-3042fe7d6a7b::nifi-node3' The stored cache content is Gzipped JSON string. The cache key will be deleted when target listing configuration is changed. Used by 'Tracking Entities' strategy.</description><controllerServiceDefinition><className>org.apache.nifi.distributed.cache.client.DistributedMapCacheClient</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>et-time-window</name><displayName>Entity Tracking Time Window</displayName><description>Specify how long this processor should track already-listed entities. 'Tracking Entities' strategy can pick any entity whose timestamp is inside the specified time window. For example, if set to '30 minutes', any entity having timestamp in recent 30 minutes will be the listing target when this processor runs. A listed entity is considered 'new/updated' and a FlowFile is emitted if one of following condition meets: 1. does not exist in the already-listed entities, 2. has newer timestamp than the cached entity, 3. has different size than the cached entity. If a cached entity's timestamp becomes older than specified time window, that entity will be removed from the cached already-listed entities. Used by 'Tracking Entities' strategy.</description><defaultValue>3 hours</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>et-initial-listing-target</name><displayName>Entity Tracking Initial Listing Target</displayName><description>Specify how initial listing should be handled. Used by 'Tracking Entities' strategy.</description><defaultValue>all</defaultValue><allowableValues><allowableValue><displayName>Tracking Time Window</displayName><value>window</value><description>Ignore entities having timestamp older than the specified 'Tracking Time Window' at the initial listing activity.</description></allowableValue><allowableValue><displayName>All Available</displayName><value>all</value><description>Regardless of entities timestamp, all existing entities will be listed at the initial listing activity.</description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Minimum File Age</name><displayName>Minimum File Age</displayName><description>The minimum age that a file must be in order to be pulled; any file younger than this amount of time (according to last modification date) will be ignored</description><defaultValue>0 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum File Age</name><displayName>Maximum File Age</displayName><description>The maximum age that a file must be in order to be pulled; any file older than this amount of time (according to last modification date) will be ignored</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Minimum File Size</name><displayName>Minimum File Size</displayName><description>The minimum size that a file must be in order to be pulled</description><defaultValue>0 B</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum File Size</name><displayName>Maximum File Size</displayName><description>The maximum size that a file can be in order to be pulled</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Ciphers Allowed</name><displayName>Ciphers Allowed</displayName><description>A comma-separated list of Ciphers allowed for SFTP connections. Leave unset to allow all. Available options are: 3des-cbc, 3des-ctr, aes128-cbc, aes128-ctr, aes128-gcm@openssh.com, aes192-cbc, aes192-ctr, aes256-cbc, aes256-ctr, aes256-gcm@openssh.com, arcfour, arcfour128, arcfour256, blowfish-cbc, blowfish-ctr, cast128-cbc, cast128-ctr, chacha20-poly1305@openssh.com, idea-cbc, idea-ctr, serpent128-cbc, serpent128-ctr, serpent192-cbc, serpent192-ctr, serpent256-cbc, serpent256-ctr, twofish-cbc, twofish128-cbc, twofish128-ctr, twofish192-cbc, twofish192-ctr, twofish256-cbc, twofish256-ctr</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Key Algorithms Allowed</name><displayName>Key Algorithms Allowed</displayName><description>A comma-separated list of Key Algorithms allowed for SFTP connections. Leave unset to allow all. Available options are: ecdsa-sha2-nistp256, ecdsa-sha2-nistp256-cert-v01@openssh.com, ecdsa-sha2-nistp384, ecdsa-sha2-nistp384-cert-v01@openssh.com, ecdsa-sha2-nistp521, ecdsa-sha2-nistp521-cert-v01@openssh.com, rsa-sha2-256, rsa-sha2-512, ssh-dss, ssh-dss-cert-v01@openssh.com, ssh-ed25519, ssh-ed25519-cert-v01@openssh.com, ssh-rsa, ssh-rsa-cert-v01@openssh.com</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Key Exchange Algorithms Allowed</name><displayName>Key Exchange Algorithms Allowed</displayName><description>A comma-separated list of Key Exchange Algorithms allowed for SFTP connections. Leave unset to allow all. Available options are: curve25519-sha256, curve25519-sha256@libssh.org, diffie-hellman-group-exchange-sha1, diffie-hellman-group-exchange-sha256, diffie-hellman-group1-sha1, diffie-hellman-group14-sha1, diffie-hellman-group14-sha256, diffie-hellman-group14-sha256@ssh.com, diffie-hellman-group15-sha256, diffie-hellman-group15-sha256@ssh.com, diffie-hellman-group15-sha384@ssh.com, diffie-hellman-group15-sha512, diffie-hellman-group16-sha256, diffie-hellman-group16-sha384@ssh.com, diffie-hellman-group16-sha512, diffie-hellman-group16-sha512@ssh.com, diffie-hellman-group17-sha512, diffie-hellman-group18-sha512, diffie-hellman-group18-sha512@ssh.com, ecdh-sha2-nistp256, ecdh-sha2-nistp384, ecdh-sha2-nistp521, ext-info-c</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Message Authentication Codes Allowed</name><displayName>Message Authentication Codes Allowed</displayName><description>A comma-separated list of Message Authentication Codes allowed for SFTP connections. Leave unset to allow all. Available options are: hmac-md5, hmac-md5-96, hmac-md5-96-etm@openssh.com, hmac-md5-etm@openssh.com, hmac-ripemd160, hmac-ripemd160-96, hmac-ripemd160-etm@openssh.com, hmac-ripemd160@openssh.com, hmac-sha1, hmac-sha1-96, hmac-sha1-96@openssh.com, hmac-sha1-etm@openssh.com, hmac-sha2-256, hmac-sha2-256-etm@openssh.com, hmac-sha2-512, hmac-sha2-512-etm@openssh.com</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>success</name><description>All FlowFiles that are received are routed to success</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>sftp.remote.host</name><description>The hostname of the SFTP Server</description></writesAttribute><writesAttribute><name>sftp.remote.port</name><description>The port that was connected to on the SFTP Server</description></writesAttribute><writesAttribute><name>sftp.listing.user</name><description>The username of the user that performed the SFTP Listing</description></writesAttribute><writesAttribute><name>file.owner</name><description>The numeric owner id of the source file</description></writesAttribute><writesAttribute><name>file.group</name><description>The numeric group id of the source file</description></writesAttribute><writesAttribute><name>file.permissions</name><description>The read/write/execute permissions of the source file</description></writesAttribute><writesAttribute><name>file.size</name><description>The number of bytes in the source file</description></writesAttribute><writesAttribute><name>file.lastModifiedTime</name><description>The timestamp of when the file in the filesystem waslast modified as 'yyyy-MM-dd'T'HH:mm:ssZ'</description></writesAttribute><writesAttribute><name>filename</name><description>The name of the file on the SFTP Server</description></writesAttribute><writesAttribute><name>path</name><description>The fully qualified name of the directory on the SFTP Server from which the file was pulled</description></writesAttribute><writesAttribute><name>mime.type</name><description>The MIME Type that is provided by the configured Record Writer</description></writesAttribute></writesAttributes><triggerSerially>true</triggerSerially><primaryNodeOnly>true</primaryNodeOnly><stateful><description>After performing a listing of files, the timestamp of the newest file is stored. This allows the Processor to list only files that have been added or modified after this date the next time that the Processor is run. State is stored across the cluster so that this Processor can be run on Primary Node only and if a new Primary Node is selected, the new node will not duplicate the data that was listed by the previous Primary Node.</description><scopes><scope>CLUSTER</scope></scopes></stateful><inputRequirement>INPUT_FORBIDDEN</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.FetchSFTP</see><see>org.apache.nifi.processors.standard.GetSFTP</see><see>org.apache.nifi.processors.standard.PutSFTP</see></seeAlso><defaultSchedule><strategy>TIMER_DRIVEN</strategy><period>1 min</period><concurrentTasks>1</concurrentTasks></defaultSchedule></extension><extension><name>org.apache.nifi.processors.standard.ListenFTP</name><type>PROCESSOR</type><description>Starts an FTP server that listens on the specified port and transforms incoming files into FlowFiles. The URI of the service will be ftp://{hostname}:{port}. The default port is 2221.</description><tags><tag>ingest</tag><tag>FTP</tag><tag>FTPS</tag><tag>listen</tag></tags><properties><property><name>Address</name><displayName>Address</displayName><description>The address the FTP server should be bound to. If not set (or set to 0.0.0.0), the server binds to all available addresses (i.e. all network interfaces of the host machine).</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Port</name><displayName>Port</displayName><description>The Port to listen on for incoming connections. On Linux, root privileges are required to use port numbers below 1024.</description><defaultValue>2221</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Username</name><displayName>Username</displayName><description>The name of the user that is allowed to log in to the FTP server. If a username is provided, a password must also be provided. If no username is specified, anonymous connections will be permitted.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Password</name><displayName>Password</displayName><description>If the Username is set, then a password must also be specified. The password provided by the client trying to log in to the FTP server will be checked against this password.</description><required>false</required><sensitive>true</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>SSL Context Service</name><displayName>SSL Context Service</displayName><description>Specifies the SSL Context Service that can be used to create secure connections. If an SSL Context Service is selected, then a keystore file must also be specified in the SSL Context Service. Without a keystore file, the processor cannot be started successfully.Specifying a truststore file is optional. If a truststore file is specified, client authentication is required (the client needs to send a certificate to the server).Regardless of the selected TLS protocol, the highest available protocol is used for the connection. For example if NiFi is running on Java 11 and TLSv1.2 is selected in the controller service as the preferred TLS Protocol, TLSv1.3 will be used (regardless of TLSv1.2 being selected) because Java 11 supports TLSv1.3.</description><controllerServiceDefinition><className>org.apache.nifi.ssl.SSLContextProvider</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>success</name><description>Relationship for successfully received files.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>filename</name><description>The name of the file received via the FTP/FTPS connection.</description></writesAttribute><writesAttribute><name>path</name><description>The path pointing to the file's target directory. E.g.: file.txt is uploaded to /Folder1/SubFolder, then the value of the path attribute will be "/Folder1/SubFolder/" (note that it ends with a separator character).</description></writesAttribute></writesAttributes><inputRequirement>INPUT_FORBIDDEN</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.ListenHTTP</name><type>PROCESSOR</type><description>Starts an HTTP Server and listens on a given base path to transform incoming requests into FlowFiles. The default URI of the Service will be http://{hostname}:{port}/contentListener. Only HEAD and POST requests are supported. GET, PUT, DELETE, OPTIONS and TRACE will result in an error and the HTTP response status code 405; CONNECT will also result in an error and the HTTP response status code 400. GET is supported on &lt;service_URI&gt;/healthcheck. If the service is available, it returns "200 OK" with the content "OK". The health check functionality can be configured to be accessible via a different port. For details see the documentation of the "Listening Port for health check requests" property. A Record Reader and Record Writer property can be enabled on the processor to process incoming requests as records. Record processing is not allowed for multipart requests and request in FlowFileV3 format (minifi).</description><tags><tag>ingest</tag><tag>http</tag><tag>https</tag><tag>rest</tag><tag>listen</tag></tags><properties><property><name>Base Path</name><displayName>Base Path</displayName><description>Base path for incoming connections</description><defaultValue>contentListener</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Listening Port</name><displayName>Listening Port</displayName><description>The Port to listen on for incoming connections</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>health-check-port</name><displayName>Listening Port for Health Check Requests</displayName><description>The port to listen on for incoming health check requests. If set, it must be different from the Listening Port. Configure this port if the processor is set to use two-way SSL and a load balancer that does not support client authentication for health check requests is used. Only /&lt;base_path&gt;/healthcheck service is available via this port and only GET and HEAD requests are supported. If the processor is set not to use SSL, SSL will not be used on this port, either. If the processor is set to use one-way SSL, one-way SSL will be used on this port. If the processor is set to use two-way SSL, one-way SSL will be used on this port (client authentication not required).</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>SSL Context Service</name><displayName>SSL Context Service</displayName><description>SSL Context Service enables support for HTTPS</description><controllerServiceDefinition><className>org.apache.nifi.ssl.SSLContextProvider</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>HTTP Protocols</name><displayName>HTTP Protocols</displayName><description>HTTP Protocols supported for Application Layer Protocol Negotiation with TLS</description><defaultValue>HTTP_1_1</defaultValue><allowableValues><allowableValue><displayName>http/1.1</displayName><value>HTTP_1_1</value><description>HTTP/1.1</description></allowableValue><allowableValue><displayName>h2 http/1.1</displayName><value>H2_HTTP_1_1</value><description>HTTP/2 and HTTP/1.1 negotiated based on requested protocols</description></allowableValue><allowableValue><displayName>h2</displayName><value>H2</value><description>HTTP/2</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>SSL Context Service</propertyName><propertyDisplayName>SSL Context Service</propertyDisplayName></dependency></dependencies></property><property><name>client-authentication</name><displayName>Client Authentication</displayName><description>Client Authentication policy for TLS connections. Required when SSL Context Service configured.</description><defaultValue>AUTO</defaultValue><allowableValues><allowableValue><displayName>AUTO</displayName><value>AUTO</value><description>Inferred based on SSL Context Service properties. The presence of Trust Store properties implies REQUIRED, otherwise NONE is configured.</description></allowableValue><allowableValue><displayName>WANT</displayName><value>WANT</value><description>Requests the client certificate on handshake and validates if present but does not require it</description></allowableValue><allowableValue><displayName>REQUIRED</displayName><value>REQUIRED</value><description>Requests the client certificate on handshake and rejects the connection if it is not present and valid</description></allowableValue><allowableValue><displayName>NONE</displayName><value>NONE</value><description>Does not request the client certificate on handshake</description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>SSL Context Service</propertyName><propertyDisplayName>SSL Context Service</propertyDisplayName></dependency></dependencies></property><property><name>Authorized DN Pattern</name><displayName>Authorized Subject DN Pattern</displayName><description>A Regular Expression to apply against the Subject's Distinguished Name of incoming connections. If the Pattern does not match the Subject DN, the the processor will respond with a status of HTTP 403 Forbidden.</description><defaultValue>.*</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>authorized-issuer-dn-pattern</name><displayName>Authorized Issuer DN Pattern</displayName><description>A Regular Expression to apply against the Issuer's Distinguished Name of incoming connections. If the Pattern does not match the Issuer DN, the processor will respond with a status of HTTP 403 Forbidden.</description><defaultValue>.*</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Unconfirmed Flowfile Time</name><displayName>Max Unconfirmed Flowfile Time</displayName><description>The maximum amount of time to wait for a FlowFile to be confirmed before it is removed from the cache</description><defaultValue>60 secs</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>HTTP Headers to receive as Attributes (Regex)</name><displayName>HTTP Headers to receive as Attributes (Regex)</displayName><description>Specifies the Regular Expression that determines the names of HTTP Headers that should be passed along as FlowFile attributes</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Request Header Maximum Size</name><displayName>Request Header Maximum Size</displayName><description>The maximum supported size of HTTP headers in requests sent to this processor</description><defaultValue>8 KB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Return Code</name><displayName>Return Code</displayName><description>The HTTP return code returned after every HTTP call</description><defaultValue>200</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>multipart-request-max-size</name><displayName>Multipart Request Max Size</displayName><description>The max size of the request. Only applies for requests with Content-Type: multipart/form-data, and is used to prevent denial of service type of attacks, to prevent filling up the heap or disk space</description><defaultValue>1 MB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>multipart-read-buffer-size</name><displayName>Multipart Read Buffer Size</displayName><description>The threshold size, at which the contents of an incoming file would be written to disk. Only applies for requests with Content-Type: multipart/form-data. It is used to prevent denial of service type of attacks, to prevent filling up the heap or disk space.</description><defaultValue>512 KB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>max-thread-pool-size</name><displayName>Maximum Thread Pool Size</displayName><description>The maximum number of threads to be used by the embedded Jetty server. The value can be set between 8 and 1000. The value of this property affects the performance of the flows and the operating system, therefore the default value should only be changed in justified cases. A value that is less than the default value may be suitable if only a small number of HTTP clients connect to the server. A greater value may be suitable if a large number of HTTP clients are expected to make requests to the server simultaneously.</description><defaultValue>200</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>record-reader</name><displayName>Record Reader</displayName><description>The Record Reader to use parsing the incoming FlowFile into Records</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>record-writer</name><displayName>Record Writer</displayName><description>The Record Writer to use for serializing Records after they have been transformed</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>record-reader</propertyName><propertyDisplayName>Record Reader</propertyDisplayName></dependency></dependencies></property></properties><relationships><relationship><name>success</name><description>Relationship for successfully received FlowFiles</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><inputRequirement>INPUT_FORBIDDEN</inputRequirement><useCases><useCase><description>Unpack FlowFileV3 content received in a POST</description><notes>POST requests with "Content-Type: application/flowfile-v3" will have their payload interpreted as FlowFileV3 format
and will be automatically unpacked. This will output the original FlowFile(s) from within the FlowFileV3 format and
will not require a separate UnpackContent processor.
</notes><keywords><keyword>flowfile</keyword><keyword>flowfilev3</keyword><keyword>unpack</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>This feature of ListenHTTP is always on, no configuration required.

The MergeContent and PackageFlowFile processors can generate FlowFileV3 formatted data.
</configuration></useCase></useCases><multiProcessorUseCases><multiProcessorUseCase><description>Limit the date flow rate that is accepted</description><notes>When ListenHTTP cannot output FlowFiles due to back pressure, it will send HTTP 503 Service Unavailable
response to clients, or deny connections, until more space is available in the output queue.
</notes><keywords><keyword>rate</keyword><keyword>limit</keyword></keywords><processorConfigurations><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.ListenHTTP</processorClassName><configuration>Connect the 'success' relationship of ListenHTTP to a ControlRate processor and configure back pressure on that
connection so that a small amount of data will fill the queue. The size of the back pressure configuration
determines how much data to buffer to handle spikes in rate without affecting clients.
</configuration></processorConfiguration><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.ControlRate</processorClassName><configuration>Use the ControlRate properties to set the desired data flow rate limit. When the limit it reached,
the ControlRate input connection will start accumulating files. When this connection is full, ListenHTTP
will limit the input data flow rate.
</configuration></processorConfiguration></processorConfigurations></multiProcessorUseCase></multiProcessorUseCases></extension><extension><name>org.apache.nifi.processors.standard.ListenSyslog</name><type>PROCESSOR</type><description>Listens for Syslog messages being sent to a given port over TCP or UDP. Incoming messages are checked against regular expressions for RFC5424 and RFC3164 formatted messages. The format of each message is: (&lt;PRIORITY&gt;)(VERSION )(TIMESTAMP) (HOSTNAME) (BODY) where version is optional. The timestamp can be an RFC5424 timestamp with a format of "yyyy-MM-dd'T'HH:mm:ss.SZ" or "yyyy-MM-dd'T'HH:mm:ss.S+hh:mm", or it can be an RFC3164 timestamp with a format of "MMM d HH:mm:ss". If an incoming messages matches one of these patterns, the message will be parsed and the individual pieces will be placed in FlowFile attributes, with the original message in the content of the FlowFile. If an incoming message does not match one of these patterns it will not be parsed and the syslog.valid attribute will be set to false with the original message in the content of the FlowFile. Valid messages will be transferred on the success relationship, and invalid messages will be transferred on the invalid relationship.</description><tags><tag>syslog</tag><tag>listen</tag><tag>udp</tag><tag>tcp</tag><tag>logs</tag></tags><properties><property><name>Protocol</name><displayName>Protocol</displayName><description>The protocol for Syslog communication.</description><defaultValue>UDP</defaultValue><allowableValues><allowableValue><displayName>TCP</displayName><value>TCP</value><description></description></allowableValue><allowableValue><displayName>UDP</displayName><value>UDP</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Port</name><displayName>Port</displayName><description>The port for Syslog communication. Note that Expression language is not evaluated per FlowFile.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Local Network Interface</name><displayName>Local Network Interface</displayName><description>The name of a local network interface to be used to restrict listening to a specific LAN.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>socket-keep-alive</name><displayName>Socket Keep Alive</displayName><description>Whether or not to have TCP socket keep alive turned on. Timing details depend on operating system properties.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Protocol</propertyName><propertyDisplayName>Protocol</propertyDisplayName><dependentValues><dependentValue>TCP</dependentValue></dependentValues></dependency></dependencies></property><property><name>SSL Context Service</name><displayName>SSL Context Service</displayName><description>The Controller Service to use in order to obtain an SSL Context. If this property is set, syslog messages will be received over a secure connection.</description><controllerServiceDefinition><className>org.apache.nifi.ssl.SSLContextProvider</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Protocol</propertyName><propertyDisplayName>Protocol</propertyDisplayName><dependentValues><dependentValue>TCP</dependentValue></dependentValues></dependency></dependencies></property><property><name>Client Auth</name><displayName>Client Auth</displayName><description>The client authentication policy to use for the SSL Context. Only used if an SSL Context Service is provided.</description><defaultValue>REQUIRED</defaultValue><allowableValues><allowableValue><displayName>WANT</displayName><value>WANT</value><description></description></allowableValue><allowableValue><displayName>REQUIRED</displayName><value>REQUIRED</value><description></description></allowableValue><allowableValue><displayName>NONE</displayName><value>NONE</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>SSL Context Service</propertyName><propertyDisplayName>SSL Context Service</propertyDisplayName></dependency></dependencies></property><property><name>Receive Buffer Size</name><displayName>Receive Buffer Size</displayName><description>The size of each buffer used to receive Syslog messages. Adjust this value appropriately based on the expected size of the incoming Syslog messages. When UDP is selected each buffer will hold one Syslog message. When TCP is selected messages are read from an incoming connection until the buffer is full, or the connection is closed. </description><defaultValue>65507 B</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Size of Message Queue</name><displayName>Max Size of Message Queue</displayName><description>The maximum size of the internal queue used to buffer messages being transferred from the underlying channel to the processor. Setting this value higher allows more messages to be buffered in memory during surges of incoming messages, but increases the total memory used by the processor.</description><defaultValue>10000</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Size of Socket Buffer</name><displayName>Max Size of Socket Buffer</displayName><description>The maximum size of the socket buffer that should be used. This is a suggestion to the Operating System to indicate how big the socket buffer should be. If this value is set too low, the buffer may fill up before the data can be read, and incoming data will be dropped.</description><defaultValue>1 MB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Protocol</propertyName><propertyDisplayName>Protocol</propertyDisplayName><dependentValues><dependentValue>TCP</dependentValue></dependentValues></dependency></dependencies></property><property><name>Max Number of TCP Connections</name><displayName>Max Number of TCP Connections</displayName><description>The maximum number of concurrent connections to accept Syslog messages in TCP mode.</description><defaultValue>2</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Protocol</propertyName><propertyDisplayName>Protocol</propertyDisplayName><dependentValues><dependentValue>TCP</dependentValue></dependentValues></dependency></dependencies></property><property><name>Max Batch Size</name><displayName>Max Batch Size</displayName><description>The maximum number of Syslog events to add to a single FlowFile. If multiple events are available, they will be concatenated along with the &lt;Message Delimiter&gt; up to this configured maximum number of messages</description><defaultValue>1</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Message Delimiter</name><displayName>Message Delimiter</displayName><description>Specifies the delimiter to place between Syslog messages when multiple messages are bundled together (see &lt;Max Batch Size&gt; property).</description><defaultValue>\n</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Parse Messages</name><displayName>Parse Messages</displayName><description>Indicates if the processor should parse the Syslog messages. If set to false, each outgoing FlowFile will only contain the sender, protocol, and port, and no additional attributes.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Character Set</name><displayName>Character Set</displayName><description>Specifies the character set of the Syslog messages. Note that Expression language is not evaluated per FlowFile.</description><defaultValue>UTF-8</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>invalid</name><description>Syslog messages that do not match one of the expected formats will be sent out this relationship as a FlowFile per message.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>Syslog messages that match one of the expected formats will be sent out this relationship as a FlowFile per message.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>syslog.priority</name><description>The priority of the Syslog message.</description></writesAttribute><writesAttribute><name>syslog.severity</name><description>The severity of the Syslog message derived from the priority.</description></writesAttribute><writesAttribute><name>syslog.facility</name><description>The facility of the Syslog message derived from the priority.</description></writesAttribute><writesAttribute><name>syslog.version</name><description>The optional version from the Syslog message.</description></writesAttribute><writesAttribute><name>syslog.timestamp</name><description>The timestamp of the Syslog message.</description></writesAttribute><writesAttribute><name>syslog.hostname</name><description>The hostname or IP address of the Syslog message.</description></writesAttribute><writesAttribute><name>syslog.sender</name><description>The hostname of the Syslog server that sent the message.</description></writesAttribute><writesAttribute><name>syslog.body</name><description>The body of the Syslog message, everything after the hostname.</description></writesAttribute><writesAttribute><name>syslog.valid</name><description>An indicator of whether this message matched the expected formats. If this value is false, the other attributes will be empty and only the original message will be available in the content.</description></writesAttribute><writesAttribute><name>syslog.protocol</name><description>The protocol over which the Syslog message was received.</description></writesAttribute><writesAttribute><name>syslog.port</name><description>The port over which the Syslog message was received.</description></writesAttribute><writesAttribute><name>mime.type</name><description>The mime.type of the FlowFile which will be text/plain for Syslog messages.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_FORBIDDEN</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.PutSyslog</see><see>org.apache.nifi.processors.standard.ParseSyslog</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.ListenTCP</name><type>PROCESSOR</type><description>Listens for incoming TCP connections and reads data from each connection using a line separator as the message demarcator. The default behavior is for each message to produce a single FlowFile, however this can be controlled by increasing the Batch Size to a larger value for higher throughput. The Receive Buffer Size must be set as large as the largest messages expected to be received, meaning if every 100kb there is a line separator, then the Receive Buffer Size must be greater than 100kb. The processor can be configured to use an SSL Context Service to only allow secure connections. When connected clients present certificates for mutual TLS authentication, the Distinguished Names of the client certificate's issuer and subject are added to the outgoing FlowFiles as attributes. The processor does not perform authorization based on Distinguished Name values, but since these values are attached to the outgoing FlowFiles, authorization can be implemented based on these attributes.</description><tags><tag>listen</tag><tag>tcp</tag><tag>tls</tag><tag>ssl</tag></tags><properties><property><name>Local Network Interface</name><displayName>Local Network Interface</displayName><description>The name of a local network interface to be used to restrict listening to a specific LAN.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Port</name><displayName>Port</displayName><description>The port to listen on for communication.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Receive Buffer Size</name><displayName>Receive Buffer Size</displayName><description>The size of each buffer used to receive messages. Adjust this value appropriately based on the expected size of the incoming messages.</description><defaultValue>65507 B</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Size of Message Queue</name><displayName>Max Size of Message Queue</displayName><description>The maximum size of the internal queue used to buffer messages being transferred from the underlying channel to the processor. Setting this value higher allows more messages to be buffered in memory during surges of incoming messages, but increases the total memory used by the processor during these surges.</description><defaultValue>10000</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Size of Socket Buffer</name><displayName>Max Size of Socket Buffer</displayName><description>The maximum size of the socket buffer that should be used. This is a suggestion to the Operating System to indicate how big the socket buffer should be. If this value is set too low, the buffer may fill up before the data can be read, and incoming data will be dropped.</description><defaultValue>1 MB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Character Set</name><displayName>Character Set</displayName><description>Specifies the character set of the received data.</description><defaultValue>UTF-8</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Number of TCP Connections</name><displayName>Max Number of Worker Threads</displayName><description>The maximum number of worker threads available for servicing TCP connections.</description><defaultValue>2</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Batch Size</name><displayName>Max Batch Size</displayName><description>The maximum number of messages to add to a single FlowFile. If multiple messages are available, they will be concatenated along with the &lt;Message Delimiter&gt; up to this configured maximum number of messages</description><defaultValue>1</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Message Delimiter</name><displayName>Batching Message Delimiter</displayName><description>Specifies the delimiter to place between messages when multiple messages are bundled together (see &lt;Max Batch Size&gt; property).</description><defaultValue>\n</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>idle-timeout</name><displayName>Idle Connection Timeout</displayName><description>The amount of time a client's connection will remain open if no data is received. The default of 0 seconds will leave connections open until they are closed by the client.</description><defaultValue>0 seconds</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>pool-receive-buffers</name><displayName>Pool Receive Buffers</displayName><description>Enable or disable pooling of buffers that the processor uses for handling bytes received on socket connections. The framework allocates buffers as needed during processing.</description><defaultValue>True</defaultValue><allowableValues><allowableValue><displayName>True</displayName><value>True</value><description></description></allowableValue><allowableValue><displayName>False</displayName><value>False</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>SSL Context Service</name><displayName>SSL Context Service</displayName><description>The Controller Service to use in order to obtain an SSL Context. If this property is set, messages will be received over a secure connection.</description><controllerServiceDefinition><className>org.apache.nifi.ssl.SSLContextProvider</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Client Auth</name><displayName>Client Auth</displayName><description>The client authentication policy to use for the SSL Context. Only used if an SSL Context Service is provided.</description><defaultValue>REQUIRED</defaultValue><allowableValues><allowableValue><displayName>WANT</displayName><value>WANT</value><description></description></allowableValue><allowableValue><displayName>REQUIRED</displayName><value>REQUIRED</value><description></description></allowableValue><allowableValue><displayName>NONE</displayName><value>NONE</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>SSL Context Service</propertyName><propertyDisplayName>SSL Context Service</propertyDisplayName></dependency></dependencies></property></properties><relationships><relationship><name>success</name><description>Messages received successfully will be sent out this relationship.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>tcp.sender</name><description>The sending host of the messages.</description></writesAttribute><writesAttribute><name>tcp.port</name><description>The sending port the messages were received.</description></writesAttribute><writesAttribute><name>client.certificate.issuer.dn</name><description>For connections using mutual TLS, the Distinguished Name of the Certificate Authority that issued the client's certificate is attached to the FlowFile.</description></writesAttribute><writesAttribute><name>client.certificate.subject.dn</name><description>For connections using mutual TLS, the Distinguished Name of the client certificate's owner (subject) is attached to the FlowFile.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_FORBIDDEN</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.ListenUDP</name><type>PROCESSOR</type><description>Listens for Datagram Packets on a given port. The default behavior produces a FlowFile per datagram, however for higher throughput the Max Batch Size property may be increased to specify the number of datagrams to batch together in a single FlowFile. This processor can be restricted to listening for datagrams from  a specific remote host and port by specifying the Sending Host and Sending Host Port properties, otherwise it will listen for datagrams from all hosts and ports.</description><tags><tag>ingest</tag><tag>udp</tag><tag>listen</tag><tag>source</tag></tags><properties><property><name>Local Network Interface</name><displayName>Local Network Interface</displayName><description>The name of a local network interface to be used to restrict listening to a specific LAN.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Port</name><displayName>Port</displayName><description>The port to listen on for communication.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Receive Buffer Size</name><displayName>Receive Buffer Size</displayName><description>The size of each buffer used to receive messages. Adjust this value appropriately based on the expected size of the incoming messages.</description><defaultValue>65507 B</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Size of Message Queue</name><displayName>Max Size of Message Queue</displayName><description>The maximum size of the internal queue used to buffer messages being transferred from the underlying channel to the processor. Setting this value higher allows more messages to be buffered in memory during surges of incoming messages, but increases the total memory used by the processor.</description><defaultValue>10000</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Size of Socket Buffer</name><displayName>Max Size of Socket Buffer</displayName><description>The maximum size of the socket buffer that should be used. This is a suggestion to the Operating System to indicate how big the socket buffer should be. If this value is set too low, the buffer may fill up before the data can be read, and incoming data will be dropped.</description><defaultValue>1 MB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Character Set</name><displayName>Character Set</displayName><description>Specifies the character set of the received data.</description><defaultValue>UTF-8</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Batch Size</name><displayName>Max Batch Size</displayName><description>The maximum number of messages to add to a single FlowFile. If multiple messages are available, they will be concatenated along with the &lt;Message Delimiter&gt; up to this configured maximum number of messages</description><defaultValue>1</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Message Delimiter</name><displayName>Batching Message Delimiter</displayName><description>Specifies the delimiter to place between messages when multiple messages are bundled together (see &lt;Max Batch Size&gt; property).</description><defaultValue>\n</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Sending Host</name><displayName>Sending Host</displayName><description>IP, or name, of a remote host. Only Datagrams from the specified Sending Host Port and this host will be accepted. Improves Performance. May be a system property or an environment variable.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Sending Host Port</name><displayName>Sending Host Port</displayName><description>Port being used by remote host to send Datagrams. Only Datagrams from the specified Sending Host and this port will be accepted. Improves Performance. May be a system property or an environment variable.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>success</name><description>Messages received successfully will be sent out this relationship.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>udp.sender</name><description>The sending host of the messages.</description></writesAttribute><writesAttribute><name>udp.port</name><description>The sending port the messages were received.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_FORBIDDEN</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.ListenUDPRecord</name><type>PROCESSOR</type><description>Listens for Datagram Packets on a given port and reads the content of each datagram using the configured Record Reader. Each record will then be written to a flow file using the configured Record Writer. This processor can be restricted to listening for datagrams from  a specific remote host and port by specifying the Sending Host and Sending Host Port properties, otherwise it will listen for datagrams from all hosts and ports.</description><tags><tag>ingest</tag><tag>udp</tag><tag>listen</tag><tag>source</tag><tag>record</tag></tags><properties><property><name>Local Network Interface</name><displayName>Local Network Interface</displayName><description>The name of a local network interface to be used to restrict listening to a specific LAN.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Port</name><displayName>Port</displayName><description>The port to listen on for communication.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Receive Buffer Size</name><displayName>Receive Buffer Size</displayName><description>The size of each buffer used to receive messages. Adjust this value appropriately based on the expected size of the incoming messages.</description><defaultValue>65507 B</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Size of Message Queue</name><displayName>Max Size of Message Queue</displayName><description>The maximum size of the internal queue used to buffer messages being transferred from the underlying channel to the processor. Setting this value higher allows more messages to be buffered in memory during surges of incoming messages, but increases the total memory used by the processor.</description><defaultValue>10000</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Size of Socket Buffer</name><displayName>Max Size of Socket Buffer</displayName><description>The maximum size of the socket buffer that should be used. This is a suggestion to the Operating System to indicate how big the socket buffer should be. If this value is set too low, the buffer may fill up before the data can be read, and incoming data will be dropped.</description><defaultValue>1 MB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Character Set</name><displayName>Character Set</displayName><description>Specifies the character set of the received data.</description><defaultValue>UTF-8</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>poll-timeout</name><displayName>Poll Timeout</displayName><description>The amount of time to wait when polling the internal queue for more datagrams. If no datagrams are found after waiting for the configured timeout, then the processor will emit whatever records have been obtained up to that point.</description><defaultValue>50 ms</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>batch-size</name><displayName>Batch Size</displayName><description>The maximum number of datagrams to write as records to a single FlowFile. The Batch Size will only be reached when data is coming in more frequently than the Poll Timeout.</description><defaultValue>1000</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>record-reader</name><displayName>Record Reader</displayName><description>The Record Reader to use for reading the content of incoming datagrams.</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>record-writer</name><displayName>Record Writer</displayName><description>The Record Writer to use in order to serialize the data before writing to a flow file.</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>sending-host</name><displayName>Sending Host</displayName><description>IP, or name, of a remote host. Only Datagrams from the specified Sending Host Port and this host will be accepted. Improves Performance. May be a system property or an environment variable.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>sending-host-port</name><displayName>Sending Host Port</displayName><description>Port being used by remote host to send Datagrams. Only Datagrams from the specified Sending Host and this port will be accepted. Improves Performance. May be a system property or an environment variable.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>parse.failure</name><description>If a datagram cannot be parsed using the configured Record Reader, the contents of the message will be routed to this Relationship as its own individual FlowFile.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>Messages received successfully will be sent out this relationship.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>udp.sender</name><description>The sending host of the messages.</description></writesAttribute><writesAttribute><name>udp.port</name><description>The sending port the messages were received.</description></writesAttribute><writesAttribute><name>record.count</name><description>The number of records written to the flow file.</description></writesAttribute><writesAttribute><name>mime.type</name><description>The mime-type of the writer used to write the records to the flow file.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_FORBIDDEN</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.LogAttribute</name><type>PROCESSOR</type><description>Emits attributes of the FlowFile at the specified log level</description><tags><tag>attributes</tag><tag>logging</tag></tags><properties><property><name>Log Level</name><displayName>Log Level</displayName><description>The Log Level to use when logging the Attributes</description><defaultValue>info</defaultValue><allowableValues><allowableValue><displayName>trace</displayName><value>trace</value><description></description></allowableValue><allowableValue><displayName>debug</displayName><value>debug</value><description></description></allowableValue><allowableValue><displayName>info</displayName><value>info</value><description></description></allowableValue><allowableValue><displayName>warn</displayName><value>warn</value><description></description></allowableValue><allowableValue><displayName>error</displayName><value>error</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Log Payload</name><displayName>Log Payload</displayName><description>If true, the FlowFile's payload will be logged, in addition to its attributes; otherwise, just the Attributes will be logged.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Attributes to Log</name><displayName>Attributes to Log</displayName><description>A comma-separated list of Attributes to Log. If not specified, all attributes will be logged unless `Attributes to Log by Regular Expression` is modified. There's an AND relationship between the two properties.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>attributes-to-log-regex</name><displayName>Attributes to Log by Regular Expression</displayName><description>A regular expression indicating the Attributes to Log. If not specified, all attributes will be logged unless `Attributes to Log` is modified. There's an AND relationship between the two properties.</description><defaultValue>.*</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Attributes to Ignore</name><displayName>Attributes to Ignore</displayName><description>A comma-separated list of Attributes to ignore. If not specified, no attributes will be ignored unless `Attributes to Ignore by Regular Expression` is modified. There's an OR relationship between the two properties.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>attributes-to-ignore-regex</name><displayName>Attributes to Ignore by Regular Expression</displayName><description>A regular expression indicating the Attributes to Ignore. If not specified, no attributes will be ignored unless `Attributes to Ignore` is modified. There's an OR relationship between the two properties.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Log FlowFile Properties</name><displayName>Log FlowFile Properties</displayName><description>Specifies whether or not to log FlowFile "properties", such as Entry Date, Lineage Start Date, and content size</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Output Format</name><displayName>Output Format</displayName><description>Specifies the format to use for logging FlowFile attributes</description><defaultValue>Line per Attribute</defaultValue><allowableValues><allowableValue><displayName>Line per Attribute</displayName><value>Line per Attribute</value><description>Each FlowFile attribute will be logged using a single line for the attribute name and another line for the attribute value. This format is often most advantageous when looking at the attributes of a single FlowFile.</description></allowableValue><allowableValue><displayName>Single Line</displayName><value>Single Line</value><description>All FlowFile attribute names and values will be logged on a single line. This format is often most advantageous when comparing logs from multiple FlowFiles.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Log prefix</name><displayName>Log prefix</displayName><description>Log prefix appended to the log lines. It helps to distinguish the output of multiple LogAttribute processors.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>character-set</name><displayName>Character Set</displayName><description>The name of the CharacterSet to use</description><defaultValue>UTF-8</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>success</name><description>All FlowFiles are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.LogMessage</name><type>PROCESSOR</type><description>Emits a log message at the specified log level</description><tags><tag>attributes</tag><tag>logging</tag></tags><properties><property><name>log-level</name><displayName>Log Level</displayName><description>The Log Level to use when logging the message: [trace, debug, info, warn, error]</description><defaultValue>info</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>log-prefix</name><displayName>Log prefix</displayName><description>Log prefix appended to the log lines. It helps to distinguish the output of multiple LogMessage processors.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>log-message</name><displayName>Log message</displayName><description>The log message to emit</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>success</name><description>All FlowFiles are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.LookupAttribute</name><type>PROCESSOR</type><description>Lookup attributes from a lookup service</description><tags><tag>lookup</tag><tag>cache</tag><tag>enrich</tag><tag>join</tag><tag>attributes</tag><tag>Attribute Expression Language</tag></tags><properties><property><name>lookup-service</name><displayName>Lookup Service</displayName><description>The lookup service to use for attribute lookups</description><controllerServiceDefinition><className>org.apache.nifi.lookup.StringLookupService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>include-empty-values</name><displayName>Include Empty Values</displayName><description>Include null or blank values for keys that are null or blank</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>The name of the attribute to add to the FlowFile</name><value>The name of the key or property to retrieve from the lookup service</value><description>Adds a FlowFile attribute specified by the dynamic property's key with the value found in the lookup service using the the dynamic property's value</description><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>failure</name><description>FlowFiles with failing lookups are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>matched</name><description>FlowFiles with matching lookups are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>unmatched</name><description>FlowFiles with missing lookups are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.LookupRecord</name><type>PROCESSOR</type><description>Extracts one or more fields from a Record and looks up a value for those fields in a LookupService. If a result is returned by the LookupService, that result is optionally added to the Record. In this case, the processor functions as an Enrichment processor. Regardless, the Record is then routed to either the 'matched' relationship or 'unmatched' relationship (if the 'Routing Strategy' property is configured to do so), indicating whether or not a result was returned by the LookupService, allowing the processor to also function as a Routing processor. The "coordinates" to use for looking up a value in the Lookup Service are defined by adding a user-defined property. Each property that is added will have an entry added to a Map, where the name of the property becomes the Map Key and the value returned by the RecordPath becomes the value for that key. If multiple values are returned by the RecordPath, then the Record will be routed to the 'unmatched' relationship (or 'success', depending on the 'Routing Strategy' property's configuration). If one or more fields match the Result RecordPath, all fields that match will be updated. If there is no match in the configured LookupService, then no fields will be updated. I.e., it will not overwrite an existing value in the Record with a null value. Please note, however, that if the results returned by the LookupService are not accounted for in your schema (specifically, the schema that is configured for your Record Writer) then the fields will not be written out to the FlowFile.</description><tags><tag>lookup</tag><tag>enrichment</tag><tag>route</tag><tag>record</tag><tag>csv</tag><tag>json</tag><tag>avro</tag><tag>database</tag><tag>db</tag><tag>logs</tag><tag>convert</tag><tag>filter</tag></tags><properties><property><name>record-reader</name><displayName>Record Reader</displayName><description>Specifies the Controller Service to use for reading incoming data</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>record-writer</name><displayName>Record Writer</displayName><description>Specifies the Controller Service to use for writing out the records</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>lookup-service</name><displayName>Lookup Service</displayName><description>The Lookup Service to use in order to lookup a value in each Record</description><controllerServiceDefinition><className>org.apache.nifi.lookup.LookupService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Root Record Path</name><displayName>Root Record Path</displayName><description>A RecordPath that points to a child Record within each of the top-level Records in the FlowFile. If specified, the additional RecordPath properties will be evaluated against this child Record instead of the top-level Record. This allows for performing enrichment against multiple child Records within a single top-level Record.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>routing-strategy</name><displayName>Routing Strategy</displayName><description>Specifies how to route records after a Lookup has completed</description><defaultValue>route-to-success</defaultValue><allowableValues><allowableValue><displayName>Route to 'success'</displayName><value>route-to-success</value><description>Records will be routed to a 'success' Relationship regardless of whether or not there is a match in the configured Lookup Service</description></allowableValue><allowableValue><displayName>Route to 'matched' or 'unmatched'</displayName><value>route-to-matched-unmatched</value><description>Records will be routed to either a 'matched' or an 'unmatched' Relationship depending on whether or not there was a match in the configured Lookup Service. A single input FlowFile may result in two different output FlowFiles. If the given Record Paths evaluate such that multiple sub-records are evaluated, the parent Record will be routed to 'unmatched' unless all sub-records match.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>result-contents</name><displayName>Record Result Contents</displayName><description>When a result is obtained that contains a Record, this property determines whether the Record itself is inserted at the configured path or if the contents of the Record (i.e., the sub-fields) will be inserted at the configured path.</description><defaultValue>insert-entire-record</defaultValue><allowableValues><allowableValue><displayName>Insert Entire Record</displayName><value>insert-entire-record</value><description>The entire Record that is retrieved from the Lookup Service will be inserted into the destination path.</description></allowableValue><allowableValue><displayName>Insert Record Fields</displayName><value>record-fields</value><description>All of the fields in the Record that is retrieved from the Lookup Service will be inserted into the destination path.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>record-update-strategy</name><displayName>Record Update Strategy</displayName><description>This property defines the strategy to use when updating the record with the value returned by the Lookup Service.</description><defaultValue>use-property</defaultValue><allowableValues><allowableValue><displayName>Replace Existing Values</displayName><value>replace-existing-values</value><description>The "Result RecordPath" property will be ignored and the lookup service must be a single simple key lookup service. Every dynamic property value should be a record path. For each dynamic property, the value contained in the field corresponding to the record path will be used as the key in the Lookup Service and the value returned by the Lookup Service will be used to replace the existing value. It is possible to configure multiple dynamic properties to replace multiple values in one execution. This strategy only supports simple types replacements (strings, integers, etc).</description></allowableValue><allowableValue><displayName>Use "Result RecordPath" Property</displayName><value>use-property</value><description>The "Result RecordPath" property will be used to determine which part of the record should be updated with the value returned by the Lookup Service</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>result-record-path</name><displayName>Result RecordPath</displayName><description>A RecordPath that points to the field whose value should be updated with whatever value is returned from the Lookup Service. If not specified, the value that is returned from the Lookup Service will be ignored, except for determining whether the FlowFile should be routed to the 'matched' or 'unmatched' Relationship.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>record-update-strategy</propertyName><propertyDisplayName>Record Update Strategy</propertyDisplayName><dependentValues><dependentValue>use-property</dependentValue></dependentValues></dependency></dependencies></property><property><name>record-path-lookup-miss-result-cache-size</name><displayName>Cache Size</displayName><description>Specifies how many lookup values/records should be cached.Setting this property to zero means no caching will be done and the table will be queried for each lookup value in each record. If the lookup table changes often or the most recent data must be retrieved, do not use the cache.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>Value To Lookup</name><value>Valid Record Path</value><description>A RecordPath that points to the field whose value will be looked up in the configured Lookup Service</description><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>failure</name><description>If a FlowFile cannot be enriched, the unchanged FlowFile will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>All records will be sent to this Relationship if configured to do so, unless a failure occurs</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>mime.type</name><description>Sets the mime.type attribute to the MIME Type specified by the Record Writer</description></writesAttribute><writesAttribute><name>record.count</name><description>The number of records in the FlowFile</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.ConvertRecord</see><see>org.apache.nifi.processors.standard.SplitRecord</see><see>org.apache.nifi.lookup.SimpleKeyValueLookupService</see><see>org.apache.nifi.lookup.maxmind.IPLookupService</see><see>org.apache.nifi.lookup.db.DatabaseRecordLookupService</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.MergeContent</name><type>PROCESSOR</type><description>Merges a Group of FlowFiles together based on a user-defined strategy and packages them into a single FlowFile. It is recommended that the Processor be configured with only a single incoming connection, as Group of FlowFiles will not be created from FlowFiles in different connections. This processor updates the mime.type attribute as appropriate. NOTE: this processor should NOT be configured with Cron Driven for the Scheduling Strategy.</description><tags><tag>merge</tag><tag>content</tag><tag>correlation</tag><tag>tar</tag><tag>zip</tag><tag>stream</tag><tag>concatenation</tag><tag>archive</tag><tag>flowfile-stream</tag><tag>flowfile-stream-v3</tag></tags><properties><property><name>Merge Strategy</name><displayName>Merge Strategy</displayName><description>Specifies the algorithm used to merge content. The 'Defragment' algorithm combines fragments that are associated by attributes back into a single cohesive FlowFile. The 'Bin-Packing Algorithm' generates a FlowFile populated by arbitrarily chosen FlowFiles</description><defaultValue>Bin-Packing Algorithm</defaultValue><allowableValues><allowableValue><displayName>Bin-Packing Algorithm</displayName><value>Bin-Packing Algorithm</value><description>Generates 'bins' of FlowFiles and fills each bin as full as possible. FlowFiles are placed into a bin based on their size and optionally their attributes (if the &lt;Correlation Attribute&gt; property is set)</description></allowableValue><allowableValue><displayName>Defragment</displayName><value>Defragment</value><description>Combines fragments that are associated by attributes back into a single cohesive FlowFile. If using this strategy, all FlowFiles must have the attributes &lt;fragment.identifier&gt;, &lt;fragment.count&gt;, and &lt;fragment.index&gt;. All FlowFiles with the same value for "fragment.identifier" will be grouped together. All FlowFiles in this group must have the same value for the "fragment.count" attribute. All FlowFiles in this group must have a unique value for the "fragment.index" attribute between 0 and the value of the "fragment.count" attribute.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Merge Format</name><displayName>Merge Format</displayName><description>Determines the format that will be used to merge the content.</description><defaultValue>Binary Concatenation</defaultValue><allowableValues><allowableValue><displayName>TAR</displayName><value>TAR</value><description>A bin of FlowFiles will be combined into a single TAR file. The FlowFiles' &lt;path&gt; attribute will be used to create a directory in the TAR file if the &lt;Keep Paths&gt; property is set to true; otherwise, all FlowFiles will be added at the root of the TAR file. If a FlowFile has an attribute named &lt;tar.permissions&gt; that is 3 characters, each between 0-7, that attribute will be used as the TAR entry's 'mode'.</description></allowableValue><allowableValue><displayName>ZIP</displayName><value>ZIP</value><description>A bin of FlowFiles will be combined into a single ZIP file. The FlowFiles' &lt;path&gt; attribute will be used to create a directory in the ZIP file if the &lt;Keep Paths&gt; property is set to true; otherwise, all FlowFiles will be added at the root of the ZIP file. The &lt;Compression Level&gt; property indicates the ZIP compression to use.</description></allowableValue><allowableValue><displayName>FlowFile Stream, v3</displayName><value>FlowFile Stream, v3</value><description>A bin of FlowFiles will be combined into a single Version 3 FlowFile Stream</description></allowableValue><allowableValue><displayName>FlowFile Stream, v2</displayName><value>FlowFile Stream, v2</value><description>A bin of FlowFiles will be combined into a single Version 2 FlowFile Stream</description></allowableValue><allowableValue><displayName>FlowFile Tar, v1</displayName><value>FlowFile Tar, v1</value><description>A bin of FlowFiles will be combined into a single Version 1 FlowFile Package</description></allowableValue><allowableValue><displayName>Binary Concatenation</displayName><value>Binary Concatenation</value><description>The contents of all FlowFiles will be concatenated together into a single FlowFile</description></allowableValue><allowableValue><displayName>Avro</displayName><value>Avro</value><description>The Avro contents of all FlowFiles will be concatenated together into a single FlowFile</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Attribute Strategy</name><displayName>Attribute Strategy</displayName><description>Determines which FlowFile attributes should be added to the bundle. If 'Keep All Unique Attributes' is selected, any attribute on any FlowFile that gets bundled will be kept unless its value conflicts with the value from another FlowFile. If 'Keep Only Common Attributes' is selected, only the attributes that exist on all FlowFiles in the bundle, with the same value, will be preserved.</description><defaultValue>Keep Only Common Attributes</defaultValue><allowableValues><allowableValue><displayName>Keep Only Common Attributes</displayName><value>Keep Only Common Attributes</value><description>Any attribute that is not the same on all FlowFiles in a bin will be dropped. Those that are the same across all FlowFiles will be retained.</description></allowableValue><allowableValue><displayName>Keep All Unique Attributes</displayName><value>Keep All Unique Attributes</value><description>Any attribute that has the same value for all FlowFiles in a bin, or has no value for a FlowFile, will be kept. For example, if a bin consists of 3 FlowFiles and 2 of them have a value of 'hello' for the 'greeting' attribute and the third FlowFile has no 'greeting' attribute then the outbound FlowFile will get a 'greeting' attribute with the value 'hello'.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Correlation Attribute Name</name><displayName>Correlation Attribute Name</displayName><description>If specified, like FlowFiles will be binned together, where 'like FlowFiles' means FlowFiles that have the same value for this Attribute. If not specified, FlowFiles are bundled by the order in which they are pulled from the queue.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Merge Strategy</propertyName><propertyDisplayName>Merge Strategy</propertyDisplayName><dependentValues><dependentValue>Bin-Packing Algorithm</dependentValue></dependentValues></dependency></dependencies></property><property><name>mergecontent-metadata-strategy</name><displayName>Metadata Strategy</displayName><description>For FlowFiles whose input format supports metadata (Avro, e.g.), this property determines which metadata should be added to the bundle. If 'Use First Metadata' is selected, the metadata keys/values from the first FlowFile to be bundled will be used. If 'Keep Only Common Metadata' is selected, only the metadata that exists on all FlowFiles in the bundle, with the same value, will be preserved. If 'Ignore Metadata' is selected, no metadata is transferred to the outgoing bundled FlowFile. If 'Do Not Merge Uncommon Metadata' is selected, any FlowFile whose metadata values do not match those of the first bundled FlowFile will not be merged.</description><defaultValue>Do Not Merge Uncommon Metadata</defaultValue><allowableValues><allowableValue><displayName>Use First Metadata</displayName><value>Use First Metadata</value><description>For any input format that supports metadata (Avro, e.g.), the metadata for the first FlowFile in the bin will be set on the output FlowFile.</description></allowableValue><allowableValue><displayName>Keep Only Common Metadata</displayName><value>Keep Only Common Metadata</value><description>For any input format that supports metadata (Avro, e.g.), any FlowFile whose metadata values match those of the first FlowFile, any additional metadata will be dropped but the FlowFile will be merged. Any FlowFile whose metadata values do not match those of the first FlowFile in the bin will not be merged.</description></allowableValue><allowableValue><displayName>Ignore Metadata</displayName><value>Ignore Metadata</value><description>Ignores (does not transfer, compare, etc.) any metadata from a FlowFile whose content supports embedded metadata.</description></allowableValue><allowableValue><displayName>Do Not Merge Uncommon Metadata</displayName><value>Do Not Merge Uncommon Metadata</value><description>For any input format that supports metadata (Avro, e.g.), any FlowFile whose metadata values do not match those of the first FlowFile in the bin will not be merged.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Merge Format</propertyName><propertyDisplayName>Merge Format</propertyDisplayName><dependentValues><dependentValue>Avro</dependentValue></dependentValues></dependency></dependencies></property><property><name>Minimum Number of Entries</name><displayName>Minimum Number of Entries</displayName><description>The minimum number of files to include in a bundle</description><defaultValue>1</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Merge Strategy</propertyName><propertyDisplayName>Merge Strategy</propertyDisplayName><dependentValues><dependentValue>Bin-Packing Algorithm</dependentValue></dependentValues></dependency></dependencies></property><property><name>Maximum Number of Entries</name><displayName>Maximum Number of Entries</displayName><description>The maximum number of files to include in a bundle</description><defaultValue>1000</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Merge Strategy</propertyName><propertyDisplayName>Merge Strategy</propertyDisplayName><dependentValues><dependentValue>Bin-Packing Algorithm</dependentValue></dependentValues></dependency></dependencies></property><property><name>Minimum Group Size</name><displayName>Minimum Group Size</displayName><description>The minimum size for the bundle</description><defaultValue>0 B</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Merge Strategy</propertyName><propertyDisplayName>Merge Strategy</propertyDisplayName><dependentValues><dependentValue>Bin-Packing Algorithm</dependentValue></dependentValues></dependency></dependencies></property><property><name>Maximum Group Size</name><displayName>Maximum Group Size</displayName><description>The maximum size for the bundle. If not specified, there is no maximum.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Merge Strategy</propertyName><propertyDisplayName>Merge Strategy</propertyDisplayName><dependentValues><dependentValue>Bin-Packing Algorithm</dependentValue></dependentValues></dependency></dependencies></property><property><name>Bin Termination Check</name><displayName>Bin Termination Check</displayName><description>Specifies an Expression Language Expression that is to be evaluated against each FlowFile. If the result of the expression is 'true', the
bin that the FlowFile corresponds to will be terminated, even if the bin has not met the minimum number of entries or minimum size.
Note that if the FlowFile that triggers the termination of the bin is itself larger than the Maximum Bin Size, it will be placed into its
own bin without triggering the termination of any other bin. When using this property, it is recommended to use Prioritizers in the flow's
connections to ensure that the ordering is as desired.
</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Merge Strategy</propertyName><propertyDisplayName>Merge Strategy</propertyDisplayName><dependentValues><dependentValue>Bin-Packing Algorithm</dependentValue></dependentValues></dependency></dependencies></property><property><name>FlowFile Insertion Strategy</name><displayName>FlowFile Insertion Strategy</displayName><description>If a given FlowFile terminates the bin based on the &lt;Bin Termination Check&gt; property, specifies where the FlowFile should be included in the bin.</description><defaultValue>Last in Bin</defaultValue><allowableValues><allowableValue><displayName>Last in Bin</displayName><value>Last in Bin</value><description>Insert the FlowFile at the end of the Bin that is terminated</description></allowableValue><allowableValue><displayName>First in New Bin</displayName><value>First in New Bin</value><description>Insert the FlowFile at the beginning of a newly created Bin</description></allowableValue><allowableValue><displayName>Isolated</displayName><value>Isolated</value><description>Insert the FlowFile into a new Bin and terminate the Bin immediately with the FlowFile as the only content</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Bin Termination Check</propertyName><propertyDisplayName>Bin Termination Check</propertyDisplayName></dependency></dependencies></property><property><name>Max Bin Age</name><displayName>Max Bin Age</displayName><description>The maximum age of a Bin that will trigger a Bin to be complete. Expected format is &lt;duration&gt; &lt;time unit&gt; where &lt;duration&gt; is a positive integer and time unit is one of seconds, minutes, hours</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum number of Bins</name><displayName>Maximum number of Bins</displayName><description>Specifies the maximum number of bins that can be held in memory at any one time</description><defaultValue>5</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Delimiter Strategy</name><displayName>Delimiter Strategy</displayName><description>Determines if Header, Footer, and Demarcator should point to files containing the respective content, or if the values of the properties should be used as the content.</description><defaultValue>Do Not Use Delimiters</defaultValue><allowableValues><allowableValue><displayName>Filename</displayName><value>Filename</value><description>The values of Header, Footer, and Demarcator will be retrieved from the contents of a file</description></allowableValue><allowableValue><displayName>Text</displayName><value>Text</value><description>The values of Header, Footer, and Demarcator will be specified as property values</description></allowableValue><allowableValue><displayName>Do Not Use Delimiters</displayName><value>Do Not Use Delimiters</value><description>No Header, Footer, or Demarcator will be used</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Merge Format</propertyName><propertyDisplayName>Merge Format</propertyDisplayName><dependentValues><dependentValue>Binary Concatenation</dependentValue></dependentValues></dependency></dependencies></property><property><name>Header File</name><displayName>Header</displayName><description>Filename or text specifying the header to use. If not specified, no header is supplied.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType><resourceType>TEXT</resourceType></resourceTypes></resourceDefinition><dependencies><dependency><propertyName>Delimiter Strategy</propertyName><propertyDisplayName>Delimiter Strategy</propertyDisplayName><dependentValues><dependentValue>Filename</dependentValue><dependentValue>Text</dependentValue></dependentValues></dependency><dependency><propertyName>Merge Format</propertyName><propertyDisplayName>Merge Format</propertyDisplayName><dependentValues><dependentValue>Binary Concatenation</dependentValue></dependentValues></dependency></dependencies></property><property><name>Footer File</name><displayName>Footer</displayName><description>Filename or text specifying the footer to use. If not specified, no footer is supplied.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType><resourceType>TEXT</resourceType></resourceTypes></resourceDefinition><dependencies><dependency><propertyName>Delimiter Strategy</propertyName><propertyDisplayName>Delimiter Strategy</propertyDisplayName><dependentValues><dependentValue>Filename</dependentValue><dependentValue>Text</dependentValue></dependentValues></dependency><dependency><propertyName>Merge Format</propertyName><propertyDisplayName>Merge Format</propertyDisplayName><dependentValues><dependentValue>Binary Concatenation</dependentValue></dependentValues></dependency></dependencies></property><property><name>Demarcator File</name><displayName>Demarcator</displayName><description>Filename or text specifying the demarcator to use. If not specified, no demarcator is supplied.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType><resourceType>TEXT</resourceType></resourceTypes></resourceDefinition><dependencies><dependency><propertyName>Delimiter Strategy</propertyName><propertyDisplayName>Delimiter Strategy</propertyDisplayName><dependentValues><dependentValue>Filename</dependentValue><dependentValue>Text</dependentValue></dependentValues></dependency><dependency><propertyName>Merge Format</propertyName><propertyDisplayName>Merge Format</propertyDisplayName><dependentValues><dependentValue>Binary Concatenation</dependentValue></dependentValues></dependency></dependencies></property><property><name>Compression Level</name><displayName>Compression Level</displayName><description>Specifies the compression level to use when using the Zip Merge Format; if not using the Zip Merge Format, this value is ignored</description><defaultValue>1</defaultValue><allowableValues><allowableValue><displayName>0</displayName><value>0</value><description></description></allowableValue><allowableValue><displayName>1</displayName><value>1</value><description></description></allowableValue><allowableValue><displayName>2</displayName><value>2</value><description></description></allowableValue><allowableValue><displayName>3</displayName><value>3</value><description></description></allowableValue><allowableValue><displayName>4</displayName><value>4</value><description></description></allowableValue><allowableValue><displayName>5</displayName><value>5</value><description></description></allowableValue><allowableValue><displayName>6</displayName><value>6</value><description></description></allowableValue><allowableValue><displayName>7</displayName><value>7</value><description></description></allowableValue><allowableValue><displayName>8</displayName><value>8</value><description></description></allowableValue><allowableValue><displayName>9</displayName><value>9</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Merge Format</propertyName><propertyDisplayName>Merge Format</propertyDisplayName><dependentValues><dependentValue>ZIP</dependentValue></dependentValues></dependency></dependencies></property><property><name>Keep Path</name><displayName>Keep Path</displayName><description>If using the Zip or Tar Merge Format, specifies whether or not the FlowFiles' paths should be included in their entry names.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Merge Format</propertyName><propertyDisplayName>Merge Format</propertyDisplayName><dependentValues><dependentValue>TAR</dependentValue><dependentValue>ZIP</dependentValue></dependentValues></dependency></dependencies></property><property><name>Tar Modified Time</name><displayName>Tar Modified Time</displayName><description>If using the Tar Merge Format, specifies if the Tar entry should store the modified timestamp either by expression (e.g. ${file.lastModifiedTime} or static value, both of which must match the ISO8601 format 'yyyy-MM-dd'T'HH:mm:ssZ'.</description><defaultValue>${file.lastModifiedTime}</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Merge Format</propertyName><propertyDisplayName>Merge Format</propertyDisplayName><dependentValues><dependentValue>TAR</dependentValue></dependentValues></dependency></dependencies></property></properties><relationships><relationship><name>failure</name><description>If the bundle cannot be created, all FlowFiles that would have been used to created the bundle will be transferred to failure</description><autoTerminated>false</autoTerminated></relationship><relationship><name>merged</name><description>The FlowFile containing the merged content</description><autoTerminated>false</autoTerminated></relationship><relationship><name>original</name><description>The FlowFiles that were used to create the bundle</description><autoTerminated>false</autoTerminated></relationship></relationships><readsAttributes><readsAttribute><name>fragment.identifier</name><description>Applicable only if the &lt;Merge Strategy&gt; property is set to Defragment. All FlowFiles with the same value for this attribute will be bundled together.</description></readsAttribute><readsAttribute><name>fragment.index</name><description>Applicable only if the &lt;Merge Strategy&gt; property is set to Defragment. This attribute indicates the order in which the fragments should be assembled. This attribute must be present on all FlowFiles when using the Defragment Merge Strategy and must be a unique (i.e., unique across all FlowFiles that have the same value for the "fragment.identifier" attribute) integer between 0 and the value of the fragment.count attribute. If two or more FlowFiles have the same value for the "fragment.identifier" attribute and the same value for the "fragment.index" attribute, the first FlowFile processed will be accepted and subsequent FlowFiles will not be accepted into the Bin.</description></readsAttribute><readsAttribute><name>fragment.count</name><description>Applicable only if the &lt;Merge Strategy&gt; property is set to Defragment. This attribute indicates how many FlowFiles should be expected in the given bundle. At least one FlowFile must have this attribute in the bundle. If multiple FlowFiles contain the "fragment.count" attribute in a given bundle, all must have the same value.</description></readsAttribute><readsAttribute><name>segment.original.filename</name><description>Applicable only if the &lt;Merge Strategy&gt; property is set to Defragment. This attribute must be present on all FlowFiles with the same value for the fragment.identifier attribute. All FlowFiles in the same bundle must have the same value for this attribute. The value of this attribute will be used for the filename of the completed merged FlowFile.</description></readsAttribute><readsAttribute><name>tar.permissions</name><description>Applicable only if the &lt;Merge Format&gt; property is set to TAR. The value of this attribute must be 3 characters; each character must be in the range 0 to 7 (inclusive) and indicates the file permissions that should be used for the FlowFile's TAR entry. If this attribute is missing or has an invalid value, the default value of 644 will be used</description></readsAttribute></readsAttributes><writesAttributes><writesAttribute><name>filename</name><description>When more than 1 file is merged, the filename comes from the segment.original.filename attribute. If that attribute does not exist in the source FlowFiles, then the filename is set to the number of nanoseconds matching system time. Then a filename extension may be applied:if Merge Format is TAR, then the filename will be appended with .tar, if Merge Format is ZIP, then the filename will be appended with .zip, if Merge Format is FlowFileStream, then the filename will be appended with .pkg</description></writesAttribute><writesAttribute><name>merge.count</name><description>The number of FlowFiles that were merged into this bundle</description></writesAttribute><writesAttribute><name>merge.bin.age</name><description>The age of the bin, in milliseconds, when it was merged and output. Effectively this is the greatest amount of time that any FlowFile in this bundle remained waiting in this processor before it was output</description></writesAttribute><writesAttribute><name>merge.uuid</name><description>UUID of the merged flow file that will be added to the original flow files attributes.</description></writesAttribute><writesAttribute><name>merge.reason</name><description>This processor allows for several thresholds to be configured for merging FlowFiles. This attribute indicates which of the Thresholds resulted in the FlowFiles being merged. For an explanation of each of the possible values and their meanings, see the Processor's Usage / documentation and see the 'Additional Details' page.</description></writesAttribute></writesAttributes><triggerWhenEmpty>true</triggerWhenEmpty><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><systemResourceConsiderations><systemResourceConsideration><resource>MEMORY</resource><description>While content is not stored in memory, the FlowFiles' attributes are. The configuration of MergeContent (maximum bin size, maximum group size, maximum bin age, max number of entries) will influence how much memory is used. If merging together many small FlowFiles, a two-stage approach may be necessary in order to avoid excessive use of memory.</description></systemResourceConsideration></systemResourceConsiderations><useCases><useCase><description>Concatenate FlowFiles with textual content together in order to create fewer, larger FlowFiles.</description><notes></notes><keywords><keyword>concatenate</keyword><keyword>bundle</keyword><keyword>aggregate</keyword><keyword>bin</keyword><keyword>merge</keyword><keyword>combine</keyword><keyword>smash</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>"Merge Strategy" = "Bin Packing Algorithm"
"Merge Format" = "Binary Concatenation"
"Delimiter Strategy" = "Text"
"Demarcator" = "\n" (a newline can be inserted by pressing Shift + Enter)
"Minimum Number of Entries" = "1"
"Maximum Number of Entries" = "500000000"
"Minimum Group Size" = the minimum amount of data to write to an output FlowFile. A reasonable value might be "128 MB"
"Maximum Group Size" = the maximum amount of data to write to an output FlowFile. A reasonable value might be "256 MB"
"Max Bin Age" = the maximum amount of time to wait for incoming data before timing out and transferring the FlowFile along even though it is smaller than the Max Bin Age. A reasonable value might be "5 mins"
</configuration></useCase><useCase><description>Concatenate FlowFiles with binary content together in order to create fewer, larger FlowFiles.</description><notes>Not all binary data can be concatenated together. Whether or not this configuration is valid depends on the type of your data.</notes><keywords><keyword>concatenate</keyword><keyword>bundle</keyword><keyword>aggregate</keyword><keyword>bin</keyword><keyword>merge</keyword><keyword>combine</keyword><keyword>smash</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>"Merge Strategy" = "Bin Packing Algorithm"
"Merge Format" = "Binary Concatenation"
"Delimiter Strategy" = "Text"
"Minimum Number of Entries" = "1"
"Maximum Number of Entries" = "500000000"
"Minimum Group Size" = the minimum amount of data to write to an output FlowFile. A reasonable value might be "128 MB"
"Maximum Group Size" = the maximum amount of data to write to an output FlowFile. A reasonable value might be "256 MB"
"Max Bin Age" = the maximum amount of time to wait for incoming data before timing out and transferring the FlowFile along even though it is smaller than the Max Bin Age. A reasonable value might be "5 mins"
</configuration></useCase><useCase><description>Reassemble a FlowFile that was previously split apart into smaller FlowFiles by a processor such as SplitText, UnpackContext, SplitRecord, etc.</description><notes></notes><keywords><keyword>reassemble</keyword><keyword>repack</keyword><keyword>merge</keyword><keyword>recombine</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>"Merge Strategy" = "Defragment"
"Merge Format" = the value of Merge Format depends on the desired output format. If the file was previously zipped together and was split apart by UnpackContent,
    a Merge Format of "ZIP" makes sense. If it was previously a .tar file, a Merge Format of "TAR" makes sense. If the data is textual, "Binary Concatenation" can be
    used to combine the text into a single document.
"Delimiter Strategy" = "Text"
"Max Bin Age" = the maximum amount of time to wait for incoming data before timing out and transferring the fragments to 'failure'. A reasonable value might be "5 mins"

For textual data, "Demarcator" should be set to a newline (\n), set by pressing Shift+Enter in the UI. For binary data, "Demarcator" should be left blank.
</configuration></useCase></useCases><seeAlso><see>org.apache.nifi.processors.standard.SegmentContent</see><see>org.apache.nifi.processors.standard.MergeRecord</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.MergeRecord</name><type>PROCESSOR</type><description>This Processor merges together multiple record-oriented FlowFiles into a single FlowFile that contains all of the Records of the input FlowFiles. This Processor works by creating 'bins' and then adding FlowFiles to these bins until they are full. Once a bin is full, all of the FlowFiles will be combined into a single output FlowFile, and that FlowFile will be routed to the 'merged' Relationship. A bin will consist of potentially many 'like FlowFiles'. In order for two FlowFiles to be considered 'like FlowFiles', they must have the same Schema (as identified by the Record Reader) and, if the &lt;Correlation Attribute Name&gt; property is set, the same value for the specified attribute. See Processor Usage and Additional Details for more information. NOTE: this processor should NOT be configured with Cron Driven for the Scheduling Strategy.</description><tags><tag>merge</tag><tag>record</tag><tag>content</tag><tag>correlation</tag><tag>stream</tag><tag>event</tag></tags><properties><property><name>record-reader</name><displayName>Record Reader</displayName><description>Specifies the Controller Service to use for reading incoming data</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>record-writer</name><displayName>Record Writer</displayName><description>Specifies the Controller Service to use for writing out the records</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>merge-strategy</name><displayName>Merge Strategy</displayName><description>Specifies the algorithm used to merge records. The 'Defragment' algorithm combines fragments that are associated by attributes back into a single cohesive FlowFile. The 'Bin-Packing Algorithm' generates a FlowFile populated by arbitrarily chosen FlowFiles</description><defaultValue>Bin-Packing Algorithm</defaultValue><allowableValues><allowableValue><displayName>Bin-Packing Algorithm</displayName><value>Bin-Packing Algorithm</value><description>Generates 'bins' of FlowFiles and fills each bin as full as possible. FlowFiles are placed into a bin based on their size and optionally their attributes (if the &lt;Correlation Attribute&gt; property is set)</description></allowableValue><allowableValue><displayName>Defragment</displayName><value>Defragment</value><description>Combines fragments that are associated by attributes back into a single cohesive FlowFile. If using this strategy, all FlowFiles must have the attributes &lt;fragment.identifier&gt; and &lt;fragment.count&gt;. All FlowFiles with the same value for "fragment.identifier" will be grouped together. All FlowFiles in this group must have the same value for the "fragment.count" attribute. The ordering of the Records that are output is not guaranteed.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>correlation-attribute-name</name><displayName>Correlation Attribute Name</displayName><description>If specified, two FlowFiles will be binned together only if they have the same value for this Attribute. If not specified, FlowFiles are bundled by the order in which they are pulled from the queue.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Attribute Strategy</name><displayName>Attribute Strategy</displayName><description>Determines which FlowFile attributes should be added to the bundle. If 'Keep All Unique Attributes' is selected, any attribute on any FlowFile that gets bundled will be kept unless its value conflicts with the value from another FlowFile. If 'Keep Only Common Attributes' is selected, only the attributes that exist on all FlowFiles in the bundle, with the same value, will be preserved.</description><defaultValue>Keep Only Common Attributes</defaultValue><allowableValues><allowableValue><displayName>Keep Only Common Attributes</displayName><value>Keep Only Common Attributes</value><description>Any attribute that is not the same on all FlowFiles in a bin will be dropped. Those that are the same across all FlowFiles will be retained.</description></allowableValue><allowableValue><displayName>Keep All Unique Attributes</displayName><value>Keep All Unique Attributes</value><description>Any attribute that has the same value for all FlowFiles in a bin, or has no value for a FlowFile, will be kept. For example, if a bin consists of 3 FlowFiles and 2 of them have a value of 'hello' for the 'greeting' attribute and the third FlowFile has no 'greeting' attribute then the outbound FlowFile will get a 'greeting' attribute with the value 'hello'.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>min-records</name><displayName>Minimum Number of Records</displayName><description>The minimum number of records to include in a bin</description><defaultValue>1</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>max-records</name><displayName>Maximum Number of Records</displayName><description>The maximum number of Records to include in a bin. This is a 'soft limit' in that if a FlowFIle is added to a bin, all records in that FlowFile will be added, so this limit may be exceeded by up to the number of records in the last input FlowFile.</description><defaultValue>1000</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>min-bin-size</name><displayName>Minimum Bin Size</displayName><description>The minimum size of for the bin</description><defaultValue>0 B</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>max-bin-size</name><displayName>Maximum Bin Size</displayName><description>The maximum size for the bundle. If not specified, there is no maximum. This is a 'soft limit' in that if a FlowFile is added to a bin, all records in that FlowFile will be added, so this limit may be exceeded by up to the number of bytes in last input FlowFile.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>max-bin-age</name><displayName>Max Bin Age</displayName><description>The maximum age of a Bin that will trigger a Bin to be complete. Expected format is &lt;duration&gt; &lt;time unit&gt; where &lt;duration&gt; is a positive integer and time unit is one of seconds, minutes, hours</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>max.bin.count</name><displayName>Maximum Number of Bins</displayName><description>Specifies the maximum number of bins that can be held in memory at any one time. This number should not be smaller than the maximum number of concurrent threads for this Processor, or the bins that are created will often consist only of a single incoming FlowFile.</description><defaultValue>10</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>If the bundle cannot be created, all FlowFiles that would have been used to created the bundle will be transferred to failure</description><autoTerminated>false</autoTerminated></relationship><relationship><name>merged</name><description>The FlowFile containing the merged records</description><autoTerminated>false</autoTerminated></relationship><relationship><name>original</name><description>The FlowFiles that were used to create the bundle</description><autoTerminated>false</autoTerminated></relationship></relationships><readsAttributes><readsAttribute><name>fragment.identifier</name><description>Applicable only if the &lt;Merge Strategy&gt; property is set to Defragment. All FlowFiles with the same value for this attribute will be bundled together.</description></readsAttribute><readsAttribute><name>fragment.count</name><description>Applicable only if the &lt;Merge Strategy&gt; property is set to Defragment. This attribute must be present on all FlowFiles with the same value for the fragment.identifier attribute. All FlowFiles in the same bundle must have the same value for this attribute. The value of this attribute indicates how many FlowFiles should be expected in the given bundle.</description></readsAttribute></readsAttributes><writesAttributes><writesAttribute><name>record.count</name><description>The merged FlowFile will have a 'record.count' attribute indicating the number of records that were written to the FlowFile.</description></writesAttribute><writesAttribute><name>mime.type</name><description>The MIME Type indicated by the Record Writer</description></writesAttribute><writesAttribute><name>merge.count</name><description>The number of FlowFiles that were merged into this bundle</description></writesAttribute><writesAttribute><name>merge.bin.age</name><description>The age of the bin, in milliseconds, when it was merged and output. Effectively this is the greatest amount of time that any FlowFile in this bundle remained waiting in this processor before it was output</description></writesAttribute><writesAttribute><name>merge.uuid</name><description>UUID of the merged FlowFile that will be added to the original FlowFiles attributes</description></writesAttribute><writesAttribute><name>merge.completion.reason</name><description>This processor allows for several thresholds to be configured for merging FlowFiles.  This attribute indicates which of the Thresholds resulted in the FlowFiles being merged. For an explanation of each of the possible values  and their meanings, see the Processor's Usage / documentation and see the 'Additional Details' page.</description></writesAttribute><writesAttribute><name>&lt;Attributes from Record Writer&gt;</name><description>Any Attribute that the configured Record Writer returns will be added to the FlowFile.</description></writesAttribute></writesAttributes><triggerWhenEmpty>true</triggerWhenEmpty><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><useCases><useCase><description>Combine together many arbitrary Records in order to create a single, larger file</description><notes></notes><keywords></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>Configure the "Record Reader" to specify a Record Reader that is appropriate for the incoming data type.
Configure the "Record Writer" to specify a Record Writer that is appropriate for the desired output data type.
Set "Merge Strategy" to `Bin-Packing Algorithm`.
Set the "Minimum Bin Size" to desired file size of the merged output file. For example, a value of `1 MB` will result in not merging data until at least
    1 MB of data is available (unless the Max Bin Age is reached first). If there is no desired minimum file size, leave the default value of `0 B`.
Set the "Minimum Number of Records" property to the minimum number of Records that should be included in the merged output file. For example, setting the value
    to `10000` ensures that the output file will have at least 10,000 Records in it (unless the Max Bin Age is reached first).
Set the "Max Bin Age" to specify the maximum amount of time to hold data before merging. This can be thought of as a "timeout" at which time the Processor will
    merge whatever data it is, even if the "Minimum Bin Size" and "Minimum Number of Records" has not been reached. It is always recommended to set the value.
    A reasonable default might be `10 mins` if there is no other latency requirement.

Connect the 'merged' Relationship to the next component in the flow. Auto-terminate the 'original' Relationship.
</configuration></useCase></useCases><multiProcessorUseCases><multiProcessorUseCase><description>Combine together many Records that have the same value for a particular field in the data, in order to create a single, larger file</description><notes></notes><keywords><keyword>merge</keyword><keyword>combine</keyword><keyword>aggregate</keyword><keyword>like records</keyword><keyword>similar data</keyword></keywords><processorConfigurations><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.PartitionRecord</processorClassName><configuration>Configure the "Record Reader" to specify a Record Reader that is appropriate for the incoming data type.
Configure the "Record Writer" to specify a Record Writer that is appropriate for the desired output data type.

Add a single additional property. The name of the property should describe the field on which the data is being merged together.
The property's value should be a RecordPath that specifies which output FlowFile the Record belongs to.

For example, to merge together data that has the same value for the "productSku" field, add a property named `productSku` with a value of `/productSku`.

Connect the "success" Relationship to MergeRecord.
Auto-terminate the "original" Relationship.
</configuration></processorConfiguration><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.MergeRecord</processorClassName><configuration>Configure the "Record Reader" to specify a Record Reader that is appropriate for the incoming data type.
Configure the "Record Writer" to specify a Record Writer that is appropriate for the desired output data type.
Set "Merge Strategy" to `Bin-Packing Algorithm`.
Set the "Minimum Bin Size" to desired file size of the merged output file. For example, a value of `1 MB` will result in not merging data until at least
    1 MB of data is available (unless the Max Bin Age is reached first). If there is no desired minimum file size, leave the default value of `0 B`.
Set the "Minimum Number of Records" property to the minimum number of Records that should be included in the merged output file. For example, setting the value
    to `10000` ensures that the output file will have at least 10,000 Records in it (unless the Max Bin Age is reached first).
Set the "Maximum Number of Records" property to a value at least as large as the "Minimum Number of Records." If there is no need to limit the maximum number of
    records per file, this number can be set to a value that will never be reached such as `1000000000`.
Set the "Max Bin Age" to specify the maximum amount of time to hold data before merging. This can be thought of as a "timeout" at which time the Processor will
    merge whatever data it is, even if the "Minimum Bin Size" and "Minimum Number of Records" has not been reached. It is always recommended to set the value.
    A reasonable default might be `10 mins` if there is no other latency requirement.
Set the value of the "Correlation Attribute Name" property to the name of the property that you added in the PartitionRecord Processor. For example, if merging data
    based on the "productSku" field, the property in PartitionRecord was named `productSku` so the value of the "Correlation Attribute Name" property should
    be `productSku`.
Set the "Maximum Number of Bins" property to a value that is at least as large as the different number of values that will be present for the Correlation Attribute.
    For example, if you expect 1,000 different SKUs, set this value to at least `1001`. It is not advisable, though, to set the value above 10,000.

Connect the 'merged' Relationship to the next component in the flow.
Auto-terminate the 'original' Relationship.
</configuration></processorConfiguration></processorConfigurations></multiProcessorUseCase></multiProcessorUseCases><seeAlso><see>org.apache.nifi.processors.standard.MergeContent</see><see>org.apache.nifi.processors.standard.SplitRecord</see><see>org.apache.nifi.processors.standard.PartitionRecord</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.ModifyBytes</name><type>PROCESSOR</type><description>Discard byte range at the start and end or all content of a binary file.</description><tags><tag>binary</tag><tag>discard</tag><tag>keep</tag></tags><properties><property><name>Start Offset</name><displayName>Start Offset</displayName><description>Number of bytes removed at the beginning of the file.</description><defaultValue>0 B</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>End Offset</name><displayName>End Offset</displayName><description>Number of bytes removed at the end of the file.</description><defaultValue>0 B</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Remove All Content</name><displayName>Remove All Content</displayName><description>Remove all content from the FlowFile superseding Start Offset and End Offset properties.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>success</name><description>Processed flowfiles.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.MonitorActivity</name><type>PROCESSOR</type><description>Monitors the flow for activity and sends out an indicator when the flow has not had any data for some specified amount of time and again when the flow's activity is restored</description><tags><tag>monitor</tag><tag>flow</tag><tag>active</tag><tag>inactive</tag><tag>activity</tag><tag>detection</tag></tags><properties><property><name>Threshold Duration</name><displayName>Threshold Duration</displayName><description>Determines how much time must elapse before considering the flow to be inactive</description><defaultValue>5 min</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Continually Send Messages</name><displayName>Continually Send Messages</displayName><description>If true, will send inactivity indicator continually every Threshold Duration amount of time until activity is restored; if false, will send an indicator only when the flow first becomes inactive</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Inactivity Message</name><displayName>Inactivity Message</displayName><description>The message that will be the content of FlowFiles that are sent to the 'inactive' relationship</description><defaultValue>Lacking activity as of time: ${now():format('yyyy/MM/dd HH:mm:ss')}; flow has been inactive for ${inactivityDurationMillis:toNumber():divide(60000)} minutes</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Activity Restored Message</name><displayName>Activity Restored Message</displayName><description>The message that will be the content of FlowFiles that are sent to 'activity.restored' relationship</description><defaultValue>Activity restored at time: ${now():format('yyyy/MM/dd HH:mm:ss')} after being inactive for ${inactivityDurationMillis:toNumber():divide(60000)} minutes</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Wait for Activity</name><displayName>Wait for Activity</displayName><description>When the processor gets started or restarted, if set to true, only send an inactive indicator if there had been activity beforehand. Otherwise send an inactive indicator even if there had not been activity beforehand.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Reset State on Restart</name><displayName>Reset State on Restart</displayName><description>When the processor gets started or restarted, if set to true, the initial state will always be active. Otherwise, the last reported flow state will be preserved.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Copy Attributes</name><displayName>Copy Attributes</displayName><description>If true, will copy all flow file attributes from the flow file that resumed activity to the newly created indicator flow file</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Monitoring Scope</name><displayName>Monitoring Scope</displayName><description>Specify how to determine activeness of the flow. 'node' means that activeness is examined at individual node separately. It can be useful if DFM expects each node should receive flow files in a distributed manner. With 'cluster', it defines the flow is active while at least one node receives flow files actively. If NiFi is running as standalone mode, this should be set as 'node', if it's 'cluster', NiFi logs a warning message and act as 'node' scope.</description><defaultValue>node</defaultValue><allowableValues><allowableValue><displayName>node</displayName><value>node</value><description></description></allowableValue><allowableValue><displayName>cluster</displayName><value>cluster</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Reporting Node</name><displayName>Reporting Node</displayName><description>Specify which node should send notification flow-files to inactive and activity.restored relationships. With 'all', every node in this cluster send notification flow-files. 'primary' means flow-files will be sent only from a primary node. If NiFi is running as standalone mode, this should be set as 'all', even if it's 'primary', NiFi act as 'all'.</description><defaultValue>all</defaultValue><allowableValues><allowableValue><displayName>all</displayName><value>all</value><description></description></allowableValue><allowableValue><displayName>primary</displayName><value>primary</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Monitoring Scope</propertyName><propertyDisplayName>Monitoring Scope</propertyDisplayName><dependentValues><dependentValue>cluster</dependentValue></dependentValues></dependency></dependencies></property></properties><relationships><relationship><name>activity.restored</name><description>This relationship is used to transfer an Activity Restored indicator when FlowFiles are routing to 'success' following a period of inactivity</description><autoTerminated>false</autoTerminated></relationship><relationship><name>inactive</name><description>This relationship is used to transfer an Inactivity indicator when no FlowFiles are routed to 'success' for Threshold Duration amount of time</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>All incoming FlowFiles are routed to success</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>inactivityStartMillis</name><description>The time at which Inactivity began, in the form of milliseconds since Epoch</description></writesAttribute><writesAttribute><name>inactivityDurationMillis</name><description>The number of milliseconds that the inactivity has spanned</description></writesAttribute></writesAttributes><triggerSerially>true</triggerSerially><triggerWhenEmpty>true</triggerWhenEmpty><sideEffectFree>true</sideEffectFree><stateful><description>MonitorActivity stores the last timestamp at each node as state, so that it can examine activity at cluster wide. If 'Copy Attribute' is set to true, then flow file attributes are also persisted. In local scope, it stores last known activity timestamp if the flow is inactive.</description><scopes><scope>CLUSTER</scope><scope>LOCAL</scope></scopes></stateful><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.Notify</name><type>PROCESSOR</type><description>Caches a release signal identifier in the distributed cache, optionally along with the FlowFile's attributes.  Any flow files held at a corresponding Wait processor will be released once this signal in the cache is discovered.</description><tags><tag>map</tag><tag>cache</tag><tag>notify</tag><tag>distributed</tag><tag>signal</tag><tag>release</tag></tags><properties><property><name>release-signal-id</name><displayName>Release Signal Identifier</displayName><description>A value, or the results of an Attribute Expression Language statement, which will be evaluated against a FlowFile in order to determine the release signal cache key</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>signal-counter-name</name><displayName>Signal Counter Name</displayName><description>A value, or the results of an Attribute Expression Language statement, which will be evaluated against a FlowFile in order to determine the signal counter name. Signal counter name is useful when a corresponding Wait processor needs to know the number of occurrences of different types of events, such as success or failure, or destination data source names, etc.</description><defaultValue>default</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>signal-counter-delta</name><displayName>Signal Counter Delta</displayName><description>A value, or the results of an Attribute Expression Language statement, which will be evaluated against a FlowFile in order to determine the signal counter delta. Specify how much the counter should increase. For example, if multiple signal events are processed at upstream flow in batch oriented way, the number of events processed can be notified with this property at once. Zero (0) has a special meaning, it clears target count back to 0, which is especially useful when used with Wait Releasable FlowFile Count = Zero (0) mode, to provide 'open-close-gate' type of flow control. One (1) can open a corresponding Wait processor, and Zero (0) can negate it as if closing a gate.</description><defaultValue>1</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>signal-buffer-count</name><displayName>Signal Buffer Count</displayName><description>Specify the maximum number of incoming flow files that can be buffered until signals are notified to cache service. The more buffer can provide the better performance, as it reduces the number of interactions with cache service by grouping signals by signal identifier when multiple incoming flow files share the same signal identifier.</description><defaultValue>1</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>distributed-cache-service</name><displayName>Distributed Cache Service</displayName><description>The Controller Service that is used to cache release signals in order to release files queued at a corresponding Wait processor</description><controllerServiceDefinition><className>org.apache.nifi.distributed.cache.client.AtomicDistributedMapCacheClient</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>attribute-cache-regex</name><displayName>Attribute Cache Regex</displayName><description>Any attributes whose names match this regex will be stored in the distributed cache to be copied to any FlowFiles released from a corresponding Wait processor.  Note that the uuid attribute will not be cached regardless of this value.  If blank, no attributes will be cached.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>When the cache cannot be reached, or if the Release Signal Identifier evaluates to null or empty, FlowFiles will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>All FlowFiles where the release signal has been successfully entered in the cache will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>notified</name><description>All FlowFiles will have an attribute 'notified'. The value of this attribute is true, is the FlowFile is notified, otherwise false.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_REQUIRED</inputRequirement><seeAlso><see>org.apache.nifi.distributed.cache.client.DistributedMapCacheClientService</see><see>org.apache.nifi.distributed.cache.server.map.DistributedMapCacheServer</see><see>org.apache.nifi.processors.standard.Wait</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.PackageFlowFile</name><type>PROCESSOR</type><description>This processor will package FlowFile attributes and content into an output FlowFile that can be exported from NiFi and imported back into NiFi, preserving the original attributes and content.</description><tags><tag>flowfile</tag><tag>flowfile-stream</tag><tag>flowfile-stream-v3</tag><tag>package</tag><tag>attributes</tag></tags><properties><property><name>max-batch-size</name><displayName>Maximum Batch Size</displayName><description>Maximum number of FlowFiles to package into one output FlowFile.</description><defaultValue>1</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum Batch Content Size</name><displayName>Maximum Batch Content Size</displayName><description>Maximum combined content size of FlowFiles to package into one output FlowFile. Note, that FlowFiles whose content exceeds this limit are packaged separately.</description><defaultValue>1 GB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>original</name><description>The FlowFiles that were used to create the package are sent to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>The packaged FlowFile is sent to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>mime.type</name><description>The mime.type will be changed to application/flowfile-v3</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><multiProcessorUseCases><multiProcessorUseCase><description>Send FlowFile content and attributes from one NiFi instance to another NiFi instance.</description><notes>A Remote Process Group is preferred to send FlowFiles between two NiFi instances, but an alternative is to use PackageFlowFile then InvokeHTTP sending to ListenHTTP.</notes><keywords><keyword>flowfile</keyword><keyword>attributes</keyword><keyword>content</keyword><keyword>ffv3</keyword><keyword>flowfile-stream-v3</keyword><keyword>transfer</keyword></keywords><processorConfigurations><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.PackageFlowFile</processorClassName><configuration>    "Maximum Batch Size" &gt; 1 can improve storage or transmission efficiency by batching many FlowFiles together into 1 larger file.
    "Maximum Batch Content Size" can be used to enforce a soft upper limit on the overall package size.

    Note, that the Batch properties only restrict the maximum amount of FlowFiles to incorporate into a single package.
    In case less FlowFiles are queued than the properties allow for,
    the processor will not wait for the limits to be reached but create smaller packages instead.

    Connect the success relationship of PackageFlowFile to the input of InvokeHTTP.
</configuration></processorConfiguration><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.InvokeHTTP</processorClassName><configuration>    "HTTP Method" = "POST" to send data to ListenHTTP.
    "HTTP URL" should include the hostname, port, and path to the ListenHTTP.
    "Request Content-Type" = "${mime.type}" because PackageFlowFile output files have attribute mime.type=application/flowfile-v3.
</configuration></processorConfiguration><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.ListenHTTP</processorClassName><configuration>    "Listening Port" = a unique port number.

    ListenHTTP automatically unpacks files that have attribute mime.type=application/flowfile-v3.
    If PackageFlowFile batches 99 FlowFiles into 1 file that InvokeHTTP sends, then the original 99 FlowFiles will be output by ListenHTTP.
</configuration></processorConfiguration></processorConfigurations></multiProcessorUseCase><multiProcessorUseCase><description>Export FlowFile content and attributes from NiFi to external storage and reimport.</description><notes></notes><keywords><keyword>flowfile</keyword><keyword>attributes</keyword><keyword>content</keyword><keyword>ffv3</keyword><keyword>flowfile-stream-v3</keyword><keyword>offline</keyword><keyword>storage</keyword></keywords><processorConfigurations><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.PackageFlowFile</processorClassName><configuration>    "Maximum Batch Size" &gt; 1 can improve storage or transmission efficiency by batching many FlowFiles together into 1 larger file.
    "Maximum Batch Content Size" can be used to enforce a soft upper limit on the overall package size.

    Note, that the Batch properties only restrict the maximum amount of FlowFiles to incorporate into a single package.
    In case less FlowFiles are queued than the properties allow for,
    the processor will not wait for the limits to be reached but create smaller packages instead.

    Connect the success relationship to the input of any NiFi egress processor for offline storage.
</configuration></processorConfiguration><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.UnpackContent</processorClassName><configuration>    "Packaging Format" = "application/flowfile-v3".

    Connect the output of a NiFi ingress processor that reads files stored offline to the input of UnpackContent.
    If PackageFlowFile batches 99 FlowFiles into 1 file that is read from storage, then the original 99 FlowFiles will be output by UnpackContent.
</configuration></processorConfiguration></processorConfigurations></multiProcessorUseCase></multiProcessorUseCases><seeAlso><see>org.apache.nifi.processors.standard.UnpackContent</see><see>org.apache.nifi.processors.standard.MergeContent</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.ParseSyslog</name><type>PROCESSOR</type><description>Attempts to parses the contents of a Syslog message in accordance to RFC5424 and RFC3164 formats and adds attributes to the FlowFile for each of the parts of the Syslog message.Note: Be mindfull that RFC3164 is informational and a wide range of different implementations are present in the wild. If messages fail parsing, considering using RFC5424 or using a generic parsing processors such as ExtractGrok.</description><tags><tag>logs</tag><tag>syslog</tag><tag>attributes</tag><tag>system</tag><tag>event</tag><tag>message</tag></tags><properties><property><name>Character Set</name><displayName>Character Set</displayName><description>Specifies which character set of the Syslog messages</description><defaultValue>UTF-8</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>Any FlowFile that could not be parsed as a Syslog message will be transferred to this Relationship without any attributes being added</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>Any FlowFile that is successfully parsed as a Syslog message will be to this Relationship.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>syslog.priority</name><description>The priority of the Syslog message.</description></writesAttribute><writesAttribute><name>syslog.severity</name><description>The severity of the Syslog message derived from the priority.</description></writesAttribute><writesAttribute><name>syslog.facility</name><description>The facility of the Syslog message derived from the priority.</description></writesAttribute><writesAttribute><name>syslog.version</name><description>The optional version from the Syslog message.</description></writesAttribute><writesAttribute><name>syslog.timestamp</name><description>The timestamp of the Syslog message.</description></writesAttribute><writesAttribute><name>syslog.hostname</name><description>The hostname or IP address of the Syslog message.</description></writesAttribute><writesAttribute><name>syslog.sender</name><description>The hostname of the Syslog server that sent the message.</description></writesAttribute><writesAttribute><name>syslog.body</name><description>The body of the Syslog message, everything after the hostname.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.ListenSyslog</see><see>org.apache.nifi.processors.standard.PutSyslog</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.ParseSyslog5424</name><type>PROCESSOR</type><description>Attempts to parse the contents of a well formed Syslog message in accordance to RFC5424 format and adds attributes to the FlowFile for each of the parts of the Syslog message, including Structured Data.Structured Data will be written to attributes as one attribute per item id + parameter see https://tools.ietf.org/html/rfc5424.Note: ParseSyslog5424 follows the specification more closely than ParseSyslog.  If your Syslog producer does not follow the spec closely, with regards to using '-' for missing header entries for example, those logs will fail with this parser, where they would not fail with ParseSyslog.</description><tags><tag>logs</tag><tag>syslog</tag><tag>syslog5424</tag><tag>attributes</tag><tag>system</tag><tag>event</tag><tag>message</tag></tags><properties><property><name>Character Set</name><displayName>Character Set</displayName><description>Specifies which character set of the Syslog messages</description><defaultValue>UTF-8</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>nil_policy</name><displayName>NIL Policy</displayName><description>Defines how NIL values are handled for header fields.</description><defaultValue>NULL</defaultValue><allowableValues><allowableValue><displayName>OMIT</displayName><value>OMIT</value><description>The missing field will not have an attribute added.</description></allowableValue><allowableValue><displayName>NULL</displayName><value>NULL</value><description>The missing field will have an empty attribute added.</description></allowableValue><allowableValue><displayName>DASH</displayName><value>DASH</value><description>The missing field will have an attribute added with the value of '-'.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>include_policy</name><displayName>Include Message Body in Attributes</displayName><description>If true, then the Syslog Message body will be included in the attributes.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>Any FlowFile that could not be parsed as a Syslog message will be transferred to this Relationship without any attributes being added</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>Any FlowFile that is successfully parsed as a Syslog message will be to this Relationship.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>syslog.priority</name><description>The priority of the Syslog message.</description></writesAttribute><writesAttribute><name>syslog.severity</name><description>The severity of the Syslog message derived from the priority.</description></writesAttribute><writesAttribute><name>syslog.facility</name><description>The facility of the Syslog message derived from the priority.</description></writesAttribute><writesAttribute><name>syslog.version</name><description>The optional version from the Syslog message.</description></writesAttribute><writesAttribute><name>syslog.timestamp</name><description>The timestamp of the Syslog message.</description></writesAttribute><writesAttribute><name>syslog.hostname</name><description>The hostname or IP address of the Syslog message.</description></writesAttribute><writesAttribute><name>syslog.appname</name><description>The appname of the Syslog message.</description></writesAttribute><writesAttribute><name>syslog.procid</name><description>The procid of the Syslog message.</description></writesAttribute><writesAttribute><name>syslog.messageid</name><description>The messageid the Syslog message.</description></writesAttribute><writesAttribute><name>syslog.structuredData</name><description>Multiple entries per structuredData of the Syslog message.</description></writesAttribute><writesAttribute><name>syslog.sender</name><description>The hostname of the Syslog server that sent the message.</description></writesAttribute><writesAttribute><name>syslog.body</name><description>The body of the Syslog message, everything after the hostname.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.ListenSyslog</see><see>org.apache.nifi.processors.standard.ParseSyslog</see><see>org.apache.nifi.processors.standard.PutSyslog</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.PartitionRecord</name><type>PROCESSOR</type><description>Splits, or partitions, record-oriented data based on the configured fields in the data. One or more properties must be added. The name of the property is the name of an attribute to add. The value of the property is a RecordPath to evaluate against each Record. Two records will go to the same outbound FlowFile only if they have the same value for each of the given RecordPaths. Because we know that all records in a given output FlowFile have the same value for the fields that are specified by the RecordPath, an attribute is added for each field. See Additional Details on the Usage page for more information and examples.</description><tags><tag>record</tag><tag>partition</tag><tag>recordpath</tag><tag>rpath</tag><tag>segment</tag><tag>split</tag><tag>group</tag><tag>bin</tag><tag>organize</tag></tags><properties><property><name>record-reader</name><displayName>Record Reader</displayName><description>Specifies the Controller Service to use for reading incoming data</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>record-writer</name><displayName>Record Writer</displayName><description>Specifies the Controller Service to use for writing out the records</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>The name given to the dynamic property is the name of the attribute that will be used to denote the value of the associated RecordPath.</name><value>A RecordPath that points to a field in the Record.</value><description>Each dynamic property represents a RecordPath that will be evaluated against each record in an incoming FlowFile. When the value of the RecordPath is determined for a Record, an attribute is added to the outgoing FlowFile. The name of the attribute is the same as the name of this property. The value of the attribute is the same as the value of the field in the Record that the RecordPath points to. Note that no attribute will be added if the value returned for the RecordPath is null or is not a scalar value (i.e., the value is an Array, Map, or Record).</description><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>failure</name><description>If a FlowFile cannot be partitioned from the configured input format to the configured output format, the unchanged FlowFile will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>original</name><description>Once all records in an incoming FlowFile have been partitioned, the original FlowFile is routed to this relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>FlowFiles that are successfully partitioned will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>record.count</name><description>The number of records in an outgoing FlowFile</description></writesAttribute><writesAttribute><name>mime.type</name><description>The MIME Type that the configured Record Writer indicates is appropriate</description></writesAttribute><writesAttribute><name>fragment.identifier</name><description>All partitioned FlowFiles produced from the same parent FlowFile will have the same randomly generated UUID added for this attribute</description></writesAttribute><writesAttribute><name>fragment.index</name><description>A one-up number that indicates the ordering of the partitioned FlowFiles that were created from a single parent FlowFile</description></writesAttribute><writesAttribute><name>fragment.count</name><description>The number of partitioned FlowFiles generated from the parent FlowFile</description></writesAttribute><writesAttribute><name>segment.original.filename </name><description>The filename of the parent FlowFile</description></writesAttribute><writesAttribute><name>&lt;dynamic property name&gt;</name><description>For each dynamic property that is added, an attribute may be added to the FlowFile. See the description for Dynamic Properties for more information.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_REQUIRED</inputRequirement><useCases><useCase><description>Separate records into separate FlowFiles so that all of the records in a FlowFile have the same value for a given field or set of fields.</description><notes></notes><keywords><keyword>separate</keyword><keyword>split</keyword><keyword>partition</keyword><keyword>break apart</keyword><keyword>colocate</keyword><keyword>segregate</keyword><keyword>record</keyword><keyword>field</keyword><keyword>recordpath</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>Choose a RecordReader that is appropriate based on the format of the incoming data.
Choose a RecordWriter that writes the data in the desired output format.

Add a single additional property. The name of the property should describe the type of data that is being used to partition the data. The property's value should be a RecordPath that specifies which output FlowFile the Record belongs to.

For example, if we want to separate records based on their `transactionType` field, we could add a new property named `transactionType`. The value of the property might be `/transaction/type`. An input FlowFile will then be separated into as few FlowFiles as possible such that each output FlowFile has the same value for the `transactionType` field.
</configuration></useCase><useCase><description>Separate records based on whether or not they adhere to a specific criteria</description><notes></notes><keywords><keyword>separate</keyword><keyword>split</keyword><keyword>partition</keyword><keyword>break apart</keyword><keyword>segregate</keyword><keyword>record</keyword><keyword>field</keyword><keyword>recordpath</keyword><keyword>criteria</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>Choose a RecordReader that is appropriate based on the format of the incoming data.
Choose a RecordWriter that writes the data in the desired output format.

Add a single additional property. The name of the property should describe the criteria. The property's value should be a RecordPath that returns `true` if the Record meets the criteria or `false` otherwise.

For example, if we want to separate records based on whether or not they have a transaction total of more than $1,000 we could add a new property named `largeTransaction` with a value of `/transaction/total &gt; 1000`. This will create two FlowFiles. In the first, all records will have a total over `1000`. In the second, all records will have a transaction less than or equal to 1000. Each FlowFile will have an attribute named `largeTransaction` with a value of `true` or `false`.
</configuration></useCase></useCases><seeAlso><see>org.apache.nifi.processors.standard.ConvertRecord</see><see>org.apache.nifi.processors.standard.SplitRecord</see><see>org.apache.nifi.processors.standard.UpdateRecord</see><see>org.apache.nifi.processors.standard.QueryRecord</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.PutDatabaseRecord</name><type>PROCESSOR</type><description>The PutDatabaseRecord processor uses a specified RecordReader to input (possibly multiple) records from an incoming flow file. These records are translated to SQL statements and executed as a single transaction. If any errors occur, the flow file is routed to failure or retry, and if the records are transmitted successfully, the incoming flow file is routed to success.  The type of statement executed by the processor is specified via the Statement Type property, which accepts some hard-coded values such as INSERT, UPDATE, and DELETE, as well as 'Use statement.type Attribute', which causes the processor to get the statement type from a flow file attribute.  IMPORTANT: If the Statement Type is UPDATE, then the incoming records must not alter the value(s) of the primary keys (or user-specified Update Keys). If such records are encountered, the UPDATE statement issued to the database may do nothing (if no existing records with the new primary key values are found), or could inadvertently corrupt the existing data (by changing records for which the new values of the primary keys exist).</description><tags><tag>sql</tag><tag>record</tag><tag>jdbc</tag><tag>put</tag><tag>database</tag><tag>update</tag><tag>insert</tag><tag>delete</tag></tags><properties><property><name>put-db-record-record-reader</name><displayName>Record Reader</displayName><description>Specifies the Controller Service to use for parsing incoming data and determining the data's schema.</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>db-type</name><displayName>Database Type</displayName><description>Database Type for generating statements specific to a particular service or vendor.
The Generic Type supports most cases but selecting a specific type enables optimal processing
or additional features.
</description><defaultValue>Generic</defaultValue><allowableValues><allowableValue><displayName>Database Dialect Service</displayName><value>Database Dialect Service</value><description>Requires configuring a Database Dialect Service for SQL statements</description></allowableValue><allowableValue><displayName>Generic</displayName><value>Generic</value><description>Generates ANSI SQL</description></allowableValue><allowableValue><displayName>Oracle</displayName><value>Oracle</value><description>Generates Oracle compliant SQL</description></allowableValue><allowableValue><displayName>Oracle 12+</displayName><value>Oracle 12+</value><description>Generates Oracle compliant SQL for version 12 or greater</description></allowableValue><allowableValue><displayName>MS SQL 2012+</displayName><value>MS SQL 2012+</value><description>Generates MS SQL Compatible SQL, for version 2012 or greater</description></allowableValue><allowableValue><displayName>MS SQL 2008</displayName><value>MS SQL 2008</value><description>Generates MS SQL Compatible SQL for version 2008</description></allowableValue><allowableValue><displayName>MySQL</displayName><value>MySQL</value><description>Generates MySQL compatible SQL</description></allowableValue><allowableValue><displayName>PostgreSQL</displayName><value>PostgreSQL</value><description>Generates PostgreSQL compatible SQL</description></allowableValue><allowableValue><displayName>Phoenix</displayName><value>Phoenix</value><description>Generates Phoenix compliant SQL</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Database Dialect Service</name><displayName>Database Dialect Service</displayName><description>Database Dialect Service for generating statements specific to a particular service or vendor.</description><controllerServiceDefinition><className>org.apache.nifi.database.dialect.service.api.DatabaseDialectService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>db-type</propertyName><propertyDisplayName>Database Type</propertyDisplayName><dependentValues><dependentValue>Database Dialect Service</dependentValue></dependentValues></dependency></dependencies></property><property><name>put-db-record-statement-type</name><displayName>Statement Type</displayName><description>Specifies the type of SQL Statement to generate. Please refer to the database documentation for a description of the behavior of each operation. Please note that some Database Types may not support certain Statement Types. If 'Use statement.type Attribute' is chosen, then the value is taken from the statement.type attribute in the FlowFile. The 'Use statement.type Attribute' option is the only one that allows the 'SQL' statement type. If 'SQL' is specified, the value of the field specified by the 'Field Containing SQL' property is expected to be a valid SQL statement on the target database, and will be executed as-is.</description><allowableValues><allowableValue><displayName>UPDATE</displayName><value>UPDATE</value><description></description></allowableValue><allowableValue><displayName>INSERT</displayName><value>INSERT</value><description></description></allowableValue><allowableValue><displayName>UPSERT</displayName><value>UPSERT</value><description></description></allowableValue><allowableValue><displayName>INSERT_IGNORE</displayName><value>INSERT_IGNORE</value><description></description></allowableValue><allowableValue><displayName>DELETE</displayName><value>DELETE</value><description></description></allowableValue><allowableValue><displayName>Use statement.type Attribute</displayName><value>Use statement.type Attribute</value><description></description></allowableValue><allowableValue><displayName>Use Record Path</displayName><value>Use Record Path</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Statement Type Record Path</name><displayName>Statement Type Record Path</displayName><description>Specifies a RecordPath to evaluate against each Record in order to determine the Statement Type. The RecordPath should equate to either INSERT, UPDATE, UPSERT, or DELETE. (Debezium style operation types are also supported: "r" and "c" for INSERT, "u" for UPDATE, and "d" for DELETE)</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>put-db-record-statement-type</propertyName><propertyDisplayName>Statement Type</propertyDisplayName><dependentValues><dependentValue>Use Record Path</dependentValue></dependentValues></dependency></dependencies></property><property><name>Data Record Path</name><displayName>Data Record Path</displayName><description>If specified, this property denotes a RecordPath that will be evaluated against each incoming Record and the Record that results from evaluating the RecordPath will be sent to the database instead of sending the entire incoming Record. If not specified, the entire incoming Record will be published to the database.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>put-db-record-dcbp-service</name><displayName>Database Connection Pooling Service</displayName><description>The Controller Service that is used to obtain a connection to the database for sending records.</description><controllerServiceDefinition><className>org.apache.nifi.dbcp.DBCPService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>put-db-record-catalog-name</name><displayName>Catalog Name</displayName><description>The name of the catalog that the statement should update. This may not apply for the database that you are updating. In this case, leave the field empty. Note that if the property is set and the database is case-sensitive, the catalog name must match the database's catalog name exactly.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>put-db-record-schema-name</name><displayName>Schema Name</displayName><description>The name of the schema that the table belongs to. This may not apply for the database that you are updating. In this case, leave the field empty. Note that if the property is set and the database is case-sensitive, the schema name must match the database's schema name exactly.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>put-db-record-table-name</name><displayName>Table Name</displayName><description>The name of the table that the statement should affect. Note that if the database is case-sensitive, the table name must match the database's table name exactly.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>put-db-record-binary-format</name><displayName>Binary String Format</displayName><description>The format to be applied when decoding string values to binary.</description><defaultValue>UTF-8</defaultValue><allowableValues><allowableValue><displayName>UTF-8</displayName><value>UTF-8</value><description>String values for binary columns contain the original value as text via UTF-8 character encoding</description></allowableValue><allowableValue><displayName>Hexadecimal</displayName><value>Hexadecimal</value><description>String values for binary columns contain the original value in hexadecimal format</description></allowableValue><allowableValue><displayName>Base64</displayName><value>Base64</value><description>String values for binary columns contain the original value in Base64 encoded format</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>put-db-record-translate-field-names</name><displayName>Translate Field Names</displayName><description>If true, the Processor will attempt to translate field names into the appropriate column names for the table specified. If false, the field names must match the column names exactly, or the column will not be updated</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Column Name Translation Strategy</name><displayName>Column Name Translation Strategy</displayName><description>The strategy used to normalize table column name. Column Name will be uppercased to do case-insensitive matching irrespective of strategy</description><defaultValue>REMOVE_UNDERSCORE</defaultValue><allowableValues><allowableValue><displayName>Remove Underscore</displayName><value>REMOVE_UNDERSCORE</value><description>Underscores '_' will be removed from column names Ex: 'Pics_1_23' becomes 'PICS123'</description></allowableValue><allowableValue><displayName>Remove Space</displayName><value>REMOVE_SPACE</value><description>Spaces will be removed from column names Ex. 'User Name' becomes 'USERNAME'</description></allowableValue><allowableValue><displayName>Remove Underscores and Spaces</displayName><value>REMOVE_UNDERSCORE_AND_SPACE</value><description>Spaces and Underscores will be removed from column names Ex. 'User_1 Name' becomes 'USER1NAME'</description></allowableValue><allowableValue><displayName>Remove Regular Expression Characters</displayName><value>REMOVE_ALL_SPECIAL_CHAR</value><description>Remove Regular Expression Characters Ex. 'user-id' becomes USERID ,total(estimated) become TOTALESTIMATED</description></allowableValue><allowableValue><displayName>Regular Expression</displayName><value>PATTERN</value><description>Remove characters matching this Regular Expression from the column names Ex.1. '\d' will  Remove all numbers 2. '[^a-zA-Z0-9_]' will remove special characters except underscore</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>put-db-record-translate-field-names</propertyName><propertyDisplayName>Translate Field Names</propertyDisplayName><dependentValues><dependentValue>true</dependentValue></dependentValues></dependency></dependencies></property><property><name>Column Name Translation Pattern</name><displayName>Column Name Translation Pattern</displayName><description>Column name will be normalized with this regular expression</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Column Name Translation Strategy</propertyName><propertyDisplayName>Column Name Translation Strategy</propertyDisplayName><dependentValues><dependentValue>PATTERN</dependentValue></dependentValues></dependency></dependencies></property><property><name>put-db-record-unmatched-field-behavior</name><displayName>Unmatched Field Behavior</displayName><description>If an incoming record has a field that does not map to any of the database table's columns, this property specifies how to handle the situation</description><defaultValue>Ignore Unmatched Fields</defaultValue><allowableValues><allowableValue><displayName>Ignore Unmatched Fields</displayName><value>Ignore Unmatched Fields</value><description>Any field in the document that cannot be mapped to a column in the database is ignored</description></allowableValue><allowableValue><displayName>Fail on Unmatched Fields</displayName><value>Fail on Unmatched Fields</value><description>If the document has any field that cannot be mapped to a column in the database, the FlowFile will be routed to the failure relationship</description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>put-db-record-unmatched-column-behavior</name><displayName>Unmatched Column Behavior</displayName><description>If an incoming record does not have a field mapping for all of the database table's columns, this property specifies how to handle the situation</description><defaultValue>Fail on Unmatched Columns</defaultValue><allowableValues><allowableValue><displayName>Ignore Unmatched Columns</displayName><value>Ignore Unmatched Columns</value><description>Any column in the database that does not have a field in the document will be assumed to not be required.  No notification will be logged</description></allowableValue><allowableValue><displayName>Warn on Unmatched Columns</displayName><value>Warn on Unmatched Columns</value><description>Any column in the database that does not have a field in the document will be assumed to not be required.  A warning will be logged</description></allowableValue><allowableValue><displayName>Fail on Unmatched Columns</displayName><value>Fail on Unmatched Columns</value><description>A flow will fail if any column in the database that does not have a field in the document.  An error will be logged</description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>put-db-record-update-keys</name><displayName>Update Keys</displayName><description>A comma-separated list of column names that uniquely identifies a row in the database for UPDATE statements. If the Statement Type is UPDATE and this property is not set, the table's Primary Keys are used. In this case, if no Primary Key exists, the conversion to SQL will fail if Unmatched Column Behaviour is set to FAIL. This property is ignored if the Statement Type is INSERT</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>put-db-record-statement-type</propertyName><propertyDisplayName>Statement Type</propertyDisplayName><dependentValues><dependentValue>SQL</dependentValue><dependentValue>UPDATE</dependentValue><dependentValue>UPSERT</dependentValue><dependentValue>Use Record Path</dependentValue><dependentValue>Use statement.type Attribute</dependentValue></dependentValues></dependency></dependencies></property><property><name>Delete Keys</name><displayName>Delete Keys</displayName><description>A comma-separated list of column names that uniquely identifies a row in the database for DELETE statements. If the Statement Type is DELETE and this property is not set, the table's columns are used. This property is ignored if the Statement Type is not DELETE</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>put-db-record-statement-type</propertyName><propertyDisplayName>Statement Type</propertyDisplayName><dependentValues><dependentValue>DELETE</dependentValue><dependentValue>SQL</dependentValue><dependentValue>Use Record Path</dependentValue><dependentValue>Use statement.type Attribute</dependentValue></dependentValues></dependency></dependencies></property><property><name>put-db-record-field-containing-sql</name><displayName>Field Containing SQL</displayName><description>If the Statement Type is 'SQL' (as set in the statement.type attribute), this field indicates which field in the record(s) contains the SQL statement to execute. The value of the field must be a single SQL statement. If the Statement Type is not 'SQL', this field is ignored.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>put-db-record-statement-type</propertyName><propertyDisplayName>Statement Type</propertyDisplayName><dependentValues><dependentValue>Use Record Path</dependentValue><dependentValue>Use statement.type Attribute</dependentValue></dependentValues></dependency></dependencies></property><property><name>put-db-record-allow-multiple-statements</name><displayName>Allow Multiple SQL Statements</displayName><description>If the Statement Type is 'SQL' (as set in the statement.type attribute), this field indicates whether to split the field value by a semicolon and execute each statement separately. If any statement causes an error, the entire set of statements will be rolled back. If the Statement Type is not 'SQL', this field is ignored.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>put-db-record-statement-type</propertyName><propertyDisplayName>Statement Type</propertyDisplayName><dependentValues><dependentValue>Use Record Path</dependentValue><dependentValue>Use statement.type Attribute</dependentValue></dependentValues></dependency></dependencies></property><property><name>put-db-record-quoted-identifiers</name><displayName>Quote Column Identifiers</displayName><description>Enabling this option will cause all column names to be quoted, allowing you to use reserved words as column names in your tables.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>put-db-record-quoted-table-identifiers</name><displayName>Quote Table Identifiers</displayName><description>Enabling this option will cause the table name to be quoted to support the use of special characters in the table name.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>put-db-record-query-timeout</name><displayName>Max Wait Time</displayName><description>The maximum amount of time allowed for a running SQL statement , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><defaultValue>0 seconds</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>rollback-on-failure</name><displayName>Rollback On Failure</displayName><description>Specify how to handle error. By default (false), if an error occurs while processing a FlowFile, the FlowFile will be routed to 'failure' or 'retry' relationship based on error type, and processor can continue with next FlowFile. Instead, you may want to rollback currently processed FlowFiles and stop further processing immediately. In that case, you can do so by enabling this 'Rollback On Failure' property.  If enabled, failed FlowFiles will stay in the input relationship without penalizing it and being processed repeatedly until it gets processed successfully or removed by other means. It is important to set adequate 'Yield Duration' to avoid retrying too frequently.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>table-schema-cache-size</name><displayName>Table Schema Cache Size</displayName><description>Specifies how many Table Schemas should be cached</description><defaultValue>100</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>put-db-record-max-batch-size</name><displayName>Maximum Batch Size</displayName><description>Specifies maximum number of sql statements to be included in each batch sent to the database. Zero means the batch size is not limited, and all statements are put into a single batch which can cause high memory usage issues for a very large number of statements.</description><defaultValue>1000</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>database-session-autocommit</name><displayName>Database Session AutoCommit</displayName><description>The autocommit mode to set on the database connection being used. If set to false, the operation(s) will be explicitly committed or rolled back (based on success or failure respectively). If set to true, the driver/database automatically handles the commit/rollback.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>A FlowFile is routed to this relationship if the database cannot be updated and retrying the operation will also fail, such as an invalid query or an integrity constraint violation</description><autoTerminated>false</autoTerminated></relationship><relationship><name>retry</name><description>A FlowFile is routed to this relationship if the database cannot be updated but attempting the operation again may succeed</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>Successfully created FlowFile from SQL query result set.</description><autoTerminated>false</autoTerminated></relationship></relationships><readsAttributes><readsAttribute><name>statement.type</name><description>If 'Use statement.type Attribute' is selected for the Statement Type property, the value of this attribute will be used to determine the type of statement (INSERT, UPDATE, DELETE, SQL, etc.) to generate and execute.</description></readsAttribute></readsAttributes><writesAttributes><writesAttribute><name>putdatabaserecord.error</name><description>If an error occurs during processing, the flow file will be routed to failure or retry, and this attribute will be populated with the cause of the error.</description></writesAttribute></writesAttributes><inputRequirement>INPUT_REQUIRED</inputRequirement><useCases><useCase><description>Insert records into a database</description><notes></notes><keywords></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration></configuration></useCase></useCases></extension><extension><name>org.apache.nifi.processors.standard.PutDistributedMapCache</name><type>PROCESSOR</type><description>Gets the content of a FlowFile and puts it to a distributed map cache, using a cache key computed from FlowFile attributes. If the cache already contains the entry and the cache update strategy is 'keep original' the entry is not replaced.'</description><tags><tag>map</tag><tag>cache</tag><tag>put</tag><tag>distributed</tag></tags><properties><property><name>Cache Entry Identifier</name><displayName>Cache Entry Identifier</displayName><description>A FlowFile attribute, or the results of an Attribute Expression Language statement, which will be evaluated against a FlowFile in order to determine the cache key</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Distributed Cache Service</name><displayName>Distributed Cache Service</displayName><description>The Controller Service that is used to cache flow files</description><controllerServiceDefinition><className>org.apache.nifi.distributed.cache.client.DistributedMapCacheClient</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Cache update strategy</name><displayName>Cache update strategy</displayName><description>Determines how the cache is updated if the cache already contains the entry</description><defaultValue>replace</defaultValue><allowableValues><allowableValue><displayName>Replace if present</displayName><value>replace</value><description>Adds the specified entry to the cache, replacing any value that is currently set.</description></allowableValue><allowableValue><displayName>Keep original</displayName><value>keeporiginal</value><description>Adds the specified entry to the cache, if the key does not exist.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max cache entry size</name><displayName>Max cache entry size</displayName><description>The maximum amount of data to put into cache</description><defaultValue>1 MB</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>Any FlowFile that cannot be inserted into the cache will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>Any FlowFile that is successfully inserted into cache will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>cached</name><description>All FlowFiles will have an attribute 'cached'. The value of this attribute is true, is the FlowFile is cached, otherwise false.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_REQUIRED</inputRequirement><seeAlso><see>org.apache.nifi.distributed.cache.client.DistributedMapCacheClientService</see><see>org.apache.nifi.distributed.cache.server.map.DistributedMapCacheServer</see><see>org.apache.nifi.processors.standard.FetchDistributedMapCache</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.PutEmail</name><type>PROCESSOR</type><description>Sends an e-mail to configured recipients for each incoming FlowFile</description><tags><tag>email</tag><tag>put</tag><tag>notify</tag><tag>smtp</tag></tags><properties><property><name>SMTP Hostname</name><displayName>SMTP Hostname</displayName><description>The hostname of the SMTP host</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>SMTP Port</name><displayName>SMTP Port</displayName><description>The Port used for SMTP communications</description><defaultValue>25</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>authorization-mode</name><displayName>Authorization Mode</displayName><description>How to authorize sending email on the user's behalf.</description><defaultValue>password-based-authorization-mode</defaultValue><allowableValues><allowableValue><displayName>Use Password</displayName><value>password-based-authorization-mode</value><description>Use password</description></allowableValue><allowableValue><displayName>Use OAuth2</displayName><value>oauth-based-authorization-mode</value><description>Use OAuth2 to acquire access token</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>oauth2-access-token-provider</name><displayName>OAuth2 Access Token Provider</displayName><description>OAuth2 service that can provide access tokens.</description><controllerServiceDefinition><className>org.apache.nifi.oauth2.OAuth2AccessTokenProvider</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>authorization-mode</propertyName><propertyDisplayName>Authorization Mode</propertyDisplayName><dependentValues><dependentValue>oauth-based-authorization-mode</dependentValue></dependentValues></dependency></dependencies></property><property><name>SMTP Username</name><displayName>SMTP Username</displayName><description>Username for the SMTP account</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>SMTP Password</name><displayName>SMTP Password</displayName><description>Password for the SMTP account</description><required>false</required><sensitive>true</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>authorization-mode</propertyName><propertyDisplayName>Authorization Mode</propertyDisplayName><dependentValues><dependentValue>password-based-authorization-mode</dependentValue></dependentValues></dependency></dependencies></property><property><name>SMTP Auth</name><displayName>SMTP Auth</displayName><description>Flag indicating whether authentication should be used</description><defaultValue>true</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>SMTP TLS</name><displayName>SMTP STARTTLS</displayName><description>Flag indicating whether Opportunistic TLS should be enabled using STARTTLS command</description><defaultValue>false</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>SMTP Socket Factory</name><displayName>SMTP Socket Factory</displayName><description>Socket Factory to use for SMTP Connection</description><defaultValue>javax.net.ssl.SSLSocketFactory</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>SMTP X-Mailer Header</name><displayName>SMTP X-Mailer Header</displayName><description>X-Mailer used in the header of the outgoing email</description><defaultValue>NiFi</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>attribute-name-regex</name><displayName>Attributes to Send as Headers (Regex)</displayName><description>A Regular Expression that is matched against all FlowFile attribute names. Any attribute whose name matches the regex will be added to the Email messages as a Header. If not specified, no FlowFile attributes will be added as headers.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Content Type</name><displayName>Content Type</displayName><description>Mime Type used to interpret the contents of the email, such as text/plain or text/html</description><defaultValue>text/plain</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>From</name><displayName>From</displayName><description>Specifies the Email address to use as the sender. Comma separated sequence of addresses following RFC822 syntax.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>To</name><displayName>To</displayName><description>The recipients to include in the To-Line of the email. Comma separated sequence of addresses following RFC822 syntax.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>CC</name><displayName>CC</displayName><description>The recipients to include in the CC-Line of the email. Comma separated sequence of addresses following RFC822 syntax.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>BCC</name><displayName>BCC</displayName><description>The recipients to include in the BCC-Line of the email. Comma separated sequence of addresses following RFC822 syntax.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Reply-To</name><displayName>Reply-To</displayName><description>The recipients that will receive the reply instead of the from (see RFC2822 §3.6.2).This feature is useful, for example, when the email is sent by a no-reply account. This field is optional.Comma separated sequence of addresses following RFC822 syntax.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Subject</name><displayName>Subject</displayName><description>The email subject</description><defaultValue>Message from NiFi</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Message</name><displayName>Message</displayName><description>The body of the email message</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>email-ff-content-as-message</name><displayName>Flow file content as message</displayName><description>Specifies whether or not the FlowFile content should be the message of the email. If true, the 'Message' property is ignored.</description><defaultValue>false</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>input-character-set</name><displayName>Input Character Set</displayName><description>Specifies the character set of the FlowFile contents for reading input FlowFile contents to generate the message body or as an attachment to the message. If not set, UTF-8 will be the default value.</description><defaultValue>UTF-8</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Attach File</name><displayName>Attach File</displayName><description>Specifies whether or not the FlowFile content should be attached to the email</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Include All Attributes In Message</name><displayName>Include All Attributes In Message</displayName><description>Specifies whether or not all FlowFile attributes should be recorded in the body of the email message</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>mail.propertyName</name><value>Value for a specific property to be set in the JavaMail Session object</value><description>Dynamic property names that will be passed to the Mail session. Possible properties can be found in: https://javaee.github.io/javamail/docs/api/com/sun/mail/smtp/package-summary.html.</description><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope></dynamicProperty></dynamicProperties><supportsSensitiveDynamicProperties>true</supportsSensitiveDynamicProperties><relationships><relationship><name>failure</name><description>FlowFiles that fail to send will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>FlowFiles that are successfully sent will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_REQUIRED</inputRequirement><systemResourceConsiderations><systemResourceConsideration><resource>MEMORY</resource><description>The entirety of the FlowFile's content (as a String object) will be read into memory in case the property to use the flow file content as the email body is set to true.</description></systemResourceConsideration></systemResourceConsiderations></extension><extension><name>org.apache.nifi.processors.standard.PutFTP</name><type>PROCESSOR</type><description>Sends FlowFiles to an FTP Server</description><tags><tag>remote</tag><tag>copy</tag><tag>egress</tag><tag>put</tag><tag>ftp</tag><tag>archive</tag><tag>files</tag></tags><properties><property><name>Hostname</name><displayName>Hostname</displayName><description>The fully qualified hostname or IP address of the remote system</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Port</name><displayName>Port</displayName><description>The port that the remote system is listening on for file transfers</description><defaultValue>21</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Username</name><displayName>Username</displayName><description>Username</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Password</name><displayName>Password</displayName><description>Password for the user account</description><required>false</required><sensitive>true</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Remote Path</name><displayName>Remote Path</displayName><description>The path on the remote system from which to pull or push files</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Create Directory</name><displayName>Create Directory</displayName><description>Specifies whether or not the remote directory should be created if it does not exist.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Batch Size</name><displayName>Batch Size</displayName><description>The maximum number of FlowFiles to send in a single connection</description><defaultValue>500</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Connection Timeout</name><displayName>Connection Timeout</displayName><description>Amount of time to wait before timing out while creating a connection</description><defaultValue>30 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Data Timeout</name><displayName>Data Timeout</displayName><description>When transferring a file between the local and remote system, this value specifies how long is allowed to elapse without any data being transferred between systems</description><defaultValue>30 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Conflict Resolution</name><displayName>Conflict Resolution</displayName><description>Determines how to handle the problem of filename collisions</description><defaultValue>NONE</defaultValue><allowableValues><allowableValue><displayName>REPLACE</displayName><value>REPLACE</value><description>Remote file is replaced with new file, FlowFile goes to success</description></allowableValue><allowableValue><displayName>IGNORE</displayName><value>IGNORE</value><description>File is not transferred, FlowFile goes to success</description></allowableValue><allowableValue><displayName>RENAME</displayName><value>RENAME</value><description>New file is renamed with a one-up number at the beginning, FlowFile goes to success</description></allowableValue><allowableValue><displayName>REJECT</displayName><value>REJECT</value><description>File is not transferred, FlowFile goes to reject</description></allowableValue><allowableValue><displayName>FAIL</displayName><value>FAIL</value><description>File is not transferred, FlowFile goes to failure</description></allowableValue><allowableValue><displayName>NONE</displayName><value>NONE</value><description>Do not check for conflict before transfer, FlowFile goes to success or failure</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Dot Rename</name><displayName>Dot Rename</displayName><description>If true, then the filename of the sent file is prepended with a "." and then renamed back to the original once the file is completely sent. Otherwise, there is no rename. This property is ignored if the Temporary Filename property is set.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Temporary Filename</name><displayName>Temporary Filename</displayName><description>If set, the filename of the sent file will be equal to the value specified during the transfer and after successful completion will be renamed to the original filename. If this value is set, the Dot Rename property is ignored.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Transfer Mode</name><displayName>Transfer Mode</displayName><description>The FTP Transfer Mode</description><defaultValue>Binary</defaultValue><allowableValues><allowableValue><displayName>Binary</displayName><value>Binary</value><description></description></allowableValue><allowableValue><displayName>ASCII</displayName><value>ASCII</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Connection Mode</name><displayName>Connection Mode</displayName><description>The FTP Connection Mode</description><defaultValue>Passive</defaultValue><allowableValues><allowableValue><displayName>Active</displayName><value>Active</value><description></description></allowableValue><allowableValue><displayName>Passive</displayName><value>Passive</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Reject Zero-Byte Files</name><displayName>Reject Zero-Byte Files</displayName><description>Determines whether or not Zero-byte files should be rejected without attempting to transfer</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Last Modified Time</name><displayName>Last Modified Time</displayName><description>The lastModifiedTime to assign to the file after transferring it. If not set, the lastModifiedTime will not be changed. Format must be yyyy-MM-dd'T'HH:mm:ssZ. You may also use expression language such as ${file.lastModifiedTime}. If the value is invalid, the processor will not be invalid but will fail to change lastModifiedTime of the file.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Permissions</name><displayName>Permissions</displayName><description>The permissions to assign to the file after transferring it. Format must be either UNIX rwxrwxrwx with a - in place of denied permissions (e.g. rw-r--r--) or an octal number (e.g. 644). If not set, the permissions will not be changed. You may also use expression language such as ${file.permissions}. If the value is invalid, the processor will not be invalid but will fail to change permissions of the file.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Use Compression</name><displayName>Use Compression</displayName><description>Indicates whether or not ZLIB compression should be used when transferring files</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>proxy-configuration-service</name><displayName>Proxy Configuration Service</displayName><description>Specifies the Proxy Configuration Controller Service to proxy network requests. Supported proxies: HTTP + AuthN, SOCKS + AuthN</description><controllerServiceDefinition><className>org.apache.nifi.proxy.ProxyConfigurationService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Internal Buffer Size</name><displayName>Internal Buffer Size</displayName><description>Set the internal buffer size for buffered data streams</description><defaultValue>16KB</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>ftp-use-utf8</name><displayName>Use UTF-8 Encoding</displayName><description>Tells the client to use UTF-8 encoding when processing files and filenames. If set to true, the server must also support UTF-8 encoding.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>pre.cmd._____</name><value>Not used</value><description>The command specified in the key will be executed before doing a put.  You may add these optional properties  to send any commands to the FTP server before the file is actually transferred (before the put command). This option is only available for the PutFTP processor, as only FTP has this functionality. This is essentially the same as sending quote commands to an FTP server from the command line.  While this is the same as sending a quote command, it is very important that you leave off the .</description><expressionLanguageScope>NONE</expressionLanguageScope></dynamicProperty><dynamicProperty><name>post.cmd._____</name><value>Not used</value><description>The command specified in the key will be executed after doing a put.  You may add these optional properties  to send any commands to the FTP server before the file is actually transferred (before the put command). This option is only available for the PutFTP processor, as only FTP has this functionality. This is essentially the same as sending quote commands to an FTP server from the command line.  While this is the same as sending a quote command, it is very important that you leave off the .</description><expressionLanguageScope>NONE</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>failure</name><description>FlowFiles that failed to send to the remote system; failure is usually looped back to this processor</description><autoTerminated>false</autoTerminated></relationship><relationship><name>reject</name><description>FlowFiles that were rejected by the destination system</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>FlowFiles that are successfully sent will be routed to success</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_REQUIRED</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.GetFTP</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.PutFile</name><type>PROCESSOR</type><description>Writes the contents of a FlowFile to the local file system</description><tags><tag>put</tag><tag>local</tag><tag>copy</tag><tag>archive</tag><tag>files</tag><tag>filesystem</tag></tags><properties><property><name>Directory</name><displayName>Directory</displayName><description>The directory to which files should be written. You may use expression language such as /aa/bb/${path}</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Conflict Resolution Strategy</name><displayName>Conflict Resolution Strategy</displayName><description>Indicates what should happen when a file with the same name already exists in the output directory</description><defaultValue>fail</defaultValue><allowableValues><allowableValue><displayName>replace</displayName><value>replace</value><description></description></allowableValue><allowableValue><displayName>ignore</displayName><value>ignore</value><description></description></allowableValue><allowableValue><displayName>fail</displayName><value>fail</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Create Missing Directories</name><displayName>Create Missing Directories</displayName><description>If true, then missing destination directories will be created. If false, flowfiles are penalized and sent to failure.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum File Count</name><displayName>Maximum File Count</displayName><description>Specifies the maximum number of files that can exist in the output directory</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Last Modified Time</name><displayName>Last Modified Time</displayName><description>Sets the lastModifiedTime on the output file to the value of this attribute.  Format must be yyyy-MM-dd'T'HH:mm:ssZ.  You may also use expression language such as ${file.lastModifiedTime}.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Permissions</name><displayName>Permissions</displayName><description>Sets the permissions on the output file to the value of this attribute.  Format must be either UNIX rwxrwxrwx with a - in place of denied permissions (e.g. rw-r--r--) or an octal number (e.g. 644).  You may also use expression language such as ${file.permissions}.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Owner</name><displayName>Owner</displayName><description>Sets the owner on the output file to the value of this attribute.  You may also use expression language such as ${file.owner}. Note on many operating systems Nifi must be running as a super-user to have the permissions to set the file owner.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Group</name><displayName>Group</displayName><description>Sets the group on the output file to the value of this attribute.  You may also use expression language such as ${file.group}.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>Files that could not be written to the output directory for some reason are transferred to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>Files that have been successfully written to the output directory are transferred to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><readsAttributes><readsAttribute><name>filename</name><description>The filename to use when writing the FlowFile to disk.</description></readsAttribute></readsAttributes><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><restricted><restrictions><restriction><requiredPermission>write filesystem</requiredPermission><explanation>Provides operator the ability to write to any file that NiFi has access to.</explanation></restriction></restrictions></restricted><inputRequirement>INPUT_REQUIRED</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.FetchFile</see><see>org.apache.nifi.processors.standard.GetFile</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.PutRecord</name><type>PROCESSOR</type><description>The PutRecord processor uses a specified RecordReader to input (possibly multiple) records from an incoming flow file, and sends them to a destination specified by a Record Destination Service (i.e. record sink).</description><tags><tag>record</tag><tag>put</tag><tag>sink</tag></tags><properties><property><name>put-record-reader</name><displayName>Record Reader</displayName><description>Specifies the Controller Service to use for reading incoming data</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>put-record-sink</name><displayName>Record Destination Service</displayName><description>Specifies the Controller Service to use for writing out the query result records to some destination.</description><controllerServiceDefinition><className>org.apache.nifi.record.sink.RecordSinkService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>put-record-include-zero-record-results</name><displayName>Include Zero Record Results</displayName><description>If no records are read from the incoming FlowFile, this property specifies whether or not an empty record set will be transmitted. The original FlowFile will still be routed to success, but if no transmission occurs, no provenance SEND event will be generated.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>A FlowFile is routed to this relationship if the records could not be transmitted and retrying the operation will also fail</description><autoTerminated>false</autoTerminated></relationship><relationship><name>retry</name><description>The original FlowFile is routed to this relationship if the records could not be transmitted but attempting the operation again may succeed</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>The original FlowFile will be routed to this relationship if the records were transmitted successfully</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.PutSFTP</name><type>PROCESSOR</type><description>Sends FlowFiles to an SFTP Server</description><tags><tag>remote</tag><tag>copy</tag><tag>egress</tag><tag>put</tag><tag>sftp</tag><tag>archive</tag><tag>files</tag></tags><properties><property><name>Hostname</name><displayName>Hostname</displayName><description>The fully qualified hostname or IP address of the remote system</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Port</name><displayName>Port</displayName><description>The port that the remote system is listening on for file transfers</description><defaultValue>22</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Username</name><displayName>Username</displayName><description>Username</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Password</name><displayName>Password</displayName><description>Password for the user account</description><required>false</required><sensitive>true</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Private Key Path</name><displayName>Private Key Path</displayName><description>The fully qualified path to the Private Key file</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType></resourceTypes></resourceDefinition></property><property><name>Private Key Passphrase</name><displayName>Private Key Passphrase</displayName><description>Password for the private key</description><required>false</required><sensitive>true</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Remote Path</name><displayName>Remote Path</displayName><description>The path on the remote system from which to pull or push files</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Create Directory</name><displayName>Create Directory</displayName><description>Specifies whether or not the remote directory should be created if it does not exist.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Disable Directory Listing</name><displayName>Disable Directory Listing</displayName><description>If set to 'true', directory listing is not performed prior to create missing directories. By default, this processor executes a directory listing command to see target directory existence before creating missing directories. However, there are situations that you might need to disable the directory listing such as the following. Directory listing might fail with some permission setups (e.g. chmod 100) on a directory. Also, if any other SFTP client created the directory after this processor performed a listing and before a directory creation request by this processor is finished, then an error is returned because the directory already exists.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Batch Size</name><displayName>Batch Size</displayName><description>The maximum number of FlowFiles to send in a single connection</description><defaultValue>500</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Connection Timeout</name><displayName>Connection Timeout</displayName><description>Amount of time to wait before timing out while creating a connection</description><defaultValue>30 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Data Timeout</name><displayName>Data Timeout</displayName><description>When transferring a file between the local and remote system, this value specifies how long is allowed to elapse without any data being transferred between systems</description><defaultValue>30 sec</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Conflict Resolution</name><displayName>Conflict Resolution</displayName><description>Determines how to handle the problem of filename collisions</description><defaultValue>NONE</defaultValue><allowableValues><allowableValue><displayName>REPLACE</displayName><value>REPLACE</value><description>Remote file is replaced with new file, FlowFile goes to success</description></allowableValue><allowableValue><displayName>IGNORE</displayName><value>IGNORE</value><description>File is not transferred, FlowFile goes to success</description></allowableValue><allowableValue><displayName>RENAME</displayName><value>RENAME</value><description>New file is renamed with a one-up number at the beginning, FlowFile goes to success</description></allowableValue><allowableValue><displayName>REJECT</displayName><value>REJECT</value><description>File is not transferred, FlowFile goes to reject</description></allowableValue><allowableValue><displayName>FAIL</displayName><value>FAIL</value><description>File is not transferred, FlowFile goes to failure</description></allowableValue><allowableValue><displayName>NONE</displayName><value>NONE</value><description>Do not check for conflict before transfer, FlowFile goes to success or failure</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Reject Zero-Byte Files</name><displayName>Reject Zero-Byte Files</displayName><description>Determines whether or not Zero-byte files should be rejected without attempting to transfer</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Dot Rename</name><displayName>Dot Rename</displayName><description>If true, then the filename of the sent file is prepended with a "." and then renamed back to the original once the file is completely sent. Otherwise, there is no rename. This property is ignored if the Temporary Filename property is set.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Temporary Filename</name><displayName>Temporary Filename</displayName><description>If set, the filename of the sent file will be equal to the value specified during the transfer and after successful completion will be renamed to the original filename. If this value is set, the Dot Rename property is ignored.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Host Key File</name><displayName>Host Key File</displayName><description>If supplied, the given file will be used as the Host Key; otherwise, if 'Strict Host Key Checking' property is applied (set to true) then uses the 'known_hosts' and 'known_hosts2' files from ~/.ssh directory else no host key file will be used</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType></resourceTypes></resourceDefinition></property><property><name>Last Modified Time</name><displayName>Last Modified Time</displayName><description>The lastModifiedTime to assign to the file after transferring it. If not set, the lastModifiedTime will not be changed. Format must be yyyy-MM-dd'T'HH:mm:ssZ. You may also use expression language such as ${file.lastModifiedTime}. If the value is invalid, the processor will not be invalid but will fail to change lastModifiedTime of the file.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Permissions</name><displayName>Permissions</displayName><description>The permissions to assign to the file after transferring it. Format must be either UNIX rwxrwxrwx with a - in place of denied permissions (e.g. rw-r--r--) or an octal number (e.g. 644). If not set, the permissions will not be changed. You may also use expression language such as ${file.permissions}. If the value is invalid, the processor will not be invalid but will fail to change permissions of the file.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Remote Owner</name><displayName>Remote Owner</displayName><description>Integer value representing the User ID to set on the file after transferring it. If not set, the owner will not be set. You may also use expression language such as ${file.owner}. If the value is invalid, the processor will not be invalid but will fail to change the owner of the file.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Remote Group</name><displayName>Remote Group</displayName><description>Integer value representing the Group ID to set on the file after transferring it. If not set, the group will not be set. You may also use expression language such as ${file.group}. If the value is invalid, the processor will not be invalid but will fail to change the group of the file.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Strict Host Key Checking</name><displayName>Strict Host Key Checking</displayName><description>Indicates whether or not strict enforcement of hosts keys should be applied</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Send Keep Alive On Timeout</name><displayName>Send Keep Alive On Timeout</displayName><description>Send a Keep Alive message every 5 seconds up to 5 times for an overall timeout of 25 seconds.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Use Compression</name><displayName>Use Compression</displayName><description>Indicates whether or not ZLIB compression should be used when transferring files</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>proxy-configuration-service</name><displayName>Proxy Configuration Service</displayName><description>Specifies the Proxy Configuration Controller Service to proxy network requests. Supported proxies: HTTP + AuthN, SOCKS + AuthN</description><controllerServiceDefinition><className>org.apache.nifi.proxy.ProxyConfigurationService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Ciphers Allowed</name><displayName>Ciphers Allowed</displayName><description>A comma-separated list of Ciphers allowed for SFTP connections. Leave unset to allow all. Available options are: 3des-cbc, 3des-ctr, aes128-cbc, aes128-ctr, aes128-gcm@openssh.com, aes192-cbc, aes192-ctr, aes256-cbc, aes256-ctr, aes256-gcm@openssh.com, arcfour, arcfour128, arcfour256, blowfish-cbc, blowfish-ctr, cast128-cbc, cast128-ctr, chacha20-poly1305@openssh.com, idea-cbc, idea-ctr, serpent128-cbc, serpent128-ctr, serpent192-cbc, serpent192-ctr, serpent256-cbc, serpent256-ctr, twofish-cbc, twofish128-cbc, twofish128-ctr, twofish192-cbc, twofish192-ctr, twofish256-cbc, twofish256-ctr</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Key Algorithms Allowed</name><displayName>Key Algorithms Allowed</displayName><description>A comma-separated list of Key Algorithms allowed for SFTP connections. Leave unset to allow all. Available options are: ecdsa-sha2-nistp256, ecdsa-sha2-nistp256-cert-v01@openssh.com, ecdsa-sha2-nistp384, ecdsa-sha2-nistp384-cert-v01@openssh.com, ecdsa-sha2-nistp521, ecdsa-sha2-nistp521-cert-v01@openssh.com, rsa-sha2-256, rsa-sha2-512, ssh-dss, ssh-dss-cert-v01@openssh.com, ssh-ed25519, ssh-ed25519-cert-v01@openssh.com, ssh-rsa, ssh-rsa-cert-v01@openssh.com</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Key Exchange Algorithms Allowed</name><displayName>Key Exchange Algorithms Allowed</displayName><description>A comma-separated list of Key Exchange Algorithms allowed for SFTP connections. Leave unset to allow all. Available options are: curve25519-sha256, curve25519-sha256@libssh.org, diffie-hellman-group-exchange-sha1, diffie-hellman-group-exchange-sha256, diffie-hellman-group1-sha1, diffie-hellman-group14-sha1, diffie-hellman-group14-sha256, diffie-hellman-group14-sha256@ssh.com, diffie-hellman-group15-sha256, diffie-hellman-group15-sha256@ssh.com, diffie-hellman-group15-sha384@ssh.com, diffie-hellman-group15-sha512, diffie-hellman-group16-sha256, diffie-hellman-group16-sha384@ssh.com, diffie-hellman-group16-sha512, diffie-hellman-group16-sha512@ssh.com, diffie-hellman-group17-sha512, diffie-hellman-group18-sha512, diffie-hellman-group18-sha512@ssh.com, ecdh-sha2-nistp256, ecdh-sha2-nistp384, ecdh-sha2-nistp521, ext-info-c</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Message Authentication Codes Allowed</name><displayName>Message Authentication Codes Allowed</displayName><description>A comma-separated list of Message Authentication Codes allowed for SFTP connections. Leave unset to allow all. Available options are: hmac-md5, hmac-md5-96, hmac-md5-96-etm@openssh.com, hmac-md5-etm@openssh.com, hmac-ripemd160, hmac-ripemd160-96, hmac-ripemd160-etm@openssh.com, hmac-ripemd160@openssh.com, hmac-sha1, hmac-sha1-96, hmac-sha1-96@openssh.com, hmac-sha1-etm@openssh.com, hmac-sha2-256, hmac-sha2-256-etm@openssh.com, hmac-sha2-512, hmac-sha2-512-etm@openssh.com</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>FlowFiles that failed to send to the remote system; failure is usually looped back to this processor</description><autoTerminated>false</autoTerminated></relationship><relationship><name>reject</name><description>FlowFiles that were rejected by the destination system</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>FlowFiles that are successfully sent will be routed to success</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_REQUIRED</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.GetSFTP</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.PutSQL</name><type>PROCESSOR</type><description>Executes a SQL UPDATE or INSERT command. The content of an incoming FlowFile is expected to be the SQL command to execute. The SQL command may use the ? to escape parameters. In this case, the parameters to use must exist as FlowFile attributes with the naming convention sql.args.N.type and sql.args.N.value, where N is a positive integer. The sql.args.N.type is expected to be a number indicating the JDBC Type. The content of the FlowFile is expected to be in UTF-8 format.</description><tags><tag>sql</tag><tag>put</tag><tag>rdbms</tag><tag>database</tag><tag>update</tag><tag>insert</tag><tag>relational</tag></tags><properties><property><name>JDBC Connection Pool</name><displayName>JDBC Connection Pool</displayName><description>Specifies the JDBC Connection Pool to use in order to convert the JSON message to a SQL statement. The Connection Pool is necessary in order to determine the appropriate database column types.</description><controllerServiceDefinition><className>org.apache.nifi.dbcp.DBCPService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>putsql-sql-statement</name><displayName>SQL Statement</displayName><description>The SQL statement to execute. The statement can be empty, a constant value, or built from attributes using Expression Language. If this property is specified, it will be used regardless of the content of incoming FlowFiles. If this property is empty, the content of the incoming FlowFile is expected to contain a valid SQL statement, to be issued by the processor to the database.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Support Fragmented Transactions</name><displayName>Support Fragmented Transactions</displayName><description>If true, when a FlowFile is consumed by this Processor, the Processor will first check the fragment.identifier and fragment.count attributes of that FlowFile. If the fragment.count value is greater than 1, the Processor will not process any FlowFile with that fragment.identifier until all are available; at that point, it will process all FlowFiles with that fragment.identifier as a single transaction, in the order specified by the FlowFiles' fragment.index attributes. This Provides atomicity of those SQL statements. Once any statement of this transaction throws exception when executing, this transaction will be rolled back. When transaction rollback happened, none of these FlowFiles would be routed to 'success'. If the &lt;Rollback On Failure&gt; is set true, these FlowFiles will stay in the input relationship. When the &lt;Rollback On Failure&gt; is set false,, if any of these FlowFiles will be routed to 'retry', all of these FlowFiles will be routed to 'retry'.Otherwise, they will be routed to 'failure'. If this value is false, these attributes will be ignored and the updates will occur independent of one another.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>database-session-autocommit</name><displayName>Database Session AutoCommit</displayName><description>The autocommit mode to set on the database connection being used. If set to false, the operation(s) will be explicitly committed or rolled back (based on success or failure respectively), if set to true the driver/database handles the commit/rollback.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Transaction Timeout</name><displayName>Transaction Timeout</displayName><description>If the &lt;Support Fragmented Transactions&gt; property is set to true, specifies how long to wait for all FlowFiles for a particular fragment.identifier attribute to arrive before just transferring all of the FlowFiles with that identifier to the 'failure' relationship</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Batch Size</name><displayName>Batch Size</displayName><description>The preferred number of FlowFiles to put to the database in a single transaction</description><defaultValue>100</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Obtain Generated Keys</name><displayName>Obtain Generated Keys</displayName><description>If true, any key that is automatically generated by the database will be added to the FlowFile that generated it using the sql.generate.key attribute. This may result in slightly slower performance and is not supported by all databases.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>rollback-on-failure</name><displayName>Rollback On Failure</displayName><description>Specify how to handle error. By default (false), if an error occurs while processing a FlowFile, the FlowFile will be routed to 'failure' or 'retry' relationship based on error type, and processor can continue with next FlowFile. Instead, you may want to rollback currently processed FlowFiles and stop further processing immediately. In that case, you can do so by enabling this 'Rollback On Failure' property.  If enabled, failed FlowFiles will stay in the input relationship without penalizing it and being processed repeatedly until it gets processed successfully or removed by other means. It is important to set adequate 'Yield Duration' to avoid retrying too frequently.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>A FlowFile is routed to this relationship if the database cannot be updated and retrying the operation will also fail, such as an invalid query or an integrity constraint violation</description><autoTerminated>false</autoTerminated></relationship><relationship><name>retry</name><description>A FlowFile is routed to this relationship if the database cannot be updated but attempting the operation again may succeed</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>A FlowFile is routed to this relationship after the database is successfully updated</description><autoTerminated>false</autoTerminated></relationship></relationships><readsAttributes><readsAttribute><name>fragment.identifier</name><description>If the &lt;Support Fragment Transactions&gt; property is true, this attribute is used to determine whether or not two FlowFiles belong to the same transaction.</description></readsAttribute><readsAttribute><name>fragment.count</name><description>If the &lt;Support Fragment Transactions&gt; property is true, this attribute is used to determine how many FlowFiles are needed to complete the transaction.</description></readsAttribute><readsAttribute><name>fragment.index</name><description>If the &lt;Support Fragment Transactions&gt; property is true, this attribute is used to determine the order that the FlowFiles in a transaction should be evaluated.</description></readsAttribute><readsAttribute><name>sql.args.N.type</name><description>Incoming FlowFiles are expected to be parametrized SQL statements. The type of each Parameter is specified as an integer that represents the JDBC Type of the parameter.</description></readsAttribute><readsAttribute><name>sql.args.N.value</name><description>Incoming FlowFiles are expected to be parametrized SQL statements. The value of the Parameters are specified as sql.args.1.value, sql.args.2.value, sql.args.3.value, and so on. The type of the sql.args.1.value Parameter is specified by the sql.args.1.type attribute.</description></readsAttribute><readsAttribute><name>sql.args.N.format</name><description>This attribute is always optional, but default options may not always work for your data. Incoming FlowFiles are expected to be parametrized SQL statements. In some cases a format option needs to be specified, currently this is only applicable for binary data types, dates, times and timestamps. Binary Data Types (defaults to 'ascii') - ascii: each string character in your attribute value represents a single byte. This is the format provided by Avro Processors. base64: the string is a Base64 encoded string that can be decoded to bytes. hex: the string is hex encoded with all letters in upper case and no '0x' at the beginning. Dates/Times/Timestamps - Date, Time and Timestamp formats all support both custom formats or named format ('yyyy-MM-dd','ISO_OFFSET_DATE_TIME') as specified according to java.time.format.DateTimeFormatter. If not specified, a long value input is expected to be an unix epoch (milli seconds from 1970/1/1), or a string value in 'yyyy-MM-dd' format for Date, 'HH:mm:ss.SSS' for Time (some database engines e.g. Derby or MySQL do not support milliseconds and will truncate milliseconds), 'yyyy-MM-dd HH:mm:ss.SSS' for Timestamp is used.</description></readsAttribute></readsAttributes><writesAttributes><writesAttribute><name>sql.generated.key</name><description>If the database generated a key for an INSERT statement and the Obtain Generated Keys property is set to true, this attribute will be added to indicate the generated key, if possible. This feature is not supported by all database vendors.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.PutSyslog</name><type>PROCESSOR</type><description>Sends Syslog messages to a given host and port over TCP or UDP. Messages are constructed from the "Message ___" properties of the processor which can use expression language to generate messages from incoming FlowFiles. The properties are used to construct messages of the form: (&lt;PRIORITY&gt;)(VERSION )(TIMESTAMP) (HOSTNAME) (BODY) where version is optional.  The constructed messages are checked against regular expressions for RFC5424 and RFC3164 formatted messages. The timestamp can be an RFC5424 timestamp with a format of "yyyy-MM-dd'T'HH:mm:ss.S'Z'" or "yyyy-MM-dd'T'HH:mm:ss.S+hh:mm", or it can be an RFC3164 timestamp with a format of "MMM d HH:mm:ss". If a message is constructed that does not form a valid Syslog message according to the above description, then it is routed to the invalid relationship. Valid messages are sent to the Syslog server and successes are routed to the success relationship, failures routed to the failure relationship.</description><tags><tag>syslog</tag><tag>put</tag><tag>udp</tag><tag>tcp</tag><tag>logs</tag></tags><properties><property><name>Hostname</name><displayName>Hostname</displayName><description>The IP address or hostname of the Syslog server.</description><defaultValue>localhost</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Protocol</name><displayName>Protocol</displayName><description>The protocol for Syslog communication.</description><defaultValue>UDP</defaultValue><allowableValues><allowableValue><displayName>TCP</displayName><value>TCP</value><description></description></allowableValue><allowableValue><displayName>UDP</displayName><value>UDP</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Port</name><displayName>Port</displayName><description>The port for Syslog communication. Note that Expression language is not evaluated per FlowFile.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Size of Socket Send Buffer</name><displayName>Max Size of Socket Send Buffer</displayName><description>The maximum size of the socket send buffer that should be used. This is a suggestion to the Operating System to indicate how big the socket buffer should be. If this value is set too low, the buffer may fill up before the data can be read, and incoming data will be dropped.</description><defaultValue>1 MB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>SSL Context Service</name><displayName>SSL Context Service</displayName><description>The Controller Service to use in order to obtain an SSL Context. If this property is set, syslog messages will be sent over a secure connection.</description><controllerServiceDefinition><className>org.apache.nifi.ssl.SSLContextProvider</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Protocol</propertyName><propertyDisplayName>Protocol</propertyDisplayName><dependentValues><dependentValue>TCP</dependentValue></dependentValues></dependency></dependencies></property><property><name>Idle Connection Expiration</name><displayName>Idle Connection Expiration</displayName><description>The amount of time a connection should be held open without being used before closing the connection.</description><defaultValue>5 seconds</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Timeout</name><displayName>Timeout</displayName><description>The timeout for connecting to and communicating with the syslog server. Does not apply to UDP. Note that Expression language is not evaluated per FlowFile.</description><defaultValue>10 seconds</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Batch Size</name><displayName>Batch Size</displayName><description>The number of incoming FlowFiles to process in a single execution of this processor.</description><defaultValue>25</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Character Set</name><displayName>Character Set</displayName><description>Specifies the character set of the Syslog messages. Note that Expression language is not evaluated per FlowFile.</description><defaultValue>UTF-8</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Message Priority</name><displayName>Message Priority</displayName><description>The priority for the Syslog messages, excluding &lt; &gt;.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Message Version</name><displayName>Message Version</displayName><description>The version for the Syslog messages.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Message Timestamp</name><displayName>Message Timestamp</displayName><description>The timestamp for the Syslog messages. The timestamp can be an RFC5424 timestamp with a format of "yyyy-MM-dd'T'HH:mm:ss.S'Z'" or "yyyy-MM-dd'T'HH:mm:ss.S+hh:mm", " or it can be an RFC3164 timestamp with a format of "MMM d HH:mm:ss".</description><defaultValue>${now():format('MMM d HH:mm:ss')}</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Message Hostname</name><displayName>Message Hostname</displayName><description>The hostname for the Syslog messages.</description><defaultValue>${hostname(true)}</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Message Body</name><displayName>Message Body</displayName><description>The body for the Syslog messages.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>FlowFiles that failed to send to Syslog are sent out this relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>invalid</name><description>FlowFiles that do not form a valid Syslog message are sent out this relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>FlowFiles that are sent successfully to Syslog are sent out this relationship.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><triggerWhenEmpty>true</triggerWhenEmpty><inputRequirement>INPUT_REQUIRED</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.ListenSyslog</see><see>org.apache.nifi.processors.standard.ParseSyslog</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.PutTCP</name><type>PROCESSOR</type><description>Sends serialized FlowFiles or Records over TCP to a configurable destination with optional support for TLS</description><tags><tag>remote</tag><tag>egress</tag><tag>put</tag><tag>tcp</tag></tags><properties><property><name>Hostname</name><displayName>Hostname</displayName><description>Destination hostname or IP address</description><defaultValue>localhost</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Port</name><displayName>Port</displayName><description>Destination port number</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Size of Socket Send Buffer</name><displayName>Max Size of Socket Send Buffer</displayName><description>The maximum size of the socket send buffer that should be used. This is a suggestion to the Operating System to indicate how big the socket buffer should be. If this value is set too low, the buffer may fill up before the data can be read, and incoming data will be dropped.</description><defaultValue>1 MB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Idle Connection Expiration</name><displayName>Idle Connection Expiration</displayName><description>The amount of time a connection should be held open without being used before closing the connection. A value of 0 seconds will disable this feature.</description><defaultValue>15 seconds</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Timeout</name><displayName>Timeout</displayName><description>The timeout for connecting to and communicating with the destination. Does not apply to UDP</description><defaultValue>10 seconds</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Connection Per FlowFile</name><displayName>Connection Per FlowFile</displayName><description>Specifies whether to send each FlowFile's content on an individual connection.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>SSL Context Service</name><displayName>SSL Context Service</displayName><description>Specifies the SSL Context Service to enable TLS socket communication</description><controllerServiceDefinition><className>org.apache.nifi.ssl.SSLContextProvider</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Transmission Strategy</name><displayName>Transmission Strategy</displayName><description>Specifies the strategy used for reading input FlowFiles and transmitting messages to the destination socket address</description><defaultValue>FLOWFILE_ORIENTED</defaultValue><allowableValues><allowableValue><displayName>FlowFile-oriented</displayName><value>FLOWFILE_ORIENTED</value><description>Send FlowFile content as a single stream</description></allowableValue><allowableValue><displayName>Record-oriented</displayName><value>RECORD_ORIENTED</value><description>Read Records from input FlowFiles and send serialized Records as individual messages</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Outgoing Message Delimiter</name><displayName>Outgoing Message Delimiter</displayName><description>Specifies the delimiter to use when sending messages out over the same TCP stream. The delimiter is appended to each FlowFile message that is transmitted over the stream so that the receiver can determine when one message ends and the next message begins. Users should ensure that the FlowFile content does not contain the delimiter character to avoid errors. In order to use a new line character you can enter '\n'. For a tab character use '\t'. Finally for a carriage return use '\r'.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Transmission Strategy</propertyName><propertyDisplayName>Transmission Strategy</propertyDisplayName><dependentValues><dependentValue>FLOWFILE_ORIENTED</dependentValue></dependentValues></dependency></dependencies></property><property><name>Character Set</name><displayName>Character Set</displayName><description>Specifies the character set of the data being sent.</description><defaultValue>UTF-8</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Transmission Strategy</propertyName><propertyDisplayName>Transmission Strategy</propertyDisplayName><dependentValues><dependentValue>FLOWFILE_ORIENTED</dependentValue></dependentValues></dependency></dependencies></property><property><name>Record Reader</name><displayName>Record Reader</displayName><description>Specifies the Controller Service to use for reading Records from input FlowFiles</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Transmission Strategy</propertyName><propertyDisplayName>Transmission Strategy</propertyDisplayName><dependentValues><dependentValue>RECORD_ORIENTED</dependentValue></dependentValues></dependency></dependencies></property><property><name>Record Writer</name><displayName>Record Writer</displayName><description>Specifies the Controller Service to use for writing Records to the configured socket address</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Transmission Strategy</propertyName><propertyDisplayName>Transmission Strategy</propertyDisplayName><dependentValues><dependentValue>RECORD_ORIENTED</dependentValue></dependentValues></dependency></dependencies></property></properties><relationships><relationship><name>failure</name><description>FlowFiles that failed to send to the destination are sent out this relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>FlowFiles that are sent successfully to the destination are sent out this relationship.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>record.count.transmitted</name><description>Count of records transmitted to configured destination address</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_REQUIRED</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.ListenTCP</see><see>org.apache.nifi.processors.standard.PutUDP</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.PutUDP</name><type>PROCESSOR</type><description>The PutUDP processor receives a FlowFile and packages the FlowFile content into a single UDP datagram packet which is then transmitted to the configured UDP server. The user must ensure that the FlowFile content being fed to this processor is not larger than the maximum size for the underlying UDP transport. The maximum transport size will vary based on the platform setup but is generally just under 64KB. FlowFiles will be marked as failed if their content is larger than the maximum transport size.</description><tags><tag>remote</tag><tag>egress</tag><tag>put</tag><tag>udp</tag></tags><properties><property><name>Hostname</name><displayName>Hostname</displayName><description>Destination hostname or IP address</description><defaultValue>localhost</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Port</name><displayName>Port</displayName><description>Destination port number</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Size of Socket Send Buffer</name><displayName>Max Size of Socket Send Buffer</displayName><description>The maximum size of the socket send buffer that should be used. This is a suggestion to the Operating System to indicate how big the socket buffer should be. If this value is set too low, the buffer may fill up before the data can be read, and incoming data will be dropped.</description><defaultValue>1 MB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Idle Connection Expiration</name><displayName>Idle Connection Expiration</displayName><description>The amount of time a connection should be held open without being used before closing the connection. A value of 0 seconds will disable this feature.</description><defaultValue>15 seconds</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Timeout</name><displayName>Timeout</displayName><description>The timeout for connecting to and communicating with the destination. Does not apply to UDP</description><defaultValue>10 seconds</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>FlowFiles that failed to send to the destination are sent out this relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>FlowFiles that are sent successfully to the destination are sent out this relationship.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_REQUIRED</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.ListenUDP</see><see>org.apache.nifi.processors.standard.PutTCP</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.QueryDatabaseTable</name><type>PROCESSOR</type><description>Generates a SQL select query, or uses a provided statement, and executes it to fetch all rows whose values in the specified Maximum Value column(s) are larger than the previously-seen maxima. Query result will be converted to Avro format. Expression Language is supported for several properties, but no incoming connections are permitted. The Environment/System properties may be used to provide values for any property containing Expression Language. If it is desired to leverage flow file attributes to perform these queries, the GenerateTableFetch and/or ExecuteSQL processors can be used for this purpose. Streaming is used so arbitrarily large result sets are supported. This processor can be scheduled to run on a timer or cron expression, using the standard scheduling methods. This processor is intended to be run on the Primary Node only. FlowFile attribute 'querydbtable.row.count' indicates how many rows were selected.</description><tags><tag>sql</tag><tag>select</tag><tag>jdbc</tag><tag>query</tag><tag>database</tag></tags><properties><property><name>Database Connection Pooling Service</name><displayName>Database Connection Pooling Service</displayName><description>The Controller Service that is used to obtain a connection to the database.</description><controllerServiceDefinition><className>org.apache.nifi.dbcp.DBCPService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>db-fetch-db-type</name><displayName>Database Type</displayName><description>Database Type for generating statements specific to a particular service or vendor.
The Generic Type supports most cases but selecting a specific type enables optimal processing
or additional features.
</description><defaultValue>Generic</defaultValue><allowableValues><allowableValue><displayName>Database Dialect Service</displayName><value>Database Dialect Service</value><description>Requires configuring a Database Dialect Service for SQL statements</description></allowableValue><allowableValue><displayName>Generic</displayName><value>Generic</value><description>Generates ANSI SQL</description></allowableValue><allowableValue><displayName>Oracle</displayName><value>Oracle</value><description>Generates Oracle compliant SQL</description></allowableValue><allowableValue><displayName>Oracle 12+</displayName><value>Oracle 12+</value><description>Generates Oracle compliant SQL for version 12 or greater</description></allowableValue><allowableValue><displayName>MS SQL 2012+</displayName><value>MS SQL 2012+</value><description>Generates MS SQL Compatible SQL, for version 2012 or greater</description></allowableValue><allowableValue><displayName>MS SQL 2008</displayName><value>MS SQL 2008</value><description>Generates MS SQL Compatible SQL for version 2008</description></allowableValue><allowableValue><displayName>MySQL</displayName><value>MySQL</value><description>Generates MySQL compatible SQL</description></allowableValue><allowableValue><displayName>PostgreSQL</displayName><value>PostgreSQL</value><description>Generates PostgreSQL compatible SQL</description></allowableValue><allowableValue><displayName>Phoenix</displayName><value>Phoenix</value><description>Generates Phoenix compliant SQL</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Database Dialect Service</name><displayName>Database Dialect Service</displayName><description>Database Dialect Service for generating statements specific to a particular service or vendor.</description><controllerServiceDefinition><className>org.apache.nifi.database.dialect.service.api.DatabaseDialectService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>db-fetch-db-type</propertyName><propertyDisplayName>Database Type</propertyDisplayName><dependentValues><dependentValue>Database Dialect Service</dependentValue></dependentValues></dependency></dependencies></property><property><name>Table Name</name><displayName>Table Name</displayName><description>The name of the database table to be queried. When a custom query is used, this property is used to alias the query and appears as an attribute on the FlowFile.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Columns to Return</name><displayName>Columns to Return</displayName><description>A comma-separated list of column names to be used in the query. If your database requires special treatment of the names (quoting, e.g.), each name should include such treatment. If no column names are supplied, all columns in the specified table will be returned. NOTE: It is important to use consistent column names for a given table for incremental fetch to work properly.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>db-fetch-where-clause</name><displayName>Additional WHERE clause</displayName><description>A custom clause to be added in the WHERE condition when building SQL queries.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>db-fetch-sql-query</name><displayName>Custom Query</displayName><description>A custom SQL query used to retrieve data. Instead of building a SQL query from other properties, this query will be wrapped as a sub-query. Query must have no ORDER BY statement.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum-value Columns</name><displayName>Maximum-value Columns</displayName><description>A comma-separated list of column names. The processor will keep track of the maximum value for each column that has been returned since the processor started running. Using multiple columns implies an order to the column list, and each column's values are expected to increase more slowly than the previous columns' values. Thus, using multiple columns implies a hierarchical structure of columns, which is usually used for partitioning tables. This processor can be used to retrieve only those rows that have been added/updated since the last retrieval. Note that some JDBC types such as bit/boolean are not conducive to maintaining maximum value, so columns of these types should not be listed in this property, and will result in error(s) during processing. If no columns are provided, all rows from the table will be considered, which could have a performance impact. NOTE: It is important to use consistent max-value column names for a given table for incremental fetch to work properly.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>initial-load-strategy</name><displayName>Initial Load Strategy</displayName><description>How to handle existing rows in the database table when the processor is started for the first time (or its state has been cleared). The property will be ignored, if any 'initial.maxvalue.*' dynamic property has also been configured.</description><defaultValue>Start at Beginning</defaultValue><allowableValues><allowableValue><displayName>Start at Beginning</displayName><value>Start at Beginning</value><description>Loads all existing rows from the database table.</description></allowableValue><allowableValue><displayName>Start at Current Maximum Values</displayName><value>Start at Current Maximum Values</value><description>Loads only the newly inserted or updated rows based on the maximum value(s) of the column(s) configured in the 'Maximum-value Columns' property.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Wait Time</name><displayName>Max Wait Time</displayName><description>The maximum amount of time allowed for a running SQL select query , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><defaultValue>0 seconds</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Fetch Size</name><displayName>Fetch Size</displayName><description>The number of result rows to be fetched from the result set at a time. This is a hint to the database driver and may not be honored and/or exact. If the value specified is zero, then the hint is ignored. If using PostgreSQL, then 'Set Auto Commit' must be equal to 'false' to cause 'Fetch Size' to take effect.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Set Auto Commit</name><displayName>Set Auto Commit</displayName><description>Allows enabling or disabling the auto commit functionality of the DB connection. Default value is 'No value set'. 'No value set' will leave the db connection's auto commit mode unchanged. For some JDBC drivers such as PostgreSQL driver, it is required to disable the auto commit functionality to get the 'Fetch Size' setting to take effect. When auto commit is enabled, PostgreSQL driver ignores 'Fetch Size' setting and loads all rows of the result set to memory at once. This could lead for a large amount of memory usage when executing queries which fetch large data sets. More Details of this behaviour in PostgreSQL driver can be found in https://jdbc.postgresql.org//documentation/head/query.html.</description><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>qdbt-max-rows</name><displayName>Max Rows Per Flow File</displayName><description>The maximum number of result rows that will be included in a single FlowFile. This will allow you to break up very large result sets into multiple FlowFiles. If the value specified is zero, then all rows are returned in a single FlowFile.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>qdbt-output-batch-size</name><displayName>Output Batch Size</displayName><description>The number of output FlowFiles to queue before committing the process session. When set to zero, the session will be committed when all result set rows have been processed and the output FlowFiles are ready for transfer to the downstream relationship. For large result sets, this can cause a large burst of FlowFiles to be transferred at the end of processor execution. If this property is set, then when the specified number of FlowFiles are ready for transfer, then the session will be committed, thus releasing the FlowFiles to the downstream relationship. NOTE: The maxvalue.* and fragment.count attributes will not be set on FlowFiles when this property is set.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>qdbt-max-frags</name><displayName>Maximum Number of Fragments</displayName><description>The maximum number of fragments. If the value specified is zero, then all fragments are returned. This prevents OutOfMemoryError when this processor ingests huge table. NOTE: Setting this property can result in data loss, as the incoming results are not ordered, and fragments may end at arbitrary boundaries where rows are not included in the result set.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dbf-normalize</name><displayName>Normalize Table/Column Names</displayName><description>Whether to change non-Avro-compatible characters in column names to Avro-compatible characters. For example, colons and periods will be changed to underscores in order to build a valid Avro record.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>transaction-isolation-level</name><displayName>Transaction Isolation Level</displayName><description>This setting will set the transaction isolation level for the database connection for drivers that support this setting</description><allowableValues><allowableValue><displayName>TRANSACTION_NONE</displayName><value>0</value><description></description></allowableValue><allowableValue><displayName>TRANSACTION_READ_COMMITTED</displayName><value>2</value><description></description></allowableValue><allowableValue><displayName>TRANSACTION_READ_UNCOMMITTED</displayName><value>1</value><description></description></allowableValue><allowableValue><displayName>TRANSACTION_REPEATABLE_READ</displayName><value>4</value><description></description></allowableValue><allowableValue><displayName>TRANSACTION_SERIALIZABLE</displayName><value>8</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dbf-user-logical-types</name><displayName>Use Avro Logical Types</displayName><description>Whether to use Avro Logical Types for DECIMAL/NUMBER, DATE, TIME and TIMESTAMP columns. If disabled, written as string. If enabled, Logical types are used and written as its underlying type, specifically, DECIMAL/NUMBER as logical 'decimal': written as bytes with additional precision and scale meta data, DATE as logical 'date-millis': written as int denoting days since Unix epoch (1970-01-01), TIME as logical 'time-millis': written as int denoting milliseconds since Unix epoch, and TIMESTAMP as logical 'timestamp-millis': written as long denoting milliseconds since Unix epoch. If a reader of written Avro records also knows these logical types, then these values can be deserialized with more context depending on reader implementation.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dbf-default-precision</name><displayName>Default Decimal Precision</displayName><description>When a DECIMAL/NUMBER value is written as a 'decimal' Avro logical type, a specific 'precision' denoting number of available digits is required. Generally, precision is defined by column data type definition or database engines default. However undefined precision (0) can be returned from some database engines. 'Default Decimal Precision' is used when writing those undefined precision numbers.</description><defaultValue>10</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dbf-default-scale</name><displayName>Default Decimal Scale</displayName><description>When a DECIMAL/NUMBER value is written as a 'decimal' Avro logical type, a specific 'scale' denoting number of available decimal digits is required. Generally, scale is defined by column data type definition or database engines default. However when undefined precision (0) is returned, scale can also be uncertain with some database engines. 'Default Decimal Scale' is used when writing those undefined numbers. If a value has more decimals than specified scale, then the value will be rounded-up, e.g. 1.53 becomes 2 with scale 0, and 1.5 with scale 1.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>initial.maxvalue.&lt;max_value_column&gt;</name><value>Initial maximum value for the specified column</value><description>Specifies an initial max value for max value column(s). Properties should be added in the format `initial.maxvalue.&lt;max_value_column&gt;`. This value is only used the first time the table is accessed (when a Maximum Value Column is specified).</description><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>success</name><description>Successfully created FlowFile from SQL query result set.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>tablename</name><description>Name of the table being queried</description></writesAttribute><writesAttribute><name>querydbtable.row.count</name><description>The number of rows selected by the query</description></writesAttribute><writesAttribute><name>fragment.identifier</name><description>If 'Max Rows Per Flow File' is set then all FlowFiles from the same query result set will have the same value for the fragment.identifier attribute. This can then be used to correlate the results.</description></writesAttribute><writesAttribute><name>fragment.count</name><description>If 'Max Rows Per Flow File' is set then this is the total number of  FlowFiles produced by a single ResultSet. This can be used in conjunction with the fragment.identifier attribute in order to know how many FlowFiles belonged to the same incoming ResultSet. If Output Batch Size is set, then this attribute will not be populated.</description></writesAttribute><writesAttribute><name>fragment.index</name><description>If 'Max Rows Per Flow File' is set then the position of this FlowFile in the list of outgoing FlowFiles that were all derived from the same result set FlowFile. This can be used in conjunction with the fragment.identifier attribute to know which FlowFiles originated from the same query result set and in what order  FlowFiles were produced</description></writesAttribute><writesAttribute><name>maxvalue.*</name><description>Each attribute contains the observed maximum value of a specified 'Maximum-value Column'. The suffix of the attribute is the name of the column. If Output Batch Size is set, then this attribute will not be populated.</description></writesAttribute></writesAttributes><triggerSerially>true</triggerSerially><primaryNodeOnly>true</primaryNodeOnly><stateful><description>After performing a query on the specified table, the maximum values for the specified column(s) will be retained for use in future executions of the query. This allows the Processor to fetch only those records that have max values greater than the retained values. This can be used for incremental fetching, fetching of newly added rows, etc. To clear the maximum values, clear the state of the processor per the State Management documentation</description><scopes><scope>CLUSTER</scope></scopes></stateful><inputRequirement>INPUT_FORBIDDEN</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.GenerateTableFetch</see><see>org.apache.nifi.processors.standard.ExecuteSQL</see></seeAlso><defaultSchedule><strategy>TIMER_DRIVEN</strategy><period>1 min</period><concurrentTasks>1</concurrentTasks></defaultSchedule></extension><extension><name>org.apache.nifi.processors.standard.QueryDatabaseTableRecord</name><type>PROCESSOR</type><description>Generates a SQL select query, or uses a provided statement, and executes it to fetch all rows whose values in the specified Maximum Value column(s) are larger than the previously-seen maxima. Query result will be converted to the format specified by the record writer. Expression Language is supported for several properties, but no incoming connections are permitted. The Environment/System properties may be used to provide values for any property containing Expression Language. If it is desired to leverage flow file attributes to perform these queries, the GenerateTableFetch and/or ExecuteSQL processors can be used for this purpose. Streaming is used so arbitrarily large result sets are supported. This processor can be scheduled to run on a timer or cron expression, using the standard scheduling methods. This processor is intended to be run on the Primary Node only. FlowFile attribute 'querydbtable.row.count' indicates how many rows were selected.</description><tags><tag>sql</tag><tag>select</tag><tag>jdbc</tag><tag>query</tag><tag>database</tag><tag>record</tag></tags><properties><property><name>Database Connection Pooling Service</name><displayName>Database Connection Pooling Service</displayName><description>The Controller Service that is used to obtain a connection to the database.</description><controllerServiceDefinition><className>org.apache.nifi.dbcp.DBCPService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>db-fetch-db-type</name><displayName>Database Type</displayName><description>Database Type for generating statements specific to a particular service or vendor.
The Generic Type supports most cases but selecting a specific type enables optimal processing
or additional features.
</description><defaultValue>Generic</defaultValue><allowableValues><allowableValue><displayName>Database Dialect Service</displayName><value>Database Dialect Service</value><description>Requires configuring a Database Dialect Service for SQL statements</description></allowableValue><allowableValue><displayName>Generic</displayName><value>Generic</value><description>Generates ANSI SQL</description></allowableValue><allowableValue><displayName>Oracle</displayName><value>Oracle</value><description>Generates Oracle compliant SQL</description></allowableValue><allowableValue><displayName>Oracle 12+</displayName><value>Oracle 12+</value><description>Generates Oracle compliant SQL for version 12 or greater</description></allowableValue><allowableValue><displayName>MS SQL 2012+</displayName><value>MS SQL 2012+</value><description>Generates MS SQL Compatible SQL, for version 2012 or greater</description></allowableValue><allowableValue><displayName>MS SQL 2008</displayName><value>MS SQL 2008</value><description>Generates MS SQL Compatible SQL for version 2008</description></allowableValue><allowableValue><displayName>MySQL</displayName><value>MySQL</value><description>Generates MySQL compatible SQL</description></allowableValue><allowableValue><displayName>PostgreSQL</displayName><value>PostgreSQL</value><description>Generates PostgreSQL compatible SQL</description></allowableValue><allowableValue><displayName>Phoenix</displayName><value>Phoenix</value><description>Generates Phoenix compliant SQL</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Database Dialect Service</name><displayName>Database Dialect Service</displayName><description>Database Dialect Service for generating statements specific to a particular service or vendor.</description><controllerServiceDefinition><className>org.apache.nifi.database.dialect.service.api.DatabaseDialectService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>db-fetch-db-type</propertyName><propertyDisplayName>Database Type</propertyDisplayName><dependentValues><dependentValue>Database Dialect Service</dependentValue></dependentValues></dependency></dependencies></property><property><name>Table Name</name><displayName>Table Name</displayName><description>The name of the database table to be queried. When a custom query is used, this property is used to alias the query and appears as an attribute on the FlowFile.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Columns to Return</name><displayName>Columns to Return</displayName><description>A comma-separated list of column names to be used in the query. If your database requires special treatment of the names (quoting, e.g.), each name should include such treatment. If no column names are supplied, all columns in the specified table will be returned. NOTE: It is important to use consistent column names for a given table for incremental fetch to work properly.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>db-fetch-where-clause</name><displayName>Additional WHERE clause</displayName><description>A custom clause to be added in the WHERE condition when building SQL queries.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>db-fetch-sql-query</name><displayName>Custom Query</displayName><description>A custom SQL query used to retrieve data. Instead of building a SQL query from other properties, this query will be wrapped as a sub-query. Query must have no ORDER BY statement.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>qdbtr-record-writer</name><displayName>Record Writer</displayName><description>Specifies the Controller Service to use for writing results to a FlowFile. The Record Writer may use Inherit Schema to emulate the inferred schema behavior, i.e. an explicit schema need not be defined in the writer, and will be supplied by the same logic used to infer the schema from the column types.</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum-value Columns</name><displayName>Maximum-value Columns</displayName><description>A comma-separated list of column names. The processor will keep track of the maximum value for each column that has been returned since the processor started running. Using multiple columns implies an order to the column list, and each column's values are expected to increase more slowly than the previous columns' values. Thus, using multiple columns implies a hierarchical structure of columns, which is usually used for partitioning tables. This processor can be used to retrieve only those rows that have been added/updated since the last retrieval. Note that some JDBC types such as bit/boolean are not conducive to maintaining maximum value, so columns of these types should not be listed in this property, and will result in error(s) during processing. If no columns are provided, all rows from the table will be considered, which could have a performance impact. NOTE: It is important to use consistent max-value column names for a given table for incremental fetch to work properly.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>initial-load-strategy</name><displayName>Initial Load Strategy</displayName><description>How to handle existing rows in the database table when the processor is started for the first time (or its state has been cleared). The property will be ignored, if any 'initial.maxvalue.*' dynamic property has also been configured.</description><defaultValue>Start at Beginning</defaultValue><allowableValues><allowableValue><displayName>Start at Beginning</displayName><value>Start at Beginning</value><description>Loads all existing rows from the database table.</description></allowableValue><allowableValue><displayName>Start at Current Maximum Values</displayName><value>Start at Current Maximum Values</value><description>Loads only the newly inserted or updated rows based on the maximum value(s) of the column(s) configured in the 'Maximum-value Columns' property.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Wait Time</name><displayName>Max Wait Time</displayName><description>The maximum amount of time allowed for a running SQL select query , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><defaultValue>0 seconds</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Fetch Size</name><displayName>Fetch Size</displayName><description>The number of result rows to be fetched from the result set at a time. This is a hint to the database driver and may not be honored and/or exact. If the value specified is zero, then the hint is ignored. If using PostgreSQL, then 'Set Auto Commit' must be equal to 'false' to cause 'Fetch Size' to take effect.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Set Auto Commit</name><displayName>Set Auto Commit</displayName><description>Allows enabling or disabling the auto commit functionality of the DB connection. Default value is 'No value set'. 'No value set' will leave the db connection's auto commit mode unchanged. For some JDBC drivers such as PostgreSQL driver, it is required to disable the auto commit functionality to get the 'Fetch Size' setting to take effect. When auto commit is enabled, PostgreSQL driver ignores 'Fetch Size' setting and loads all rows of the result set to memory at once. This could lead for a large amount of memory usage when executing queries which fetch large data sets. More Details of this behaviour in PostgreSQL driver can be found in https://jdbc.postgresql.org//documentation/head/query.html.</description><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>qdbt-max-rows</name><displayName>Max Rows Per Flow File</displayName><description>The maximum number of result rows that will be included in a single FlowFile. This will allow you to break up very large result sets into multiple FlowFiles. If the value specified is zero, then all rows are returned in a single FlowFile.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>qdbt-output-batch-size</name><displayName>Output Batch Size</displayName><description>The number of output FlowFiles to queue before committing the process session. When set to zero, the session will be committed when all result set rows have been processed and the output FlowFiles are ready for transfer to the downstream relationship. For large result sets, this can cause a large burst of FlowFiles to be transferred at the end of processor execution. If this property is set, then when the specified number of FlowFiles are ready for transfer, then the session will be committed, thus releasing the FlowFiles to the downstream relationship. NOTE: The maxvalue.* and fragment.count attributes will not be set on FlowFiles when this property is set.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>qdbt-max-frags</name><displayName>Maximum Number of Fragments</displayName><description>The maximum number of fragments. If the value specified is zero, then all fragments are returned. This prevents OutOfMemoryError when this processor ingests huge table. NOTE: Setting this property can result in data loss, as the incoming results are not ordered, and fragments may end at arbitrary boundaries where rows are not included in the result set.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>qdbtr-normalize</name><displayName>Normalize Table/Column Names</displayName><description>Whether to change characters in column names when creating the output schema. For example, colons and periods will be changed to underscores.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dbf-user-logical-types</name><displayName>Use Avro Logical Types</displayName><description>Whether to use Avro Logical Types for DECIMAL/NUMBER, DATE, TIME and TIMESTAMP columns. If disabled, written as string. If enabled, Logical types are used and written as its underlying type, specifically, DECIMAL/NUMBER as logical 'decimal': written as bytes with additional precision and scale meta data, DATE as logical 'date-millis': written as int denoting days since Unix epoch (1970-01-01), TIME as logical 'time-millis': written as int denoting milliseconds since Unix epoch, and TIMESTAMP as logical 'timestamp-millis': written as long denoting milliseconds since Unix epoch. If a reader of written Avro records also knows these logical types, then these values can be deserialized with more context depending on reader implementation.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dbf-default-precision</name><displayName>Default Decimal Precision</displayName><description>When a DECIMAL/NUMBER value is written as a 'decimal' Avro logical type, a specific 'precision' denoting number of available digits is required. Generally, precision is defined by column data type definition or database engines default. However undefined precision (0) can be returned from some database engines. 'Default Decimal Precision' is used when writing those undefined precision numbers.</description><defaultValue>10</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dbf-default-scale</name><displayName>Default Decimal Scale</displayName><description>When a DECIMAL/NUMBER value is written as a 'decimal' Avro logical type, a specific 'scale' denoting number of available decimal digits is required. Generally, scale is defined by column data type definition or database engines default. However when undefined precision (0) is returned, scale can also be uncertain with some database engines. 'Default Decimal Scale' is used when writing those undefined numbers. If a value has more decimals than specified scale, then the value will be rounded-up, e.g. 1.53 becomes 2 with scale 0, and 1.5 with scale 1.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>initial.maxvalue.&lt;max_value_column&gt;</name><value>Initial maximum value for the specified column</value><description>Specifies an initial max value for max value column(s). Properties should be added in the format `initial.maxvalue.&lt;max_value_column&gt;`. This value is only used the first time the table is accessed (when a Maximum Value Column is specified).</description><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>success</name><description>Successfully created FlowFile from SQL query result set.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>tablename</name><description>Name of the table being queried</description></writesAttribute><writesAttribute><name>querydbtable.row.count</name><description>The number of rows selected by the query</description></writesAttribute><writesAttribute><name>fragment.identifier</name><description>If 'Max Rows Per Flow File' is set then all FlowFiles from the same query result set will have the same value for the fragment.identifier attribute. This can then be used to correlate the results.</description></writesAttribute><writesAttribute><name>fragment.count</name><description>If 'Max Rows Per Flow File' is set then this is the total number of  FlowFiles produced by a single ResultSet. This can be used in conjunction with the fragment.identifier attribute in order to know how many FlowFiles belonged to the same incoming ResultSet. If Output Batch Size is set, then this attribute will not be populated.</description></writesAttribute><writesAttribute><name>fragment.index</name><description>If 'Max Rows Per Flow File' is set then the position of this FlowFile in the list of outgoing FlowFiles that were all derived from the same result set FlowFile. This can be used in conjunction with the fragment.identifier attribute to know which FlowFiles originated from the same query result set and in what order  FlowFiles were produced</description></writesAttribute><writesAttribute><name>maxvalue.*</name><description>Each attribute contains the observed maximum value of a specified 'Maximum-value Column'. The suffix of the attribute is the name of the column. If Output Batch Size is set, then this attribute will not be populated.</description></writesAttribute><writesAttribute><name>mime.type</name><description>Sets the mime.type attribute to the MIME Type specified by the Record Writer.</description></writesAttribute><writesAttribute><name>record.count</name><description>The number of records output by the Record Writer.</description></writesAttribute></writesAttributes><triggerSerially>true</triggerSerially><primaryNodeOnly>true</primaryNodeOnly><stateful><description>After performing a query on the specified table, the maximum values for the specified column(s) will be retained for use in future executions of the query. This allows the Processor to fetch only those records that have max values greater than the retained values. This can be used for incremental fetching, fetching of newly added rows, etc. To clear the maximum values, clear the state of the processor per the State Management documentation</description><scopes><scope>CLUSTER</scope></scopes></stateful><inputRequirement>INPUT_FORBIDDEN</inputRequirement><useCases><useCase><description>Retrieve all rows from a database table.</description><notes></notes><keywords><keyword>jdbc</keyword><keyword>rdbms</keyword><keyword>cdc</keyword><keyword>database</keyword><keyword>table</keyword><keyword>stream</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>Configure the "Database Connection Pooling Service" to specify a Connection Pooling Service so that the Processor knows how to connect to the database.
Set the "Database Type" property to the type of database to query, or "Generic" if the database vendor is not listed.
Set the "Table Name" property to the name of the table to retrieve records from.
Configure the "Record Writer" to specify a Record Writer that is appropriate for the desired output format.
Set the "Maximum-value Columns" property to a comma-separated list of columns whose values can be used to determine which values are new. For example, this might be set to
    an `id` column that is a one-up number, or a `last_modified` column that is a timestamp of when the row was last modified.
Set the "Initial Load Strategy" property to "Start at Beginning".
Set the "Fetch Size" to a number that avoids loading too much data into memory on the NiFi side. For example, a value of `1000` will load up to 1,000 rows of data.
Set the "Max Rows Per Flow File" to a value that allows efficient processing, such as `1000` or `10000`.
Set the "Output Batch Size" property to a value greater than `0`. A smaller value, such as `1` or even `20` will result in lower latency but also slightly lower throughput.
    A larger value such as `1000` will result in higher throughput but also higher latency. It is not recommended to set the value larger than `1000` as it can cause significant
    memory utilization.
</configuration></useCase><useCase><description>Perform an incremental load of a single database table, fetching only new rows as they are added to the table.</description><notes></notes><keywords><keyword>incremental load</keyword><keyword>rdbms</keyword><keyword>jdbc</keyword><keyword>cdc</keyword><keyword>database</keyword><keyword>table</keyword><keyword>stream</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>Configure the "Database Connection Pooling Service" to specify a Connection Pooling Service so that the Processor knows how to connect to the database.
Set the "Database Type" property to the type of database to query, or "Generic" if the database vendor is not listed.
Set the "Table Name" property to the name of the table to retrieve records from.
Configure the "Record Writer" to specify a Record Writer that is appropriate for the desired output format.
Set the "Maximum-value Columns" property to a comma-separated list of columns whose values can be used to determine which values are new. For example, this might be set to
    an `id` column that is a one-up number, or a `last_modified` column that is a timestamp of when the row was last modified.
Set the "Initial Load Strategy" property to "Start at Current Maximum Values".
Set the "Fetch Size" to a number that avoids loading too much data into memory on the NiFi side. For example, a value of `1000` will load up to 1,000 rows of data.
Set the "Max Rows Per Flow File" to a value that allows efficient processing, such as `1000` or `10000`.
Set the "Output Batch Size" property to a value greater than `0`. A smaller value, such as `1` or even `20` will result in lower latency but also slightly lower throughput.
    A larger value such as `1000` will result in higher throughput but also higher latency. It is not recommended to set the value larger than `1000` as it can cause significant
    memory utilization.
</configuration></useCase></useCases><multiProcessorUseCases><multiProcessorUseCase><description>Perform an incremental load of multiple database tables, fetching only new rows as they are added to the tables.</description><notes></notes><keywords><keyword>incremental load</keyword><keyword>rdbms</keyword><keyword>jdbc</keyword><keyword>cdc</keyword><keyword>database</keyword><keyword>table</keyword><keyword>stream</keyword></keywords><processorConfigurations><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.ListDatabaseTables</processorClassName><configuration>Configure the "Database Connection Pooling Service" property to specify a Connection Pool that is applicable for interacting with your database.

Set the "Catalog" property to the name of the database Catalog;
set the "Schema Pattern" property to a Java Regular Expression that matches all database Schemas that should be included; and
set the "Table Name Pattern" property to a Java Regular Expression that matches the names of all tables that should be included.
In order to perform an incremental load of all tables, leave the Catalog, Schema Pattern, and Table Name Pattern unset.

Leave the RecordWriter property unset.

Connect the 'success' relationship to QueryDatabaseTableRecord.
</configuration></processorConfiguration><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.QueryDatabaseTableRecord</processorClassName><configuration>Configure the "Database Connection Pooling Service" to the same Connection Pool that was used in ListDatabaseTables.
Set the "Database Type" property to the type of database to query, or "Generic" if the database vendor is not listed.
Set the "Table Name" property to "${db.table.fullname}"
Configure the "Record Writer" to specify a Record Writer that is appropriate for the desired output format.
Set the "Maximum-value Columns" property to a comma-separated list of columns whose values can be used to determine which values are new. For example, this might be set to
    an `id` column that is a one-up number, or a `last_modified` column that is a timestamp of when the row was last modified.
Set the "Initial Load Strategy" property to "Start at Current Maximum Values".
Set the "Fetch Size" to a number that avoids loading too much data into memory on the NiFi side. For example, a value of `1000` will load up to 1,000 rows of data.
Set the "Max Rows Per Flow File" to a value that allows efficient processing, such as `1000` or `10000`.
Set the "Output Batch Size" property to a value greater than `0`. A smaller value, such as `1` or even `20` will result in lower latency but also slightly lower throughput.
    A larger value such as `1000` will result in higher throughput but also higher latency. It is not recommended to set the value larger than `1000` as it can cause significant
    memory utilization.
</configuration></processorConfiguration></processorConfigurations></multiProcessorUseCase></multiProcessorUseCases><seeAlso><see>org.apache.nifi.processors.standard.GenerateTableFetch</see><see>org.apache.nifi.processors.standard.ExecuteSQL</see></seeAlso><defaultSchedule><strategy>TIMER_DRIVEN</strategy><period>1 min</period><concurrentTasks>1</concurrentTasks></defaultSchedule></extension><extension><name>org.apache.nifi.processors.standard.QueryRecord</name><type>PROCESSOR</type><description>Evaluates one or more SQL queries against the contents of a FlowFile. The result of the SQL query then becomes the content of the output FlowFile. This can be used, for example, for field-specific filtering, transformation, and row-level filtering. Columns can be renamed, simple calculations and aggregations performed, etc. The Processor is configured with a Record Reader Controller Service and a Record Writer service so as to allow flexibility in incoming and outgoing data formats. The Processor must be configured with at least one user-defined property. The name of the Property is the Relationship to route data to, and the value of the Property is a SQL SELECT statement that is used to specify how input data should be transformed/filtered. The SQL statement must be valid ANSI SQL and is powered by Apache Calcite. If the transformation fails, the original FlowFile is routed to the 'failure' relationship. Otherwise, the data selected will be routed to the associated relationship. If the Record Writer chooses to inherit the schema from the Record, it is important to note that the schema that is inherited will be from the ResultSet, rather than the input Record. This allows a single instance of the QueryRecord processor to have multiple queries, each of which returns a different set of columns and aggregations. As a result, though, the schema that is derived will have no schema name, so it is important that the configured Record Writer not attempt to write the Schema Name as an attribute if inheriting the Schema from the Record. See the Processor Usage documentation for more information.</description><tags><tag>sql</tag><tag>query</tag><tag>calcite</tag><tag>route</tag><tag>record</tag><tag>transform</tag><tag>select</tag><tag>update</tag><tag>modify</tag><tag>etl</tag><tag>filter</tag><tag>record</tag><tag>csv</tag><tag>json</tag><tag>logs</tag><tag>text</tag><tag>avro</tag><tag>aggregate</tag></tags><properties><property><name>record-reader</name><displayName>Record Reader</displayName><description>Specifies the Controller Service to use for parsing incoming data and determining the data's schema</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>record-writer</name><displayName>Record Writer</displayName><description>Specifies the Controller Service to use for writing results to a FlowFile</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>include-zero-record-flowfiles</name><displayName>Include Zero Record FlowFiles</displayName><description>When running the SQL statement against an incoming FlowFile, if the result has no data, this property specifies whether or not a FlowFile will be sent to the corresponding relationship</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dbf-default-precision</name><displayName>Default Decimal Precision</displayName><description>When a DECIMAL/NUMBER value is written as a 'decimal' Avro logical type, a specific 'precision' denoting number of available digits is required. Generally, precision is defined by column data type definition or database engines default. However undefined precision (0) can be returned from some database engines. 'Default Decimal Precision' is used when writing those undefined precision numbers.</description><defaultValue>10</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dbf-default-scale</name><displayName>Default Decimal Scale</displayName><description>When a DECIMAL/NUMBER value is written as a 'decimal' Avro logical type, a specific 'scale' denoting number of available decimal digits is required. Generally, scale is defined by column data type definition or database engines default. However when undefined precision (0) is returned, scale can also be uncertain with some database engines. 'Default Decimal Scale' is used when writing those undefined numbers. If a value has more decimals than specified scale, then the value will be rounded-up, e.g. 1.53 becomes 2 with scale 0, and 1.5 with scale 1.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>The name of the relationship to route data to</name><value>A SQL SELECT statement that is used to determine what data should be routed to this relationship.</value><description>Each user-defined property specifies a SQL SELECT statement to run over the data, with the data that is selected being routed to the relationship whose name is the property name</description><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>failure</name><description>If a FlowFile fails processing for any reason (for example, the SQL statement contains columns not present in input data), the original FlowFile it will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>original</name><description>The original FlowFile is routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><dynamicRelationship><name>&lt;Property Name&gt;</name><description>Each user-defined property defines a new Relationship for this Processor.</description></dynamicRelationship><writesAttributes><writesAttribute><name>mime.type</name><description>Sets the mime.type attribute to the MIME Type specified by the Record Writer</description></writesAttribute><writesAttribute><name>record.count</name><description>The number of records selected by the query</description></writesAttribute><writesAttribute><name>QueryRecord.Route</name><description>The relation to which the FlowFile was routed</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><useCases><useCase><description>Filter out records based on the values of the records' fields</description><notes></notes><keywords><keyword>filter out</keyword><keyword>remove</keyword><keyword>drop</keyword><keyword>strip out</keyword><keyword>record field</keyword><keyword>sql</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>"Record Reader" should be set to a Record Reader that is appropriate for your data.
"Record Writer" should be set to a Record Writer that writes out data in the desired format.

One additional property should be added.
The name of the property should be a short description of the data to keep.
Its value is a SQL statement that selects all columns from a table named `FLOW_FILE` for relevant rows.
The WHERE clause selects the data to keep. I.e., it is the exact opposite of what we want to remove.
It is recommended to always quote column names using double-quotes in order to avoid conflicts with SQL keywords.
For example, to remove records where either the name is George OR the age is less than 18, we would add a   property named "adults not george" with a value that selects records where the name is not George AND the age is greater than or equal to 18.   So the value would be `SELECT * FROM FLOWFILE WHERE "name" &lt;&gt; 'George' AND "age" &gt;= 18`

Adding this property now gives us a new Relationship whose name is the same as the property name. So, the "adults not george" Relationship should be connected to the next Processor in our flow.
</configuration></useCase><useCase><description>Keep only specific records</description><notes></notes><keywords><keyword>keep</keyword><keyword>filter</keyword><keyword>retain</keyword><keyword>select</keyword><keyword>include</keyword><keyword>record</keyword><keyword>sql</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>"Record Reader" should be set to a Record Reader that is appropriate for your data.
"Record Writer" should be set to a Record Writer that writes out data in the desired format.

One additional property should be added.
The name of the property should be a short description of the data to keep.
Its value is a SQL statement that selects all columns from a table named `FLOW_FILE` for relevant rows.
The WHERE clause selects the data to keep.
It is recommended to always quote column names using double-quotes in order to avoid conflicts with SQL keywords.
For example, to keep only records where the person is an adult (aged 18 or older), add a property named "adults"   with a value that is a SQL statement that selects records where the age is at least 18.   So the value would be `SELECT * FROM FLOWFILE WHERE "age" &gt;= 18`

Adding this property now gives us a new Relationship whose name is the same as the property name. So, the "adults" Relationship should be connected to the next Processor in our flow.
</configuration></useCase><useCase><description>Keep only specific fields in a a Record, where the names of the fields to keep are known</description><notes></notes><keywords><keyword>keep</keyword><keyword>filter</keyword><keyword>retain</keyword><keyword>select</keyword><keyword>include</keyword><keyword>record</keyword><keyword>fields</keyword><keyword>sql</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>"Record Reader" should be set to a Record Reader that is appropriate for your data.
"Record Writer" should be set to a Record Writer that writes out data in the desired format.

One additional property should be added.
The name of the property should be a short description of the data to keep, such as `relevant fields`.
Its value is a SQL statement that selects the desired columns from a table named `FLOW_FILE` for relevant rows.
There is no WHERE clause.
It is recommended to always quote column names using double-quotes in order to avoid conflicts with SQL keywords.
For example, to keep only the `name`, `age`, and `address` fields, add a property named `relevant fields`   with a value of `SELECT "name", "age", "address" FROM FLOWFILE`

Adding this property now gives us a new Relationship whose name is the same as the property name. So, the `relevant fields` Relationship should be connected to the next Processor in our flow.
</configuration></useCase><useCase><description>Route record-oriented data for processing based on its contents</description><notes></notes><keywords><keyword>record</keyword><keyword>route</keyword><keyword>conditional processing</keyword><keyword>field</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>"Record Reader" should be set to a Record Reader that is appropriate for your data.
"Record Writer" should be set to a Record Writer that writes out data in the desired format.

For each route that you want to create, add a new property.
The name of the property should be a short description of the data that should be selected for the route.
Its value is a SQL statement that selects all columns from a table named `FLOW_FILE`. The WHERE clause selects the data that should be included in the route.
It is recommended to always quote column names using double-quotes in order to avoid conflicts with SQL keywords.

A new outbound relationship is created for each property that is added. The name of the relationship is the same as the property name.

For example, to route data based on whether or not it is a large transaction, we would add two properties:
`small transaction` would have a value such as `SELECT * FROM FLOWFILE WHERE transactionTotal &lt; 100`
`large transaction` would have a value of `SELECT * FROM FLOWFILE WHERE transactionTotal &gt;= 100`
</configuration></useCase></useCases></extension><extension><name>org.apache.nifi.processors.standard.RemoveRecordField</name><type>PROCESSOR</type><description>Modifies the contents of a FlowFile that contains Record-oriented data (i.e. data that can be read via a RecordReader and written by a RecordWriter) by removing selected fields. This Processor requires that at least one user-defined Property be added. The name of the property is ignored by the processor, but could be a meaningful identifier for the user. The value of the property should indicate a RecordPath that determines the field to be removed. The processor executes the removal in the order in which these properties are added to the processor. Set the "Record Writer" to "Inherit Record Schema" in order to use the updated Record Schema modified when removing Fields.</description><tags><tag>update</tag><tag>record</tag><tag>generic</tag><tag>schema</tag><tag>json</tag><tag>csv</tag><tag>avro</tag><tag>freeform</tag><tag>text</tag><tag>remove</tag><tag>delete</tag></tags><properties><property><name>Record Reader</name><displayName>Record Reader</displayName><description>Specifies the Controller Service to use for reading incoming data</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Record Writer</name><displayName>Record Writer</displayName><description>Specifies the Controller Service to use for writing out the records</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>A description of the field to remove</name><value>A RecordPath to the field to be removed.</value><description>Any field that matches the RecordPath set as the value will be removed.</description><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>failure</name><description>If a FlowFile cannot be transformed from the configured input format to the configured output format, the unchanged FlowFile will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>FlowFiles that are successfully transformed will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>record.error.message</name><description>This attribute provides on failure the error message encountered by the Reader or Writer.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><useCases><useCase><description>Remove one or more fields from a Record, where the names of the fields to remove are known.</description><notes></notes><keywords><keyword>record</keyword><keyword>field</keyword><keyword>drop</keyword><keyword>remove</keyword><keyword>delete</keyword><keyword>expunge</keyword><keyword>recordpath</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>Configure the Record Reader according to the incoming data format.
Configure the Record Writer according to the desired output format.

For each field that you want to remove, add a single new property to the Processor.
The name of the property can be anything but it's recommended to use a brief description of the field.
The value of the property is a RecordPath that matches the field to remove.

For example, to remove the `name` and `email` fields, add two Properties:
`name` = `/name`
`email` = `/email`
</configuration></useCase></useCases><seeAlso><see>org.apache.nifi.processors.standard.UpdateRecord</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.RenameRecordField</name><type>PROCESSOR</type><description>Renames one or more fields in each Record of a FlowFile. This Processor requires that at least one user-defined Property be added. The name of the Property should indicate a RecordPath that determines the field that should be updated. The value of the Property is the new name to assign to the Record Field that matches the RecordPath. The property value may use Expression Language to reference FlowFile attributes as well as the variables `field.name`, `field.value`, `field.type`, and `record.index`</description><tags><tag>update</tag><tag>record</tag><tag>rename</tag><tag>field</tag><tag>generic</tag><tag>schema</tag><tag>json</tag><tag>csv</tag><tag>avro</tag><tag>log</tag><tag>logs</tag></tags><properties><property><name>Record Reader</name><displayName>Record Reader</displayName><description>Specifies the Controller Service to use for reading incoming data</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Record Writer</name><displayName>Record Writer</displayName><description>Specifies the Controller Service to use for writing out the records</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>A RecordPath that identifies which field(s) to update</name><value>The new name to assign to the Record field</value><description>Allows users to specify a new name for each field that matches the RecordPath.</description><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>failure</name><description>If a FlowFile cannot be transformed from the configured input format to the configured output format, the unchanged FlowFile will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>FlowFiles that are successfully transformed will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>record.index</name><description>This attribute provides the current row index and is only available inside the literal value expression.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><useCases><useCase><description>Rename a field in each Record to a specific, known name.</description><notes></notes><keywords><keyword>rename</keyword><keyword>field</keyword><keyword>static</keyword><keyword>specific</keyword><keyword>name</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>Configure the 'Record Reader' according to the input format.
Configure the 'Record Writer' according to the desired output format.

Add a property to the Processor such that the name of the property is a RecordPath to identifies the field to rename. The value of the property is the new name of the property.

For example, to rename the `name` field to `full_name`, add a property with a name of `/name` and a value of `full_name`.

Many properties can be added following this pattern in order to rename multiple fields.
</configuration></useCase><useCase><description>Rename a field in each Record to a name that is derived from a FlowFile attribute.</description><notes></notes><keywords><keyword>rename</keyword><keyword>field</keyword><keyword>expression language</keyword><keyword>EL</keyword><keyword>flowfile</keyword><keyword>attribute</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>Configure the 'Record Reader' according to the input format.
Configure the 'Record Writer' according to the desired output format.

Add a property to the Processor such that the name of the property is a RecordPath to identifies the field to rename. The value of the property is an Expression Language expression that can be used to determine the new name of the field.

For example, to rename the `addr` field to whatever value is stored in the `preferred_address_name` attribute, add a property with a name of `/name` and a value of `${preferred_address_name}`.

Many properties can be added following this pattern in order to rename multiple fields.
</configuration></useCase><useCase><description>Rename a field in each Record to a new name that is derived from the current field name.</description><notes>This might be used, for example, to add a prefix or a suffix to some fields, or to transform the name of the field by making it uppercase.</notes><keywords><keyword>rename</keyword><keyword>field</keyword><keyword>expression language</keyword><keyword>EL</keyword><keyword>field.name</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>Configure the 'Record Reader' according to the input format.
Configure the 'Record Writer' according to the desired output format.

Add a property to the Processor such that the name of the property is a RecordPath to identifies the field to rename. The value of the property is an Expression Language expression that references the `field.name` property.

For example, to rename all fields with a prefix of `pre_`, we add a property named `/*` and a value of `pre_${field.name}`. If we would like this to happen recursively, to nested fields as well, we use a property name of `//*` with the value of `pre_${field.name}`.

To make all field names uppercase, we can add a property named `//*` with a value of `${field.name:toUpper()}`.

Many properties can be added following this pattern in order to rename multiple fields.
</configuration></useCase></useCases><seeAlso><see>org.apache.nifi.processors.standard.UpdateRecord</see><see>org.apache.nifi.processors.standard.RemoveRecordField</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.ReplaceText</name><type>PROCESSOR</type><description>Updates the content of a FlowFile by searching for some textual value in the FlowFile content (via Regular Expression/regex, or literal value) and replacing the section of the content that matches with some alternate value. It can also be used to append or prepend text to the contents of a FlowFile.</description><tags><tag>Text</tag><tag>Regular Expression</tag><tag>Update</tag><tag>Change</tag><tag>Replace</tag><tag>Modify</tag><tag>Regex</tag></tags><properties><property><name>Replacement Strategy</name><displayName>Replacement Strategy</displayName><description>The strategy for how and what to replace within the FlowFile's text content.</description><defaultValue>Regex Replace</defaultValue><allowableValues><allowableValue><displayName>Prepend</displayName><value>Prepend</value><description>Insert the Replacement Value at the beginning of the FlowFile or the beginning of each line (depending on the Evaluation Mode). For "Line-by-Line" Evaluation Mode, the value will be prepended to each line. Similarly, for "First-Line", "Last-Line", "Except-Last-Line" and "Except-First-Line" Evaluation Modes,the value will be prepended to header alone, footer alone, all lines except header and all lines except footer respectively. For "Entire Text" evaluation mode,the value will be prepended to the entire text.</description></allowableValue><allowableValue><displayName>Append</displayName><value>Append</value><description>Insert the Replacement Value at the end of the FlowFile or the end of each line (depending on the Evaluation Mode). For "Line-by-Line" Evaluation Mode, the value will be appended to each line. Similarly, for "First-Line", "Last-Line", "Except-Last-Line" and "Except-First-Line" Evaluation Modes,the value will be appended to header alone, footer alone, all lines except header and all lines except footer respectively. For "Entire Text" evaluation mode,the value will be appended to the entire text.</description></allowableValue><allowableValue><displayName>Surround</displayName><value>Surround</value><description>Prepends text before the start of the FlowFile (or the start of each line, depending on the configuration of the Evaluation Mode property) as well as appending text to the end of the FlowFile (or the end of each line, depending on the configuration of the Evaluation Mode property)</description></allowableValue><allowableValue><displayName>Regex Replace</displayName><value>Regex Replace</value><description>Interpret the Search Value as a Regular Expression and replace all matches with the Replacement Value. The Replacement Value may reference Capturing Groups used in the Search Value by using a dollar-sign followed by the Capturing Group number, such as $1 or $2. If the Search Value is set to .* then everything is replaced without even evaluating the Regular Expression.</description></allowableValue><allowableValue><displayName>Literal Replace</displayName><value>Literal Replace</value><description>Search for all instances of the Search Value and replace the matches with the Replacement Value.</description></allowableValue><allowableValue><displayName>Always Replace</displayName><value>Always Replace</value><description>Always replaces the entire line or the entire contents of the FlowFile (depending on the value of the &lt;Evaluation Mode&gt; property) and does not bother searching for any value. When this strategy is chosen, the &lt;Search Value&gt; property is ignored.</description></allowableValue><allowableValue><displayName>Substitute Variables</displayName><value>Substitute Variables</value><description>Substitute variable references (specified in ${var} form) using FlowFile attributes for looking up the replacement value by variable name. When this strategy is chosen, both the &lt;Search Value&gt; and &lt;Replacement Value&gt; properties are ignored.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Regular Expression</name><displayName>Search Value</displayName><description>The Search Value to search for in the FlowFile content. Only used for 'Literal Replace' and 'Regex Replace' matching strategies</description><defaultValue>(?s)(^.*$)</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Replacement Strategy</propertyName><propertyDisplayName>Replacement Strategy</propertyDisplayName><dependentValues><dependentValue>Literal Replace</dependentValue><dependentValue>Regex Replace</dependentValue></dependentValues></dependency></dependencies></property><property><name>Replacement Value</name><displayName>Replacement Value</displayName><description>The value to insert using the 'Replacement Strategy'. Using "Regex Replace" back-references to Regular Expression capturing groups are supported, but back-references that reference capturing groups that do not exist in the regular expression will be treated as literal value. Back References may also be referenced using the Expression Language, as '$1', '$2', etc. The single-tick marks MUST be included, as these variables are not "Standard" attribute names (attribute names must be quoted unless they contain only numbers, letters, and _).</description><defaultValue>$1</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Replacement Strategy</propertyName><propertyDisplayName>Replacement Strategy</propertyDisplayName><dependentValues><dependentValue>Always Replace</dependentValue><dependentValue>Append</dependentValue><dependentValue>Literal Replace</dependentValue><dependentValue>Prepend</dependentValue><dependentValue>Regex Replace</dependentValue></dependentValues></dependency></dependencies></property><property><name>Text to Prepend</name><displayName>Text to Prepend</displayName><description>The text to prepend to the start of the FlowFile, or each line, depending on the configured value of the Evaluation Mode property</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Replacement Strategy</propertyName><propertyDisplayName>Replacement Strategy</propertyDisplayName><dependentValues><dependentValue>Surround</dependentValue></dependentValues></dependency></dependencies></property><property><name>Text to Append</name><displayName>Text to Append</displayName><description>The text to append to the end of the FlowFile, or each line, depending on the configured value of the Evaluation Mode property</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Replacement Strategy</propertyName><propertyDisplayName>Replacement Strategy</propertyDisplayName><dependentValues><dependentValue>Surround</dependentValue></dependentValues></dependency></dependencies></property><property><name>Character Set</name><displayName>Character Set</displayName><description>The Character Set in which the file is encoded</description><defaultValue>UTF-8</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum Buffer Size</name><displayName>Maximum Buffer Size</displayName><description>Specifies the maximum amount of data to buffer (per file or per line, depending on the Evaluation Mode) in order to apply the replacement. If 'Entire Text' (in Evaluation Mode) is selected and the FlowFile is larger than this value, the FlowFile will be routed to 'failure'. In 'Line-by-Line' Mode, if a single line is larger than this value, the FlowFile will be routed to 'failure'. A default value of 1 MB is provided, primarily for 'Entire Text' mode. In 'Line-by-Line' Mode, a value such as 8 KB or 16 KB is suggested. This value is ignored if the &lt;Replacement Strategy&gt; property is set to one of: Append, Prepend, Always Replace</description><defaultValue>1 MB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Evaluation Mode</name><displayName>Evaluation Mode</displayName><description>Run the 'Replacement Strategy' against each line separately (Line-by-Line) or buffer the entire file into memory (Entire Text) and run against that.</description><defaultValue>Line-by-Line</defaultValue><allowableValues><allowableValue><displayName>Line-by-Line</displayName><value>Line-by-Line</value><description></description></allowableValue><allowableValue><displayName>Entire text</displayName><value>Entire text</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Line-by-Line Evaluation Mode</name><displayName>Line-by-Line Evaluation Mode</displayName><description>Run the 'Replacement Strategy' against each line separately (Line-by-Line) for all lines in the FlowFile, First Line (Header) alone, Last Line (Footer) alone, Except the First Line (Header) or Except the Last Line (Footer).</description><defaultValue>All</defaultValue><allowableValues><allowableValue><displayName>All</displayName><value>All</value><description></description></allowableValue><allowableValue><displayName>First-Line</displayName><value>First-Line</value><description></description></allowableValue><allowableValue><displayName>Last-Line</displayName><value>Last-Line</value><description></description></allowableValue><allowableValue><displayName>Except-First-Line</displayName><value>Except-First-Line</value><description></description></allowableValue><allowableValue><displayName>Except-Last-Line</displayName><value>Except-Last-Line</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>FlowFiles that could not be updated are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>FlowFiles that have been successfully processed are routed to this relationship. This includes both FlowFiles that had text replaced and those that did not.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><systemResourceConsiderations><systemResourceConsideration><resource>MEMORY</resource><description>An instance of this component can cause high usage of this system resource.  Multiple instances or high concurrency settings may result a degradation of performance.</description></systemResourceConsideration></systemResourceConsiderations><useCases><useCase><description>Append text to the end of every line in a FlowFile</description><notes></notes><keywords><keyword>raw text</keyword><keyword>append</keyword><keyword>line</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>"Evaluation Mode" = "Line-by-Line"
"Replacement Strategy" = "Append"

"Replacement Value" is set to whatever text should be appended to the line.
For example, to insert the text `&lt;fin&gt;` at the end of every line, we would set "Replacement Value" to `&lt;fin&gt;`.
We can also use Expression Language. So to insert the filename at the end of every line, we set "Replacement Value" to `${filename}`
</configuration></useCase><useCase><description>Prepend text to the beginning of every line in a FlowFile</description><notes></notes><keywords><keyword>raw text</keyword><keyword>prepend</keyword><keyword>line</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>"Evaluation Mode" = "Line-by-Line"
"Replacement Strategy" = "Prepend"

"Replacement Value" is set to whatever text should be prepended to the line.
For example, to insert the text `&lt;start&gt;` at the beginning of every line, we would set "Replacement Value" to `&lt;start&gt;`.
We can also use Expression Language. So to insert the filename at the beginning of every line, we set "Replacement Value" to `${filename}`
</configuration></useCase><useCase><description>Replace every occurrence of a literal string in the FlowFile with a different value</description><notes></notes><keywords><keyword>replace</keyword><keyword>string</keyword><keyword>text</keyword><keyword>literal</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>"Evaluation Mode" = "Line-by-Line"
"Replacement Strategy" = "Literal Replace"
"Search Value" is set to whatever text is in the FlowFile that needs to be replaced.
"Replacement Value" is set to the text that should replace the current text.

For example, to replace the word "spider" with "arachnid" we set "Search Value" to `spider` and set "Replacement Value" to `arachnid`.
</configuration></useCase><useCase><description>Transform every occurrence of a literal string in a FlowFile</description><notes></notes><keywords><keyword>replace</keyword><keyword>transform</keyword><keyword>raw text</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>"Evaluation Mode" = "Line-by-Line"
"Replacement Strategy" = "Regex Replace"
"Search Value" is set to a regular expression that matches the text that should be transformed in a capturing group.
"Replacement Value" is set to a NiFi Expression Language expression that references `$1` (in quotes to escape the reference name).

For example, if we wanted to lowercase any occurrence of WOLF, TIGER, or LION, we would use a "Search Value" of `(WOLF|TIGER|LION)` and a "Replacement Value" of `${'$1':toLower()}`.
If we want to replace any identifier with a hash of that identifier, we might use a "Search Value" of `identifier: (.*)` and a "Replacement Value" of `identifier: ${'$1':hash('sha256')}`
</configuration></useCase><useCase><description>Completely replace the contents of a FlowFile to a specific text</description><notes></notes><keywords><keyword>replace</keyword><keyword>raw text</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>"Evaluation Mode" = "Entire text"
"Replacement Strategy" = "Always Replace"

"Replacement Value" is set to the new text that should be written to the FlowFile. This text might include NiFi Expression Language to reference one or more attributes.
</configuration></useCase></useCases></extension><extension><name>org.apache.nifi.processors.standard.ReplaceTextWithMapping</name><type>PROCESSOR</type><description>Updates the content of a FlowFile by evaluating a Regular Expression against it and replacing the section of the content that matches the Regular Expression with some alternate value provided in a mapping file.</description><tags><tag>Text</tag><tag>Regular Expression</tag><tag>Update</tag><tag>Change</tag><tag>Replace</tag><tag>Modify</tag><tag>Regex</tag><tag>Mapping</tag></tags><properties><property><name>Regular Expression</name><displayName>Regular Expression</displayName><description>The Regular Expression to search for in the FlowFile content</description><defaultValue>\S+</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Matching Group</name><displayName>Matching Group</displayName><description>The number of the matching group of the provided regex to replace with the corresponding value from the mapping file (if it exists).</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Mapping File</name><displayName>Mapping File</displayName><description>The name of the file (including the full path) containing the Mappings.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType></resourceTypes></resourceDefinition></property><property><name>Mapping File Refresh Interval</name><displayName>Mapping File Refresh Interval</displayName><description>The polling interval to check for updates to the mapping file. The default is 60s.</description><defaultValue>60s</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Character Set</name><displayName>Character Set</displayName><description>The Character Set in which the file is encoded</description><defaultValue>UTF-8</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum Buffer Size</name><displayName>Maximum Buffer Size</displayName><description>Specifies the maximum amount of data to buffer (per file) in order to apply the regular expressions. If a FlowFile is larger than this value, the FlowFile will be routed to 'failure'</description><defaultValue>1 MB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>FlowFiles that could not be updated are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>FlowFiles that have been successfully updated are routed to this relationship, as well as FlowFiles whose content does not match the given Regular Expression</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.RetryFlowFile</name><type>PROCESSOR</type><description>FlowFiles passed to this Processor have a 'Retry Attribute' value checked against a configured 'Maximum Retries' value. If the current attribute value is below the configured maximum, the FlowFile is passed to a retry relationship. The FlowFile may or may not be penalized in that condition. If the FlowFile's attribute value exceeds the configured maximum, the FlowFile will be passed to a 'retries_exceeded' relationship. WARNING: If the incoming FlowFile has a non-numeric value in the configured 'Retry Attribute' attribute, it will be reset to '1'. You may choose to fail the FlowFile instead of performing the reset. Additional dynamic properties can be defined for any attributes you wish to add to the FlowFiles transferred to 'retries_exceeded'. These attributes support attribute expression language.</description><tags><tag>Retry</tag><tag>FlowFile</tag></tags><properties><property><name>retry-attribute</name><displayName>Retry Attribute</displayName><description>The name of the attribute that contains the current retry count for the FlowFile. WARNING: If the name matches an attribute already on the FlowFile that does not contain a numerical value, the processor will either overwrite that attribute with '1' or fail based on configuration.</description><defaultValue>flowfile.retries</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>maximum-retries</name><displayName>Maximum Retries</displayName><description>The maximum number of times a FlowFile can be retried before being passed to the 'retries_exceeded' relationship</description><defaultValue>3</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>penalize-retries</name><displayName>Penalize Retries</displayName><description>If set to 'true', this Processor will penalize input FlowFiles before passing them to the 'retry' relationship. This does not apply to the 'retries_exceeded' relationship.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Fail on Non-numerical Overwrite</name><displayName>Fail on Non-numerical Overwrite</displayName><description>If the FlowFile already has the attribute defined in 'Retry Attribute' that is *not* a number, fail the FlowFile instead of resetting that value to '1'</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>reuse-mode</name><displayName>Reuse Mode</displayName><description>Defines how the Processor behaves if the retry FlowFile has a different retry UUID than the instance that received the FlowFile. This generally means that the attribute was not reset after being successfully retried by a previous instance of this processor.</description><defaultValue>fail</defaultValue><allowableValues><allowableValue><displayName>Fail on Reuse</displayName><value>fail</value><description>If the RetryFlowFile's UUID does not match the FlowFile's retry UUID, fail the FlowFile regardless of current retry count</description></allowableValue><allowableValue><displayName>Warn on Reuse</displayName><value>warn</value><description>If the RetryFlowFile's UUID does not match the FlowFile's retry UUID, log a warning message before resetting the retry attribute and UUID for this instance</description></allowableValue><allowableValue><displayName>Reset Reuse</displayName><value>reset</value><description>If the RetryFlowFile's UUID does not match the FlowFile's retry UUID, log a debug message before resetting the retry attribute and UUID for this instance</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>Exceeded FlowFile Attribute Key</name><value>The value of the attribute added to the FlowFile</value><description>One or more dynamic properties can be used to add attributes to FlowFiles passed to the 'retries_exceeded' relationship</description><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>failure</name><description>The processor is configured such that a non-numerical value on 'Retry Attribute' results in a failure instead of resetting that value to '1'. This will immediately terminate the limited feedback loop. Might also include when 'Maximum Retries' contains attribute expression language that does not resolve to an Integer.</description><autoTerminated>true</autoTerminated></relationship><relationship><name>retries_exceeded</name><description>Input FlowFile has exceeded the configured maximum retry count, do not pass this relationship back to the input Processor to terminate the limited feedback loop.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>retry</name><description>Input FlowFile has not exceeded the configured maximum retry count, pass this relationship back to the input Processor to create a limited feedback loop.</description><autoTerminated>false</autoTerminated></relationship></relationships><readsAttributes><readsAttribute><name>Retry Attribute</name><description>Will read the attribute or attribute expression language result as defined in 'Retry Attribute'</description></readsAttribute></readsAttributes><writesAttributes><writesAttribute><name>Retry Attribute</name><description>User defined retry attribute is updated with the current retry count</description></writesAttribute><writesAttribute><name>Retry Attribute .uuid</name><description>User defined retry attribute with .uuid that determines what processor retried the FlowFile last</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.RouteOnAttribute</name><type>PROCESSOR</type><description>Routes FlowFiles based on their Attributes using the Attribute Expression Language</description><tags><tag>attributes</tag><tag>routing</tag><tag>Attribute Expression Language</tag><tag>regexp</tag><tag>regex</tag><tag>Regular Expression</tag><tag>Expression Language</tag><tag>find</tag><tag>text</tag><tag>string</tag><tag>search</tag><tag>filter</tag><tag>detect</tag></tags><properties><property><name>Routing Strategy</name><displayName>Routing Strategy</displayName><description>Specifies how to determine which relationship to use when evaluating the Expression Language</description><defaultValue>Route to Property name</defaultValue><allowableValues><allowableValue><displayName>Route to Property name</displayName><value>Route to Property name</value><description>A copy of the FlowFile will be routed to each relationship whose corresponding expression evaluates to 'true'</description></allowableValue><allowableValue><displayName>Route to 'matched' if all match</displayName><value>Route to 'match' if all match</value><description>Requires that all user-defined expressions evaluate to 'true' for the FlowFile to be considered a match</description></allowableValue><allowableValue><displayName>Route to 'matched' if any matches</displayName><value>Route to 'match' if any matches</value><description>Requires that at least one user-defined expression evaluate to 'true' for the FlowFile to be considered a match</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>Relationship Name</name><value>Expression Language expression that returns a boolean value indicating whether or not the FlowFile should be routed to this Relationship</value><description>Routes FlowFiles whose attributes match the Expression Language specified in the Dynamic Property Value to the Relationship specified in the Dynamic Property Key</description><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>unmatched</name><description>FlowFiles that do not match any user-define expression will be routed here</description><autoTerminated>false</autoTerminated></relationship></relationships><dynamicRelationship><name>Name from Dynamic Property</name><description>FlowFiles that match the Dynamic Property's Attribute Expression Language</description></dynamicRelationship><writesAttributes><writesAttribute><name>RouteOnAttribute.Route</name><description>The relation to which the FlowFile was routed</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><useCases><useCase><description>Route data to one or more relationships based on its attributes using the NiFi Expression Language.</description><notes></notes><keywords><keyword>attributes</keyword><keyword>routing</keyword><keyword>expression language</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>Set the "Routing Strategy" property to "Route to Property name".
For each route that a FlowFile might be routed to, add a new property. The name of the property should describe the route.
The value of the property is an Attribute Expression Language expression that returns a boolean value indicating whether or not a given FlowFile will be routed to the associated relationship.

For example, we might route data based on its file extension using the following properties:
    - "Routing Strategy" = "Route to Property Name"
    - "jpg" = "${filename:endsWith('.jpg')}"
    - "png" = "${filename:endsWith('.png')}"
    - "pdf" = "${filename:endsWith('.pdf')}"

The Processor will now have 3 relationships: `jpg`, `png`, and `pdf`. Each of these should be connected to the appropriate downstream processor.
</configuration></useCase><useCase><description>Keep data only if its attributes meet some criteria, such as its filename ends with .txt.</description><notes></notes><keywords><keyword>keep</keyword><keyword>filter</keyword><keyword>remove</keyword><keyword>delete</keyword><keyword>expression language</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>Add a new property for each condition that must be satisfied in order to keep the data.
If the data should be kept in the case that any of the provided conditions is met, set the "Routing Strategy" property to "Route to 'matched' if any matches".
If all conditions must be met in order to keep the data, set the "Routing Strategy" property  to "Route to 'matched' if all match".

For example, to keep files whose filename ends with .txt and have a file size of at least 1000 bytes, we will use the following properties:
    - "ends_with_txt" = "${filename:endsWith('.txt')}"
    - "large_enough" = "${fileSize:ge(1000)}
    - "Routing Strategy" = "Route to 'matched' if all match"

Auto-terminate the 'unmatched' relationship.
Connect the 'matched' relationship to the next processor in the flow.
</configuration></useCase><useCase><description>Discard or drop a file based on attributes, such as filename.</description><notes></notes><keywords><keyword>discard</keyword><keyword>drop</keyword><keyword>filter</keyword><keyword>remove</keyword><keyword>delete</keyword><keyword>expression language</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>Add a new property for each condition that must be satisfied in order to drop the data.
If the data should be dropped in the case that any of the provided conditions is met, set the "Routing Strategy" property to "Route to 'matched' if any matches".
If all conditions must be met in order to drop the data, set the "Routing Strategy" property  to "Route to 'matched' if all match".

Here are a couple of examples for configuring the properties:
    Example 1 Use Case: Data should be dropped if its "uuid" attribute has an 'a' in it or ends with '0'.
      Here, we will use the following properties:
        - "has_a" = "${uuid:contains('a')}"
        - "ends_with_0" = "${uuid:endsWith('0')}
        - "Routing Strategy" = "Route to 'matched' if any matches"
    Example 2 Use Case: Data should be dropped if its 'uuid' attribute has an 'a' AND it ends with a '1'.
      Here, we will use the following properties:
        - "has_a" = "${uuid:contains('a')}"
        - "ends_with_1" = "${uuid:endsWith('1')}
        - "Routing Strategy" = "Route to 'matched' if all match"

Auto-terminate the 'matched' relationship.
Connect the 'unmatched' relationship to the next processor in the flow.
</configuration></useCase></useCases><multiProcessorUseCases><multiProcessorUseCase><description>Route record-oriented data based on whether or not the record's values meet some criteria</description><notes></notes><keywords><keyword>record</keyword><keyword>route</keyword><keyword>content</keyword><keyword>data</keyword></keywords><processorConfigurations><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.PartitionRecord</processorClassName><configuration>Choose a RecordReader that is appropriate based on the format of the incoming data.
Choose a RecordWriter that writes the data in the desired output format.

Add a single additional property. The name of the property should describe the criteria to route on. The property's value should be a RecordPath that returns `true` if the Record meets the criteria or `false` otherwise. This adds a new attribute to the FlowFile whose name is equal to the property name.

Connect the 'success' Relationship to RouteOnAttribute.
</configuration></processorConfiguration><processorConfiguration><processorClassName>org.apache.nifi.processors.standard.RouteOnAttribute</processorClassName><configuration>Set "Routing Strategy" to "Route to Property name"

Add two additional properties. For the first one, the name of the property should describe data that matches the criteria. The value is an Expression Language expression that checks if the attribute added by the PartitionRecord processor has a value of `true`. For example, `${criteria:equals('true')}`.
The second property should have a name that describes data that does not match the criteria. The value is an Expression Language that evaluates to the opposite of the first property value. For example, `${criteria:equals('true'):not()}`.

Connect each of the newly created Relationships to the appropriate downstream processors.
</configuration></processorConfiguration></processorConfigurations></multiProcessorUseCase></multiProcessorUseCases></extension><extension><name>org.apache.nifi.processors.standard.RouteOnContent</name><type>PROCESSOR</type><description>Applies Regular Expressions to the content of a FlowFile and routes a copy of the FlowFile to each destination whose Regular Expression matches. Regular Expressions are added as User-Defined Properties where the name of the property is the name of the relationship and the value is a Regular Expression to match against the FlowFile content. User-Defined properties do support the Attribute Expression Language, but the results are interpreted as literal values, not Regular Expressions</description><tags><tag>route</tag><tag>content</tag><tag>regex</tag><tag>regular expression</tag><tag>regexp</tag><tag>find</tag><tag>text</tag><tag>string</tag><tag>search</tag><tag>filter</tag><tag>detect</tag></tags><properties><property><name>Match Requirement</name><displayName>Match Requirement</displayName><description>Specifies whether the entire content of the file must match the regular expression exactly, or if any part of the file (up to Content Buffer Size) can contain the regular expression in order to be considered a match</description><defaultValue>content must match exactly</defaultValue><allowableValues><allowableValue><displayName>content must match exactly</displayName><value>content must match exactly</value><description></description></allowableValue><allowableValue><displayName>content must contain match</displayName><value>content must contain match</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Character Set</name><displayName>Character Set</displayName><description>The Character Set in which the file is encoded</description><defaultValue>UTF-8</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Content Buffer Size</name><displayName>Content Buffer Size</displayName><description>Specifies the maximum amount of data to buffer in order to apply the regular expressions. If the size of the FlowFile exceeds this value, any amount of this value will be ignored</description><defaultValue>1 MB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>Relationship Name</name><value>A Regular Expression</value><description>Routes FlowFiles whose content matches the regular expression defined by Dynamic Property's value to the Relationship defined by the Dynamic Property's key</description><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>unmatched</name><description>FlowFiles that do not match any of the user-supplied regular expressions will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><dynamicRelationship><name>Name from Dynamic Property</name><description>FlowFiles that match the Dynamic Property's Regular Expression</description></dynamicRelationship><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.RouteText</name><type>PROCESSOR</type><description>Routes textual data based on a set of user-defined rules. Each line in an incoming FlowFile is compared against the values specified by user-defined Properties. The mechanism by which the text is compared to these user-defined properties is defined by the 'Matching Strategy'. The data is then routed according to these rules, routing each line of the text individually.</description><tags><tag>attributes</tag><tag>routing</tag><tag>text</tag><tag>regexp</tag><tag>regex</tag><tag>Regular Expression</tag><tag>Expression Language</tag><tag>csv</tag><tag>filter</tag><tag>logs</tag><tag>delimited</tag><tag>find</tag><tag>string</tag><tag>search</tag><tag>filter</tag><tag>detect</tag></tags><properties><property><name>Routing Strategy</name><displayName>Routing Strategy</displayName><description>Specifies how to determine which Relationship(s) to use when evaluating the lines of incoming text against the 'Matching Strategy' and user-defined properties.</description><defaultValue>Route to each matching Property Name</defaultValue><allowableValues><allowableValue><displayName>Route to each matching Property Name</displayName><value>Route to each matching Property Name</value><description>Lines will be routed to each relationship whose corresponding expression evaluates to 'true'</description></allowableValue><allowableValue><displayName>Route to 'matched' if line matches all conditions</displayName><value>Route to 'matched' if line matches all conditions</value><description>Requires that all user-defined expressions evaluate to 'true' for the line to be considered a match</description></allowableValue><allowableValue><displayName>Route to 'matched' if lines matches any condition</displayName><value>Route to 'matched' if lines matches any condition</value><description>Requires that at least one user-defined expression evaluate to 'true' for the line to be considered a match</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Matching Strategy</name><displayName>Matching Strategy</displayName><description>Specifies how to evaluate each line of incoming text against the user-defined properties.</description><allowableValues><allowableValue><displayName>Satisfies Expression</displayName><value>Satisfies Expression</value><description>Match lines based on whether or not the the text satisfies the given Expression Language expression. I.e., the line will match if the property value, evaluated as an Expression, returns true. The expression is able to reference FlowFile Attributes, as well as the variables 'line' (which is the text of the line to evaluate) and 'lineNo' (which is the line number being evaluated. This will be 1 for the first line, 2 for the second and so on).</description></allowableValue><allowableValue><displayName>Starts With</displayName><value>Starts With</value><description>Match lines based on whether the line starts with the property value</description></allowableValue><allowableValue><displayName>Ends With</displayName><value>Ends With</value><description>Match lines based on whether the line ends with the property value</description></allowableValue><allowableValue><displayName>Contains</displayName><value>Contains</value><description>Match lines based on whether the line contains the property value</description></allowableValue><allowableValue><displayName>Equals</displayName><value>Equals</value><description>Match lines based on whether the line equals the property value</description></allowableValue><allowableValue><displayName>Matches Regular Expression</displayName><value>Matches Regular Expression</value><description>Match lines based on whether the line exactly matches the Regular Expression that is provided as the Property value</description></allowableValue><allowableValue><displayName>Contains Regular Expression</displayName><value>Contains Regular Expression</value><description>Match lines based on whether the line contains some text that matches the Regular Expression that is provided as the Property value</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Character Set</name><displayName>Character Set</displayName><description>The Character Set in which the incoming text is encoded</description><defaultValue>UTF-8</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Ignore Leading/Trailing Whitespace</name><displayName>Ignore Leading/Trailing Whitespace</displayName><description>Indicates whether or not the whitespace at the beginning and end of the lines should be ignored when evaluating the line.</description><defaultValue>true</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Ignore Case</name><displayName>Ignore Case</displayName><description>If true, capitalization will not be taken into account when comparing values. E.g., matching against 'HELLO' or 'hello' will have the same result. This property is ignored if the 'Matching Strategy' is set to 'Satisfies Expression'.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Grouping Regular Expression</name><displayName>Grouping Regular Expression</displayName><description>Specifies a Regular Expression to evaluate against each line to determine which Group the line should be placed in. The Regular Expression must have at least one Capturing Group that defines the line's Group. If multiple Capturing Groups exist in the Regular Expression, the values from all Capturing Groups will be concatenated together. Two lines will not be placed into the same FlowFile unless they both have the same value for the Group (or neither line matches the Regular Expression). For example, to group together all lines in a CSV File by the first column, we can set this value to "(.*?),.*". Two lines that have the same Group but different Relationships will never be placed into the same FlowFile.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>Relationship Name</name><value>value to match against</value><description>Routes data that matches the value specified in the Dynamic Property Value to the Relationship specified in the Dynamic Property Key.</description><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>original</name><description>The original input file will be routed to this destination when the lines have been successfully routed to 1 or more relationships</description><autoTerminated>false</autoTerminated></relationship><relationship><name>unmatched</name><description>Data that does not satisfy the required user-defined rules will be routed to this Relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><dynamicRelationship><name>Name from Dynamic Property</name><description>FlowFiles that match the Dynamic Property's value</description></dynamicRelationship><writesAttributes><writesAttribute><name>RouteText.Route</name><description>The name of the relationship to which the FlowFile was routed.</description></writesAttribute><writesAttribute><name>RouteText.Group</name><description>The value captured by all capturing groups in the 'Grouping Regular Expression' property. If this property is not set or contains no capturing groups, this attribute will not be added.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><useCases><useCase><description>Drop blank or empty lines from the FlowFile's content.</description><notes></notes><keywords><keyword>filter</keyword><keyword>drop</keyword><keyword>empty</keyword><keyword>blank</keyword><keyword>remove</keyword><keyword>delete</keyword><keyword>strip out</keyword><keyword>lines</keyword><keyword>text</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>"Routing Strategy" = "Route to each matching Property Name"
"Matching Strategy" = "Matches Regular Expression"
"Empty Line" = "^$"

Auto-terminate the "Empty Line" relationship.
Connect the "unmatched" relationship to the next processor in your flow.
</configuration></useCase><useCase><description>Remove specific lines of text from a file, such as those containing a specific word or having a line length over some threshold.</description><notes></notes><keywords><keyword>filter</keyword><keyword>drop</keyword><keyword>empty</keyword><keyword>blank</keyword><keyword>remove</keyword><keyword>delete</keyword><keyword>strip out</keyword><keyword>lines</keyword><keyword>text</keyword><keyword>expression language</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>"Routing Strategy" = "Route to each matching Property Name"
"Matching Strategy" = "Satisfies Expression"

An additional property should be added named "Filter Out." The value should be a NiFi Expression Language Expression that can refer to two variables (in addition to FlowFile attributes): `line`, which is the line of text being evaluated; and `lineNo`, which is the line number in the file (starting with 1). The Expression should return `true` for any line that should be dropped.

For example, to remove any line that starts with a # symbol, we can set "Filter Out" to `${line:startsWith("#")}`.
We could also remove the first 2 lines of text by setting "Filter Out" to `${lineNo:le(2)}`. Note that we use the `le` function because we want lines numbers less than or equal to `2`, since the line index is 1-based.

Auto-terminate the "Filter Out" relationship.
Connect the "unmatched" relationship to the next processor in your flow.
</configuration></useCase></useCases></extension><extension><name>org.apache.nifi.processors.standard.SampleRecord</name><type>PROCESSOR</type><description>Samples the records of a FlowFile based on a specified sampling strategy (such as Reservoir Sampling). The resulting FlowFile may be of a fixed number of records (in the case of reservoir-based algorithms) or some subset of the total number of records (in the case of probabilistic sampling), or a deterministic number of records (in the case of interval sampling).</description><tags><tag>record</tag><tag>sample</tag><tag>reservoir</tag><tag>range</tag><tag>interval</tag></tags><properties><property><name>record-reader</name><displayName>Record Reader</displayName><description>Specifies the Controller Service to use for parsing incoming data and determining the data's schema</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>record-writer</name><displayName>Record Writer</displayName><description>Specifies the Controller Service to use for writing results to a FlowFile</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>sample-record-sampling-strategy</name><displayName>Sampling Strategy</displayName><description>Specifies which method to use for sampling records from the incoming FlowFile</description><defaultValue>reservoir</defaultValue><allowableValues><allowableValue><displayName>Interval Sampling</displayName><value>interval</value><description>Selects every Nth record where N is the value of the 'Interval Value' property</description></allowableValue><allowableValue><displayName>Range Sampling</displayName><value>range</value><description>Creates a sample of records based on the index (i.e. record number) of the records using the specified range. An example is '3,6-8,20-' which includes the third record, the sixth, seventh and eighth record, and all records from the twentieth record on. Commas separate intervals that don't overlap, and an interval can be between two numbers (i.e. 6-8) or up to a given number (i.e. -5), or from a number to the number of the last record (i.e. 20-).</description></allowableValue><allowableValue><displayName>Probabilistic Sampling</displayName><value>probabilistic</value><description>Selects each record with probability P where P is the value of the 'Selection Probability' property</description></allowableValue><allowableValue><displayName>Reservoir Sampling</displayName><value>reservoir</value><description>Creates a sample of K records where each record has equal probability of being included, where K is the value of the 'Reservoir Size' property. Note that if the value is very large it may cause memory issues as the reservoir is kept in-memory.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>sample-record-interval</name><displayName>Sampling Interval</displayName><description>Specifies the number of records to skip before writing a record to the outgoing FlowFile. This property is only used if Sampling Strategy is set to Interval Sampling. A value of zero (0) will cause no records to be included in theoutgoing FlowFile, a value of one (1) will cause all records to be included, and a value of two (2) will cause half the records to be included, and so on.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>sample-record-sampling-strategy</propertyName><propertyDisplayName>Sampling Strategy</propertyDisplayName><dependentValues><dependentValue>interval</dependentValue></dependentValues></dependency></dependencies></property><property><name>sample-record-range</name><displayName>Sampling Range</displayName><description>Specifies the range of records to include in the sample, from 1 to the total number of records. An example is '3,6-8,20-' which includes the third record, the sixth, seventh and eighth records, and all records from the twentieth record on. Commas separate intervals that don't overlap, and an interval can be between two numbers (i.e. 6-8) or up to a given number (i.e. -5), or from a number to the number of the last record (i.e. 20-). If this property is unset, all records will be included.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>sample-record-sampling-strategy</propertyName><propertyDisplayName>Sampling Strategy</propertyDisplayName><dependentValues><dependentValue>range</dependentValue></dependentValues></dependency></dependencies></property><property><name>sample-record-probability</name><displayName>Sampling Probability</displayName><description>Specifies the probability (as a percent from 0-100) of a record being included in the outgoing FlowFile. This property is only used if Sampling Strategy is set to Probabilistic Sampling. A value of zero (0) will cause no records to be included in theoutgoing FlowFile, and a value of 100 will cause all records to be included in the outgoing FlowFile..</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>sample-record-sampling-strategy</propertyName><propertyDisplayName>Sampling Strategy</propertyDisplayName><dependentValues><dependentValue>probabilistic</dependentValue></dependentValues></dependency></dependencies></property><property><name>sample-record-reservoir</name><displayName>Reservoir Size</displayName><description>Specifies the number of records to write to the outgoing FlowFile. This property is only used if Sampling Strategy is set to reservoir-based strategies such as Reservoir Sampling.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>sample-record-sampling-strategy</propertyName><propertyDisplayName>Sampling Strategy</propertyDisplayName><dependentValues><dependentValue>reservoir</dependentValue></dependentValues></dependency></dependencies></property><property><name>sample-record-random-seed</name><displayName>Random Seed</displayName><description>Specifies a particular number to use as the seed for the random number generator (used by probabilistic strategies). Setting this property will ensure the same records are selected even when using probabilistic strategies.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>sample-record-sampling-strategy</propertyName><propertyDisplayName>Sampling Strategy</propertyDisplayName><dependentValues><dependentValue>probabilistic</dependentValue><dependentValue>reservoir</dependentValue></dependentValues></dependency></dependencies></property></properties><relationships><relationship><name>failure</name><description>If a FlowFile fails processing for any reason (for example, any record is not valid), the original FlowFile will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>original</name><description>The original FlowFile is routed to this relationship if sampling is successful</description><autoTerminated>true</autoTerminated></relationship><relationship><name>success</name><description>The FlowFile is routed to this relationship if the sampling completed successfully</description><autoTerminated>true</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>mime.type</name><description>The MIME type indicated by the record writer</description></writesAttribute><writesAttribute><name>record.count</name><description>The number of records in the resulting flow file</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><systemResourceConsiderations><systemResourceConsideration><resource>MEMORY</resource><description>An instance of this component can cause high usage of this system resource.  Multiple instances or high concurrency settings may result a degradation of performance.</description></systemResourceConsideration></systemResourceConsiderations></extension><extension><name>org.apache.nifi.processors.standard.ScanAttribute</name><type>PROCESSOR</type><description>Scans the specified attributes of FlowFiles, checking to see if any of their values are present within the specified dictionary of terms</description><tags><tag>scan</tag><tag>attributes</tag><tag>search</tag><tag>lookup</tag><tag>find</tag><tag>text</tag></tags><properties><property><name>Dictionary File</name><displayName>Dictionary File</displayName><description>A new-line-delimited text file that includes the terms that should trigger a match. Empty lines are ignored.  The contents of the text file are loaded into memory when the processor is scheduled and reloaded when the contents are modified.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType></resourceTypes></resourceDefinition></property><property><name>Attribute Pattern</name><displayName>Attribute Pattern</displayName><description>Regular Expression that specifies the names of attributes whose values will be matched against the terms in the dictionary</description><defaultValue>.*</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Match Criteria</name><displayName>Match Criteria</displayName><description>If set to All Must Match, then FlowFiles will be routed to 'matched' only if all specified attributes' values are found in the dictionary. If set to At Least 1 Must Match, FlowFiles will be routed to 'matched' if any attribute specified is found in the dictionary</description><defaultValue>At Least 1 Must Match</defaultValue><allowableValues><allowableValue><displayName>At Least 1 Must Match</displayName><value>At Least 1 Must Match</value><description></description></allowableValue><allowableValue><displayName>All Must Match</displayName><value>All Must Match</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Dictionary Filter Pattern</name><displayName>Dictionary Filter Pattern</displayName><description>A Regular Expression that will be applied to each line in the dictionary file. If the regular expression does not match the line, the line will not be included in the list of terms to search for. If a Matching Group is specified, only the portion of the term that matches that Matching Group will be used instead of the entire term. If not specified, all terms in the dictionary will be used and each term will consist of the text of the entire line in the file</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>matched</name><description>FlowFiles whose attributes are found in the dictionary will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>unmatched</name><description>FlowFiles whose attributes are not found in the dictionary will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.ScanContent</name><type>PROCESSOR</type><description>Scans the content of FlowFiles for terms that are found in a user-supplied dictionary. If a term is matched, the UTF-8 encoded version of the term will be added to the FlowFile using the 'matching.term' attribute</description><tags><tag>aho-corasick</tag><tag>scan</tag><tag>content</tag><tag>byte sequence</tag><tag>search</tag><tag>find</tag><tag>dictionary</tag></tags><properties><property><name>Dictionary File</name><displayName>Dictionary File</displayName><description>The filename of the terms dictionary</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType></resourceTypes></resourceDefinition></property><property><name>Dictionary Encoding</name><displayName>Dictionary Encoding</displayName><description>Indicates how the dictionary is encoded. If 'text', dictionary terms are new-line delimited and UTF-8 encoded; if 'binary', dictionary terms are denoted by a 4-byte integer indicating the term length followed by the term itself</description><defaultValue>text</defaultValue><allowableValues><allowableValue><displayName>text</displayName><value>text</value><description></description></allowableValue><allowableValue><displayName>binary</displayName><value>binary</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>matched</name><description>FlowFiles that match at least one term in the dictionary are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>unmatched</name><description>FlowFiles that do not match any term in the dictionary are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>matching.term</name><description>The term that caused the Processor to route the FlowFile to the 'matched' relationship; if FlowFile is routed to the 'unmatched' relationship, this attribute is not added</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.SegmentContent</name><type>PROCESSOR</type><description>Segments a FlowFile into multiple smaller segments on byte boundaries. Each segment is given the following attributes: fragment.identifier, fragment.index, fragment.count, segment.original.filename; these attributes can then be used by the MergeContent processor in order to reconstitute the original FlowFile</description><tags><tag>segment</tag><tag>split</tag></tags><properties><property><name>Segment Size</name><displayName>Segment Size</displayName><description>The maximum data size in bytes for each segment</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>original</name><description>The original FlowFile will be sent to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>segments</name><description>All segments will be sent to this relationship. If the file was small enough that it was not segmented, a copy of the original is sent to this relationship as well as original</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>fragment.identifier</name><description>All segments produced from the same parent FlowFile will have the same randomly generated UUID added for this attribute</description></writesAttribute><writesAttribute><name>fragment.index</name><description>A one-up number that indicates the ordering of the segments that were created from a single parent FlowFile</description></writesAttribute><writesAttribute><name>fragment.count</name><description>The number of segments generated from the parent FlowFile</description></writesAttribute><writesAttribute><name>segment.original.filename </name><description>The filename of the parent FlowFile</description></writesAttribute><writesAttribute><name>segment.original.filename </name><description>The filename will be updated to include the parent's filename, the segment index, and the segment count</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><seeAlso><see>org.apache.nifi.processors.standard.MergeContent</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.SplitContent</name><type>PROCESSOR</type><description>Splits incoming FlowFiles by a specified byte sequence</description><tags><tag>content</tag><tag>split</tag><tag>binary</tag></tags><properties><property><name>Byte Sequence Format</name><displayName>Byte Sequence Format</displayName><description>Specifies how the &lt;Byte Sequence&gt; property should be interpreted</description><defaultValue>Hexadecimal</defaultValue><allowableValues><allowableValue><displayName>Hexadecimal</displayName><value>Hexadecimal</value><description>The Byte Sequence will be interpreted as a hexadecimal representation of bytes</description></allowableValue><allowableValue><displayName>Text</displayName><value>Text</value><description>The Byte Sequence will be interpreted as UTF-8 Encoded text</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Byte Sequence</name><displayName>Byte Sequence</displayName><description>A representation of bytes to look for and upon which to split the source file into separate files</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Keep Byte Sequence</name><displayName>Keep Byte Sequence</displayName><description>Determines whether or not the Byte Sequence should be included with each Split</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Byte Sequence Location</name><displayName>Byte Sequence Location</displayName><description>If &lt;Keep Byte Sequence&gt; is set to true, specifies whether the byte sequence should be added to the end of the first split or the beginning of the second; if &lt;Keep Byte Sequence&gt; is false, this property is ignored.</description><defaultValue>Trailing</defaultValue><allowableValues><allowableValue><displayName>Trailing</displayName><value>Trailing</value><description>Keep the Byte Sequence at the end of the first split if &lt;Keep Byte Sequence&gt; is true</description></allowableValue><allowableValue><displayName>Leading</displayName><value>Leading</value><description>Keep the Byte Sequence at the beginning of the second split if &lt;Keep Byte Sequence&gt; is true</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>original</name><description>The original file</description><autoTerminated>false</autoTerminated></relationship><relationship><name>splits</name><description>All Splits will be routed to the splits relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>fragment.identifier</name><description>All split FlowFiles produced from the same parent FlowFile will have the same randomly generated UUID added for this attribute</description></writesAttribute><writesAttribute><name>fragment.index</name><description>A one-up number that indicates the ordering of the split FlowFiles that were created from a single parent FlowFile</description></writesAttribute><writesAttribute><name>fragment.count</name><description>The number of split FlowFiles generated from the parent FlowFile</description></writesAttribute><writesAttribute><name>segment.original.filename </name><description>The filename of the parent FlowFile</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><systemResourceConsiderations><systemResourceConsideration><resource>MEMORY</resource><description>The FlowFile with its attributes is stored in memory, not the content of the FlowFile. If many splits are generated due to the size of the content, or how the content is configured to be split, a two-phase approach may be necessary to avoid excessive use of memory.</description></systemResourceConsideration></systemResourceConsiderations><seeAlso><see>org.apache.nifi.processors.standard.MergeContent</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.SplitJson</name><type>PROCESSOR</type><description>Splits a JSON File into multiple, separate FlowFiles for an array element specified by a JsonPath expression. Each generated FlowFile is comprised of an element of the specified array and transferred to relationship 'split,' with the original file transferred to the 'original' relationship. If the specified JsonPath is not found or does not evaluate to an array element, the original file is routed to 'failure' and no files are generated.</description><tags><tag>json</tag><tag>split</tag><tag>jsonpath</tag></tags><properties><property><name>JsonPath Expression</name><displayName>JsonPath Expression</displayName><description>A JsonPath expression that indicates the array element to split into JSON/scalar fragments.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Null Value Representation</name><displayName>Null Value Representation</displayName><description>Indicates the desired representation of JSON Path expressions resulting in a null value.</description><defaultValue>empty string</defaultValue><allowableValues><allowableValue><displayName>the string 'null'</displayName><value>the string 'null'</value><description></description></allowableValue><allowableValue><displayName>empty string</displayName><value>empty string</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max String Length</name><displayName>Max String Length</displayName><description>The maximum allowed length of a string value when parsing the JSON document</description><defaultValue>20 MB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>If a FlowFile fails processing for any reason (for example, the FlowFile is not valid JSON or the specified path does not exist), it will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>original</name><description>The original FlowFile that was split into segments. If the FlowFile fails processing, nothing will be sent to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>split</name><description>All segments of the original FlowFile will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>fragment.identifier</name><description>All split FlowFiles produced from the same parent FlowFile will have the same randomly generated UUID added for this attribute</description></writesAttribute><writesAttribute><name>fragment.index</name><description>A one-up number that indicates the ordering of the split FlowFiles that were created from a single parent FlowFile</description></writesAttribute><writesAttribute><name>fragment.count</name><description>The number of split FlowFiles generated from the parent FlowFile</description></writesAttribute><writesAttribute><name>segment.original.filename </name><description>The filename of the parent FlowFile</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><systemResourceConsiderations><systemResourceConsideration><resource>MEMORY</resource><description>The entirety of the FlowFile's content (as a JsonNode object) is read into memory, in addition to all of the generated FlowFiles representing the split JSON. If many splits are generated due to the size of the JSON, or how the JSON is configured to be split, a two-phase approach may be necessary to avoid excessive use of memory.</description></systemResourceConsideration></systemResourceConsiderations></extension><extension><name>org.apache.nifi.processors.standard.SplitRecord</name><type>PROCESSOR</type><description>Splits up an input FlowFile that is in a record-oriented data format into multiple smaller FlowFiles</description><tags><tag>split</tag><tag>generic</tag><tag>schema</tag><tag>json</tag><tag>csv</tag><tag>avro</tag><tag>log</tag><tag>logs</tag><tag>freeform</tag><tag>text</tag></tags><properties><property><name>Record Reader</name><displayName>Record Reader</displayName><description>Specifies the Controller Service to use for reading incoming data</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Record Writer</name><displayName>Record Writer</displayName><description>Specifies the Controller Service to use for writing out the records</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Records Per Split</name><displayName>Records Per Split</displayName><description>Specifies how many records should be written to each 'split' or 'segment' FlowFile</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>If a FlowFile cannot be transformed from the configured input format to the configured output format, the unchanged FlowFile will be routed to this relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>original</name><description>Upon successfully splitting an input FlowFile, the original FlowFile will be sent to this relationship.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>splits</name><description>The individual 'segments' of the original FlowFile will be routed to this relationship.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>mime.type</name><description>Sets the mime.type attribute to the MIME Type specified by the Record Writer for the FlowFiles routed to the 'splits' Relationship.</description></writesAttribute><writesAttribute><name>record.count</name><description>The number of records in the FlowFile. This is added to FlowFiles that are routed to the 'splits' Relationship.</description></writesAttribute><writesAttribute><name>fragment.identifier</name><description>All split FlowFiles produced from the same parent FlowFile will have the same randomly generated UUID added for this attribute</description></writesAttribute><writesAttribute><name>fragment.index</name><description>A one-up number that indicates the ordering of the split FlowFiles that were created from a single parent FlowFile</description></writesAttribute><writesAttribute><name>fragment.count</name><description>The number of split FlowFiles generated from the parent FlowFile</description></writesAttribute><writesAttribute><name>segment.original.filename </name><description>The filename of the parent FlowFile</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.SplitText</name><type>PROCESSOR</type><description>Splits a text file into multiple smaller text files on line boundaries limited by maximum number of lines or total size of fragment. Each output split file will contain no more than the configured number of lines or bytes. If both Line Split Count and Maximum Fragment Size are specified, the split occurs at whichever limit is reached first. If the first line of a fragment exceeds the Maximum Fragment Size, that line will be output in a single split file which exceeds the configured maximum size limit. This component also allows one to specify that each split should include a header lines. Header lines can be computed by either specifying the amount of lines that should constitute a header or by using header marker to match against the read lines. If such match happens then the corresponding line will be treated as header. Keep in mind that upon the first failure of header marker match, no more matches will be performed and the rest of the data will be parsed as regular lines for a given split. If after computation of the header there are no more data, the resulting split will consists of only header lines.</description><tags><tag>split</tag><tag>text</tag></tags><properties><property><name>Line Split Count</name><displayName>Line Split Count</displayName><description>The number of lines that will be added to each split file, excluding header lines. A value of zero requires Maximum Fragment Size to be set, and line count will not be considered in determining splits.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum Fragment Size</name><displayName>Maximum Fragment Size</displayName><description>The maximum size of each split file, including header lines. NOTE: in the case where a single line exceeds this property (including headers, if applicable), that line will be output in a split of its own which exceeds this Maximum Fragment Size setting.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Header Line Count</name><displayName>Header Line Count</displayName><description>The number of lines that should be considered part of the header; the header lines will be duplicated to all split files</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Header Line Marker Characters</name><displayName>Header Line Marker Characters</displayName><description>The first character(s) on the line of the datafile which signifies a header line. This value is ignored when Header Line Count is non-zero. The first line not containing the Header Line Marker Characters and all subsequent lines are considered non-header</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Remove Trailing Newlines</name><displayName>Remove Trailing Newlines</displayName><description>Whether to remove newlines at the end of each split file. This should be false if you intend to merge the split files later. If this is set to 'true' and a FlowFile is generated that contains only 'empty lines' (i.e., consists only of \r and \n characters), the FlowFile will not be emitted. Note, however, that if header lines are specified, the resultant FlowFile will never be empty as it will consist of the header lines, so a FlowFile may be emitted that contains only the header lines.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>If a file cannot be split for some reason, the original file will be routed to this destination and nothing will be routed elsewhere</description><autoTerminated>false</autoTerminated></relationship><relationship><name>original</name><description>The original input file will be routed to this destination when it has been successfully split into 1 or more files</description><autoTerminated>false</autoTerminated></relationship><relationship><name>splits</name><description>The split files will be routed to this destination when an input file is successfully split into 1 or more split files</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>text.line.count</name><description>The number of lines of text from the original FlowFile that were copied to this FlowFile</description></writesAttribute><writesAttribute><name>fragment.size</name><description>The number of bytes from the original FlowFile that were copied to this FlowFile, including header, if applicable, which is duplicated in each split FlowFile</description></writesAttribute><writesAttribute><name>fragment.identifier</name><description>All split FlowFiles produced from the same parent FlowFile will have the same randomly generated UUID added for this attribute</description></writesAttribute><writesAttribute><name>fragment.index</name><description>A one-up number that indicates the ordering of the split FlowFiles that were created from a single parent FlowFile</description></writesAttribute><writesAttribute><name>fragment.count</name><description>The number of split FlowFiles generated from the parent FlowFile</description></writesAttribute><writesAttribute><name>segment.original.filename </name><description>The filename of the parent FlowFile</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><systemResourceConsiderations><systemResourceConsideration><resource>MEMORY</resource><description>The FlowFile with its attributes is stored in memory, not the content of the FlowFile. If many splits are generated due to the size of the content, or how the content is configured to be split, a two-phase approach may be necessary to avoid excessive use of memory.</description></systemResourceConsideration></systemResourceConsiderations><seeAlso><see>org.apache.nifi.processors.standard.MergeContent</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.SplitXml</name><type>PROCESSOR</type><description>Splits an XML File into multiple separate FlowFiles, each comprising a child or descendant of the original root element</description><tags><tag>xml</tag><tag>split</tag></tags><properties><property><name>Split Depth</name><displayName>Split Depth</displayName><description>Indicates the XML-nesting depth to start splitting XML fragments. A depth of 1 means split the root's children, whereas a depth of 2 means split the root's children's children and so forth.</description><defaultValue>1</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>If a FlowFile fails processing for any reason (for example, the FlowFile is not valid XML), it will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>original</name><description>The original FlowFile that was split into segments. If the FlowFile fails processing, nothing will be sent to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>split</name><description>All segments of the original FlowFile will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>fragment.identifier</name><description>All split FlowFiles produced from the same parent FlowFile will have the same randomly generated UUID added for this attribute</description></writesAttribute><writesAttribute><name>fragment.index</name><description>A one-up number that indicates the ordering of the split FlowFiles that were created from a single parent FlowFile</description></writesAttribute><writesAttribute><name>fragment.count</name><description>The number of split FlowFiles generated from the parent FlowFile</description></writesAttribute><writesAttribute><name>segment.original.filename </name><description>The filename of the parent FlowFile</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><systemResourceConsiderations><systemResourceConsideration><resource>MEMORY</resource><description>The entirety of the FlowFile's content (as a Document object) is read into memory, in addition to all of the generated FlowFiles representing the split XML. A Document object can take approximately 10 times as much memory as the size of the XML. For example, a 1 MB XML document may use 10 MB of memory. If many splits are generated due to the size of the XML, a two-phase approach may be necessary to avoid excessive use of memory.</description></systemResourceConsideration></systemResourceConsiderations></extension><extension><name>org.apache.nifi.processors.standard.TailFile</name><type>PROCESSOR</type><description>"Tails" a file, or a list of files, ingesting data from the file as it is written to the file. The file is expected to be textual. Data is ingested only when a new line is encountered (carriage return or new-line character or combination). If the file to tail is periodically "rolled over", as is generally the case with log files, an optional Rolling Filename Pattern can be used to retrieve data from files that have rolled over, even if the rollover occurred while NiFi was not running (provided that the data still exists upon restart of NiFi). It is generally advisable to set the Run Schedule to a few seconds, rather than running with the default value of 0 secs, as this Processor will consume a lot of resources if scheduled very aggressively. At this time, this Processor does not support ingesting files that have been compressed when 'rolled over'.</description><tags><tag>tail</tag><tag>file</tag><tag>log</tag><tag>text</tag><tag>source</tag></tags><properties><property><name>tail-mode</name><displayName>Tailing mode</displayName><description>Mode to use: single file will tail only one file, multiple file will look for a list of file. In Multiple mode the Base directory is required.</description><defaultValue>Single file</defaultValue><allowableValues><allowableValue><displayName>Single file</displayName><value>Single file</value><description>In this mode, only the one file indicated in the 'Files to tail' property will be watched by the processor. In this mode, the file may not exist when starting the processor.</description></allowableValue><allowableValue><displayName>Multiple files</displayName><value>Multiple files</value><description>In this mode, the 'Files to tail' property accepts a regular expression and the processor will look for files in 'Base directory' to list the files to tail by the processor.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>File to Tail</name><displayName>File(s) to Tail</displayName><description>Path of the file to tail in case of single file mode. If using multifile mode, regular expression to find files to tail in the base directory. In case recursivity is set to true, the regular expression will be used to match the path starting from the base directory (see additional details for examples).</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Rolling Filename Pattern</name><displayName>Rolling Filename Pattern</displayName><description>If the file to tail "rolls over" as would be the case with log files, this filename pattern will be used to identify files that have rolled over so that if NiFi is restarted, and the file has rolled over, it will be able to pick up where it left off. This pattern supports wildcard characters * and ?, it also supports the notation ${filename} to specify a pattern based on the name of the file (without extension), and will assume that the files that have rolled over live in the same directory as the file being tailed. The same glob pattern will be used for all files.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Post-Rollover Tail Period</name><displayName>Post-Rollover Tail Period</displayName><description>When a file is rolled over, the processor will continue tailing the rolled over file until it has not been modified for this amount of time. This allows for another process to rollover a file, and then flush out any buffered data. Note that when this value is set, and the tailed file rolls over, the new file will not be tailed until the old file has not been modified for the configured amount of time. Additionally, when using this capability, in order to avoid data duplication, this period must be set longer than the Processor's Run Schedule, and the Processor must not be stopped after the file being tailed has been rolled over and before the data has been fully consumed. Otherwise, the data may be duplicated, as the entire file may be written out as the contents of a single FlowFile.</description><defaultValue>0 sec</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>tail-base-directory</name><displayName>Base directory</displayName><description>Base directory used to look for files to tail. This property is required when using Multifile mode.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Initial Start Position</name><displayName>Initial Start Position</displayName><description>When the Processor first begins to tail data, this property specifies where the Processor should begin reading data. Once data has been ingested from a file, the Processor will continue from the last point from which it has received data.</description><defaultValue>Beginning of File</defaultValue><allowableValues><allowableValue><displayName>Beginning of Time</displayName><value>Beginning of Time</value><description>Start with the oldest data that matches the Rolling Filename Pattern and then begin reading from the File to Tail</description></allowableValue><allowableValue><displayName>Beginning of File</displayName><value>Beginning of File</value><description>Start with the beginning of the File to Tail. Do not ingest any data that has already been rolled over</description></allowableValue><allowableValue><displayName>Current Time</displayName><value>Current Time</value><description>Start with the data at the end of the File to Tail. Do not ingest any data thas has already been rolled over or any data in the File to Tail that has already been written.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>File Location</name><displayName>State Location</displayName><description>Specifies where the state is located either local or cluster so that state can be stored appropriately in order to ensure that all data is consumed without duplicating data upon restart of NiFi</description><defaultValue>Local</defaultValue><allowableValues><allowableValue><displayName>Local</displayName><value>Local</value><description>State is stored locally. Each node in a cluster will tail a different file.</description></allowableValue><allowableValue><displayName>Remote</displayName><value>Remote</value><description>State is located on a remote resource. This Processor will store state across the cluster so that it can be run on Primary Node Only and a new Primary Node can pick up where the last one left off.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>tailfile-recursive-lookup</name><displayName>Recursive lookup</displayName><description>When using Multiple files mode, this property defines if files must be listed recursively or not in the base directory.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>tailfile-lookup-frequency</name><displayName>Lookup frequency</displayName><description>Only used in Multiple files mode. It specifies the minimum duration the processor will wait before listing again the files to tail.</description><defaultValue>10 minutes</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>tailfile-maximum-age</name><displayName>Maximum age</displayName><description>Only used in Multiple files mode. It specifies the necessary minimum duration to consider that no new messages will be appended in a file regarding its last modification date. This should not be set too low to avoid duplication of data in case new messages are appended at a lower frequency.</description><defaultValue>24 hours</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>reread-on-nul</name><displayName>Reread when NUL encountered</displayName><description>If this option is set to 'true', when a NUL character is read, the processor will yield and try to read the same part again later. (Note: Yielding may delay the processing of other files tailed by this processor, not just the one with the NUL character.) The purpose of this flag is to allow users to handle cases where reading a file may return temporary NUL values. NFS for example may send file contents out of order. In this case the missing parts are temporarily replaced by NUL values. CAUTION! If the file contains legitimate NUL values, setting this flag causes this processor to get stuck indefinitely. For this reason users should refrain from using this feature if they can help it and try to avoid having the target file on a file system where reads are unreliable.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Line Start Pattern</name><displayName>Line Start Pattern</displayName><description>A Regular Expression to match against the start of a log line. If specified, any line that matches the expression, and any following lines, will be buffered until another line matches the Expression. In doing this, we can avoid splitting apart multi-line messages in the file. This assumes that the data is in UTF-8 format.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>tail-mode</propertyName><propertyDisplayName>Tailing mode</propertyDisplayName><dependentValues><dependentValue>Single file</dependentValue></dependentValues></dependency></dependencies></property><property><name>pre-allocated-buffer-size</name><displayName>Pre-Allocated Buffer Size</displayName><description>Sets the amount of memory that is pre-allocated for each tailed file.</description><defaultValue>65536 B</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Max Buffer Size</name><displayName>Max Buffer Size</displayName><description>When using the Line Start Pattern, there may be situations in which the data in the file being tailed never matches the Regular Expression. This would result in the processor buffering all data from the tailed file, which can quickly exhaust the heap. To avoid this, the Processor will buffer only up to this amount of data before flushing the buffer, even if it means ingesting partial data from the file.</description><defaultValue>64 KB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Line Start Pattern</propertyName><propertyDisplayName>Line Start Pattern</propertyDisplayName></dependency></dependencies></property></properties><relationships><relationship><name>success</name><description>All FlowFiles are routed to this Relationship.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>tailfile.original.path</name><description>Path of the original file the flow file comes from.</description></writesAttribute></writesAttributes><triggerSerially>true</triggerSerially><stateful><description>Stores state about where in the Tailed File it left off so that on restart it does not have to duplicate data. State is stored either local or clustered depend on the &lt;File Location&gt; property.</description><scopes><scope>LOCAL</scope><scope>CLUSTER</scope></scopes></stateful><restricted><restrictions><restriction><requiredPermission>read filesystem</requiredPermission><explanation>Provides operator the ability to read from any file that NiFi has access to.</explanation></restriction></restrictions></restricted><inputRequirement>INPUT_FORBIDDEN</inputRequirement><defaultSchedule><strategy>TIMER_DRIVEN</strategy><period>30 sec</period><concurrentTasks>1</concurrentTasks></defaultSchedule></extension><extension><name>org.apache.nifi.processors.standard.TransformXml</name><type>PROCESSOR</type><description>Applies the provided XSLT file to the FlowFile XML payload. A new FlowFile is created with transformed content and is routed to the 'success' relationship. If the XSL transform fails, the original FlowFile is routed to the 'failure' relationship</description><tags><tag>xml</tag><tag>xslt</tag><tag>transform</tag></tags><properties><property><name>XSLT file name</name><displayName>XSLT file name</displayName><description>Provides the name (including full path) of the XSLT file to apply to the FlowFile XML content.One of the 'XSLT file name' and 'XSLT Lookup' properties must be defined.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType></resourceTypes></resourceDefinition></property><property><name>xslt-controller</name><displayName>XSLT Lookup</displayName><description>Controller lookup used to store XSLT definitions. One of the 'XSLT file name' and 'XSLT Lookup' properties must be defined. WARNING: note that the lookup controller service should not be used to store large XSLT files.</description><controllerServiceDefinition><className>org.apache.nifi.lookup.StringLookupService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>xslt-controller-key</name><displayName>XSLT Lookup key</displayName><description>Key used to retrieve the XSLT definition from the XSLT lookup controller. This property must be set when using the XSLT controller property.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>indent-output</name><displayName>Indent</displayName><description>Whether or not to indent the output.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>secure-processing</name><displayName>Secure processing</displayName><description>Whether or not to mitigate various XML-related attacks like XXE (XML External Entity) attacks.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>cache-size</name><displayName>Cache size</displayName><description>Maximum number of stylesheets to cache. Zero disables the cache.</description><defaultValue>10</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>cache-ttl-after-last-access</name><displayName>Cache TTL after last access</displayName><description>The cache TTL (time-to-live) or how long to keep stylesheets in the cache after last access.</description><defaultValue>60 secs</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>An XSLT transform parameter name</name><value>An XSLT transform parameter value</value><description>These XSLT parameters are passed to the transformer</description><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>failure</name><description>If a FlowFile fails processing for any reason (for example, the FlowFile is not valid XML), it will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>The FlowFile with transformed content will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.UnpackContent</name><type>PROCESSOR</type><description>Unpacks the content of FlowFiles that have been packaged with one of several different Packaging Formats, emitting one to many FlowFiles for each input FlowFile. Supported formats are TAR, ZIP, and FlowFile Stream packages.</description><tags><tag>Unpack</tag><tag>un-merge</tag><tag>tar</tag><tag>zip</tag><tag>archive</tag><tag>flowfile-stream</tag><tag>flowfile-stream-v3</tag></tags><properties><property><name>Packaging Format</name><displayName>Packaging Format</displayName><description>The Packaging Format used to create the file</description><defaultValue>use mime.type attribute</defaultValue><allowableValues><allowableValue><displayName>use mime.type attribute</displayName><value>use mime.type attribute</value><description></description></allowableValue><allowableValue><displayName>tar</displayName><value>tar</value><description></description></allowableValue><allowableValue><displayName>tar</displayName><value>tar</value><description></description></allowableValue><allowableValue><displayName>zip</displayName><value>zip</value><description></description></allowableValue><allowableValue><displayName>flowfile-stream-v3</displayName><value>flowfile-stream-v3</value><description></description></allowableValue><allowableValue><displayName>flowfile-stream-v2</displayName><value>flowfile-stream-v2</value><description></description></allowableValue><allowableValue><displayName>flowfile-tar-v1</displayName><value>flowfile-tar-v1</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Filename Character Set</name><displayName>Filename Character Set</displayName><description>If supplied this character set will be supplied to the Zip utility to attempt to decode filenames using the specific character set. If not specified the default platform character set will be used. This is useful if a Zip was created with a different character set than the platform default and the zip uses non standard values to specify.</description><defaultValue>UTF-8</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Packaging Format</propertyName><propertyDisplayName>Packaging Format</propertyDisplayName><dependentValues><dependentValue>use mime.type attribute</dependentValue><dependentValue>zip</dependentValue></dependentValues></dependency></dependencies></property><property><name>File Filter</name><displayName>File Filter</displayName><description>Only files contained in the archive whose names match the given regular expression will be extracted (tar/zip only)</description><defaultValue>.*</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Password</name><displayName>Password</displayName><description>Password used for decrypting Zip archives encrypted with ZipCrypto or AES. Configuring a password disables support for alternative Zip compression algorithms.</description><required>false</required><sensitive>true</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Packaging Format</propertyName><propertyDisplayName>Packaging Format</propertyDisplayName><dependentValues><dependentValue>use mime.type attribute</dependentValue><dependentValue>zip</dependentValue></dependentValues></dependency></dependencies></property><property><name>allow-stored-entries-wdd</name><displayName>Allow Stored Entries With Data Descriptor</displayName><description>Some zip archives contain stored entries with data descriptors which by spec should not happen.  If this property is true they will be read anyway.  If false and such an entry is discovered the zip will fail to process.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Packaging Format</propertyName><propertyDisplayName>Packaging Format</propertyDisplayName><dependentValues><dependentValue>use mime.type attribute</dependentValue><dependentValue>zip</dependentValue></dependentValues></dependency></dependencies></property></properties><relationships><relationship><name>failure</name><description>The original FlowFile is sent to this relationship when it cannot be unpacked for some reason</description><autoTerminated>false</autoTerminated></relationship><relationship><name>original</name><description>The original FlowFile is sent to this relationship after it has been successfully unpacked</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>Unpacked FlowFiles are sent to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><readsAttributes><readsAttribute><name>mime.type</name><description>If the &lt;Packaging Format&gt; property is set to use mime.type attribute, this attribute is used to determine the FlowFile's MIME Type. In this case, if the attribute is set to application/tar, the TAR Packaging Format will be used. If the attribute is set to application/zip, the ZIP Packaging Format will be used. If the attribute is set to application/flowfile-v3 or application/flowfile-v2 or application/flowfile-v1, the appropriate FlowFile Packaging Format will be used. If this attribute is missing, the FlowFile will be routed to 'failure'. Otherwise, if the attribute's value is not one of those mentioned above, the FlowFile will be routed to 'success' without being unpacked. Use the File Filter property only extract files matching a specific regular expression.</description></readsAttribute></readsAttributes><writesAttributes><writesAttribute><name>mime.type</name><description>If the FlowFile is successfully unpacked, its MIME Type is no longer known, so the mime.type attribute is set to application/octet-stream.</description></writesAttribute><writesAttribute><name>fragment.identifier</name><description>All unpacked FlowFiles produced from the same parent FlowFile will have the same randomly generated UUID added for this attribute</description></writesAttribute><writesAttribute><name>fragment.index</name><description>A one-up number that indicates the ordering of the unpacked FlowFiles that were created from a single parent FlowFile</description></writesAttribute><writesAttribute><name>fragment.count</name><description>The number of unpacked FlowFiles generated from the parent FlowFile</description></writesAttribute><writesAttribute><name>segment.original.filename </name><description>The filename of the parent FlowFile. Extensions of .tar, .zip or .pkg are removed because the MergeContent processor automatically adds those extensions if it is used to rebuild the original FlowFile</description></writesAttribute><writesAttribute><name>file.lastModifiedTime</name><description>The date and time that the unpacked file was last modified (tar and zip only).</description></writesAttribute><writesAttribute><name>file.creationTime</name><description>The date and time that the file was created. For encrypted zip files this attribute always holds the same value as file.lastModifiedTime. For tar and unencrypted zip files if available it will be returned otherwise this will be the same value asfile.lastModifiedTime.</description></writesAttribute><writesAttribute><name>file.lastMetadataChange</name><description>The date and time the file's metadata changed (tar only).</description></writesAttribute><writesAttribute><name>file.lastAccessTime</name><description>The date and time the file was last accessed (tar and unencrypted zip files only)</description></writesAttribute><writesAttribute><name>file.owner</name><description>The owner of the unpacked file (tar only)</description></writesAttribute><writesAttribute><name>file.group</name><description>The group owner of the unpacked file (tar only)</description></writesAttribute><writesAttribute><name>file.size</name><description>The uncompressed size of the unpacked file (tar and zip only)</description></writesAttribute><writesAttribute><name>file.permissions</name><description>The read/write/execute permissions of the unpacked file (tar and unencrypted zip files only)</description></writesAttribute><writesAttribute><name>file.encryptionMethod</name><description>The encryption method for entries in Zip archives</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><useCases><useCase><description>Unpack Zip containing filenames with special characters, created on Windows with filename charset 'Cp437' or 'IBM437'.</description><notes></notes><keywords></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>Set "Packaging Format" value to "zip" or "use mime.type attribute".
Set "Filename Character Set" value to "Cp437" or "IBM437".
</configuration></useCase></useCases><seeAlso><see>org.apache.nifi.processors.standard.MergeContent</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.UpdateCounter</name><type>PROCESSOR</type><description>This processor allows users to set specific counters and key points in their flow. It is useful for debugging and basic counting functions.</description><tags><tag>counter</tag><tag>debug</tag><tag>instrumentation</tag></tags><properties><property><name>counter-name</name><displayName>Counter Name</displayName><description>The name of the counter you want to set the value of - supports expression language like ${counterName}</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>delta</name><displayName>Delta</displayName><description>Adjusts the counter by the specified delta for each flow file received. May be a positive or negative integer.</description><defaultValue>1</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>success</name><description>Counter was updated/retrieved</description><autoTerminated>false</autoTerminated></relationship></relationships><readsAttributes><readsAttribute><name>counterName</name><description>The name of the counter to update/get.</description></readsAttribute></readsAttributes><writesAttributes></writesAttributes><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.UpdateDatabaseTable</name><type>PROCESSOR</type><description>This processor uses a JDBC connection and incoming records to generate any database table changes needed to support the incoming records. It expects a 'flat' record layout, meaning none of the top-level record fields has nested fields that are intended to become columns themselves.</description><tags><tag>metadata</tag><tag>jdbc</tag><tag>database</tag><tag>table</tag><tag>update</tag><tag>alter</tag></tags><properties><property><name>record-reader</name><displayName>Record Reader</displayName><description>The service for reading incoming flow files. The reader is only used to determine the schema of the records, the actual records will not be processed.</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>updatedatabasetable-dbcp-service</name><displayName>Database Connection Pooling Service</displayName><description>The Controller Service that is used to obtain connection(s) to the database</description><controllerServiceDefinition><className>org.apache.nifi.dbcp.DBCPService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>db-type</name><displayName>Database Type</displayName><description>Database Type for generating statements specific to a particular service or vendor.
The Generic Type supports most cases but selecting a specific type enables optimal processing
or additional features.
</description><defaultValue>Generic</defaultValue><allowableValues><allowableValue><displayName>Database Dialect Service</displayName><value>Database Dialect Service</value><description>Requires configuring a Database Dialect Service for SQL statements</description></allowableValue><allowableValue><displayName>Generic</displayName><value>Generic</value><description>Generates ANSI SQL</description></allowableValue><allowableValue><displayName>Oracle</displayName><value>Oracle</value><description>Generates Oracle compliant SQL</description></allowableValue><allowableValue><displayName>Oracle 12+</displayName><value>Oracle 12+</value><description>Generates Oracle compliant SQL for version 12 or greater</description></allowableValue><allowableValue><displayName>MS SQL 2012+</displayName><value>MS SQL 2012+</value><description>Generates MS SQL Compatible SQL, for version 2012 or greater</description></allowableValue><allowableValue><displayName>MS SQL 2008</displayName><value>MS SQL 2008</value><description>Generates MS SQL Compatible SQL for version 2008</description></allowableValue><allowableValue><displayName>MySQL</displayName><value>MySQL</value><description>Generates MySQL compatible SQL</description></allowableValue><allowableValue><displayName>PostgreSQL</displayName><value>PostgreSQL</value><description>Generates PostgreSQL compatible SQL</description></allowableValue><allowableValue><displayName>Phoenix</displayName><value>Phoenix</value><description>Generates Phoenix compliant SQL</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Database Dialect Service</name><displayName>Database Dialect Service</displayName><description>Database Dialect Service for generating statements specific to a particular service or vendor.</description><controllerServiceDefinition><className>org.apache.nifi.database.dialect.service.api.DatabaseDialectService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>db-type</propertyName><propertyDisplayName>Database Type</propertyDisplayName><dependentValues><dependentValue>Database Dialect Service</dependentValue></dependentValues></dependency></dependencies></property><property><name>updatedatabasetable-catalog-name</name><displayName>Catalog Name</displayName><description>The name of the catalog that the statement should update. This may not apply for the database that you are updating. In this case, leave the field empty. Note that if the property is set and the database is case-sensitive, the catalog name must match the database's catalog name exactly.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>updatedatabasetable-schema-name</name><displayName>Schema Name</displayName><description>The name of the database schema that the table belongs to. This may not apply for the database that you are updating. In this case, leave the field empty. Note that if the property is set and the database is case-sensitive, the schema name must match the database's schema name exactly.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>updatedatabasetable-table-name</name><displayName>Table Name</displayName><description>The name of the database table to update. If the table does not exist, then it will either be created or an error thrown, depending on the value of the Create Table property.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>updatedatabasetable-create-table</name><displayName>Create Table Strategy</displayName><description>Specifies how to process the target table when it does not exist (create it, fail, e.g.).</description><defaultValue>Fail If Not Exists</defaultValue><allowableValues><allowableValue><displayName>Create If Not Exists</displayName><value>Create If Not Exists</value><description>Create a table with the given schema if it does not already exist</description></allowableValue><allowableValue><displayName>Fail If Not Exists</displayName><value>Fail If Not Exists</value><description>If the target does not already exist, log an error and route the flowfile to failure</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>updatedatabasetable-primary-keys</name><displayName>Primary Key Fields</displayName><description>A comma-separated list of record field names that uniquely identifies a row in the database. This property is only used if the specified table needs to be created, in which case the Primary Key Fields will be used to specify the primary keys of the newly-created table. IMPORTANT: Primary Key Fields must match the record field names exactly unless 'Quote Column Identifiers' is false and the database allows for case-insensitive column names. In practice it is best to specify Primary Key Fields that exactly match the record field names, and those will become the column names in the created table.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>updatedatabasetable-create-table</propertyName><propertyDisplayName>Create Table Strategy</propertyDisplayName><dependentValues><dependentValue>Create If Not Exists</dependentValue></dependentValues></dependency></dependencies></property><property><name>updatedatabasetable-translate-field-names</name><displayName>Translate Field Names</displayName><description>If true, the Processor will attempt to translate field names into the corresponding column names for the table specified, for the purposes of determining whether the field name exists as a column in the target table. NOTE: If the target table does not exist and is to be created, this property is ignored and the field names will be used as-is. If false, the field names must match the column names exactly, or the column may not be found and instead an error my be reported that the column already exists.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Column Name Translation Strategy</name><displayName>Column Name Translation Strategy</displayName><description>The strategy used to normalize table column name. Column Name will be uppercased to do case-insensitive matching irrespective of strategy</description><defaultValue>REMOVE_UNDERSCORE</defaultValue><allowableValues><allowableValue><displayName>Remove Underscore</displayName><value>REMOVE_UNDERSCORE</value><description>Underscores '_' will be removed from column names Ex: 'Pics_1_23' becomes 'PICS123'</description></allowableValue><allowableValue><displayName>Remove Space</displayName><value>REMOVE_SPACE</value><description>Spaces will be removed from column names Ex. 'User Name' becomes 'USERNAME'</description></allowableValue><allowableValue><displayName>Remove Underscores and Spaces</displayName><value>REMOVE_UNDERSCORE_AND_SPACE</value><description>Spaces and Underscores will be removed from column names Ex. 'User_1 Name' becomes 'USER1NAME'</description></allowableValue><allowableValue><displayName>Remove Regular Expression Characters</displayName><value>REMOVE_ALL_SPECIAL_CHAR</value><description>Remove Regular Expression Characters Ex. 'user-id' becomes USERID ,total(estimated) become TOTALESTIMATED</description></allowableValue><allowableValue><displayName>Regular Expression</displayName><value>PATTERN</value><description>Remove characters matching this Regular Expression from the column names Ex.1. '\d' will  Remove all numbers 2. '[^a-zA-Z0-9_]' will remove special characters except underscore</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>updatedatabasetable-translate-field-names</propertyName><propertyDisplayName>Translate Field Names</propertyDisplayName><dependentValues><dependentValue>true</dependentValue></dependentValues></dependency></dependencies></property><property><name>Column Name Translation Pattern</name><displayName>Column Name Translation Pattern</displayName><description>Column name will be normalized with this regular expression</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Column Name Translation Strategy</propertyName><propertyDisplayName>Column Name Translation Strategy</propertyDisplayName><dependentValues><dependentValue>PATTERN</dependentValue></dependentValues></dependency></dependencies></property><property><name>updatedatabasetable-update-field-names</name><displayName>Update Field Names</displayName><description>This property indicates whether to update the output schema such that the field names are set to the exact column names from the specified table. This should be used if the incoming record field names may not match the table's column names in terms of upper- and lower-case. For example, this property should be set to true if the output FlowFile is destined for Oracle e.g., which expects the field names to match the column names exactly. NOTE: The value of the 'Translate Field Names' property is ignored when updating field names; instead they are updated to match the column name as returned by the database.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>updatedatabasetable-record-writer</name><displayName>Record Writer</displayName><description>Specifies the Controller Service to use for writing results to a FlowFile. The Record Writer should use Inherit Schema to emulate the inferred schema behavior, i.e. an explicit schema need not be defined in the writer, and will be supplied by the same logic used to infer the schema from the column types. If Create Table Strategy is set 'Create If Not Exists', the Record Writer's output format must match the Record Reader's format in order for the data to be placed in the created table location. Note that this property is only used if 'Update Field Names' is set to true and the field names do not all match the column names exactly. If no update is needed for any field names (or 'Update Field Names' is false), the Record Writer is not used and instead the input FlowFile is routed to success or failure without modification.</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>updatedatabasetable-update-field-names</propertyName><propertyDisplayName>Update Field Names</propertyDisplayName><dependentValues><dependentValue>true</dependentValue></dependentValues></dependency></dependencies></property><property><name>updatedatabasetable-quoted-table-identifiers</name><displayName>Quote Table Identifiers</displayName><description>Enabling this option will cause the table name to be quoted to support the use of special characters in the table name and/or forcing the value of the Table Name property to match the target table name exactly.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>updatedatabasetable-quoted-column-identifiers</name><displayName>Quote Column Identifiers</displayName><description>Enabling this option will cause all column names to be quoted, allowing you to use reserved words as column names in your tables and/or forcing the record field names to match the column names exactly.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>updatedatabasetable-query-timeout</name><displayName>Query Timeout</displayName><description>Sets the number of seconds the driver will wait for a query to execute. A value of 0 means no timeout. NOTE: Non-zero values may not be supported by the driver.</description><defaultValue>0</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>A FlowFile containing records routed to this relationship if the record could not be transmitted to the database.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>A FlowFile containing records routed to this relationship after the record has been successfully transmitted to the database.</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>output.table</name><description>This attribute is written on the flow files routed to the 'success' and 'failure' relationships, and contains the target table name.</description></writesAttribute><writesAttribute><name>output.path</name><description>This attribute is written on the flow files routed to the 'success' and 'failure' relationships, and contains the path on the file system to the table (or partition location if the table is partitioned).</description></writesAttribute><writesAttribute><name>mime.type</name><description>Sets the mime.type attribute to the MIME Type specified by the Record Writer, only if a Record Writer is specified and Update Field Names is 'true'.</description></writesAttribute><writesAttribute><name>record.count</name><description>Sets the number of records in the FlowFile, only if a Record Writer is specified and Update Field Names is 'true'.</description></writesAttribute></writesAttributes><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.UpdateRecord</name><type>PROCESSOR</type><description>Updates the contents of a FlowFile that contains Record-oriented data (i.e., data that can be read via a RecordReader and written by a RecordWriter). This Processor requires that at least one user-defined Property be added. The name of the Property should indicate a RecordPath that determines the field that should be updated. The value of the Property is either a replacement value (optionally making use of the Expression Language) or is itself a RecordPath that extracts a value from the Record. Whether the Property value is determined to be a RecordPath or a literal value depends on the configuration of the &lt;Replacement Value Strategy&gt; Property.</description><tags><tag>update</tag><tag>record</tag><tag>generic</tag><tag>schema</tag><tag>json</tag><tag>csv</tag><tag>avro</tag><tag>log</tag><tag>logs</tag><tag>freeform</tag><tag>text</tag></tags><properties><property><name>Record Reader</name><displayName>Record Reader</displayName><description>Specifies the Controller Service to use for reading incoming data</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Record Writer</name><displayName>Record Writer</displayName><description>Specifies the Controller Service to use for writing out the records</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Replacement Value Strategy</name><displayName>Replacement Value Strategy</displayName><description>Specifies how to interpret the configured replacement values</description><defaultValue>literal-value</defaultValue><allowableValues><allowableValue><displayName>Literal Value</displayName><value>literal-value</value><description>The value entered for a Property (after Expression Language has been evaluated) is the desired value to update the Record Fields with. Expression Language may reference variables 'field.name', 'field.type', and 'field.value' to access information about the field and the value of the field being evaluated.</description></allowableValue><allowableValue><displayName>Record Path Value</displayName><value>record-path-value</value><description>The value entered for a Property (after Expression Language has been evaluated) is not the literal value to use but rather is a Record Path that should be evaluated against the Record, and the result of the RecordPath will be used to update the Record. Note that if this option is selected, and the Record Path results in multiple values for a given Record, the input FlowFile will be routed to the 'failure' Relationship.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><dynamicProperties><dynamicProperty><name>A RecordPath.</name><value>The value to use to replace fields in the record that match the RecordPath</value><description>Allows users to specify values to use to replace fields in the record that match the RecordPath.</description><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope></dynamicProperty></dynamicProperties><relationships><relationship><name>failure</name><description>If a FlowFile cannot be transformed from the configured input format to the configured output format, the unchanged FlowFile will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>FlowFiles that are successfully transformed will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>record.index</name><description>This attribute provides the current row index and is only available inside the literal value expression.</description></writesAttribute><writesAttribute><name>record.error.message</name><description>This attribute provides on failure the error message encountered by the Reader or Writer.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement><useCases><useCase><description>Combine multiple fields into a single field.</description><notes></notes><keywords><keyword>combine</keyword><keyword>concatenate</keyword><keyword>recordpath</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>"Replacement Value Strategy" = "Record Path Value"

A single additional property is added to the Processor. The name of the property is a RecordPath identifying the field to place the result in.
The value of the property uses the concat Record Path function to concatenate multiple values together, potentially using other string literal values.
For example, to combine the `title`, `firstName` and `lastName` fields into a single field named `fullName`, we add a property with the name `/fullName` and a value of `concat(/title, ' ', /firstName, ' ', /lastName)`
</configuration></useCase><useCase><description>Change the value of a record field to an explicit value.</description><notes></notes><keywords><keyword>change</keyword><keyword>update</keyword><keyword>replace</keyword><keyword>transform</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>    "Replacement Value Strategy" = "Literal Value"

    A single additional property is added to the Processor. The name of the property is a RecordPath identifying the field to place the result in.
    The value of the property is the explicit value to set the field to. For example, we can set any field with a name of `txId`, regardless of its level in the data's hierarchy,     to `1111-1111` by adding a property with a name of `//txId` and a value of `1111-1111`
</configuration></useCase><useCase><description>Copy the value of one record field to another record field.</description><notes></notes><keywords><keyword>change</keyword><keyword>update</keyword><keyword>copy</keyword><keyword>recordpath</keyword><keyword>hierarchy</keyword><keyword>transform</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>    "Replacement Value Strategy" = "Record Path Value"

    A single additional property is added to the Processor. The name of the property is a RecordPath identifying the field to update.
    The value of the property is a RecordPath identifying the field to copy the value from.
    For example, we can copy the value of `/identifiers/all/imei` to the `identifier` field at the root level, by adding a property named     `/identifier` with a value of `/identifiers/all/imei`.
</configuration></useCase><useCase><description>Enrich data by injecting the value of an attribute into each Record.</description><notes></notes><keywords><keyword>enrich</keyword><keyword>attribute</keyword><keyword>change</keyword><keyword>update</keyword><keyword>replace</keyword><keyword>insert</keyword><keyword>transform</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>"Replacement Value Strategy" = "Literal Value"

A single additional property is added to the Processor. The name of the property is a RecordPath identifying the field to place the result in.
The value of the property is an Expression Language expression that references the attribute of interest. We can, for example, insert a new field name `filename` into each record by adding a property named `/filename` with a value of `${filename}`
</configuration></useCase><useCase><description>Change the format of a record field's value.</description><notes>Use the RenameRecordField Processor in order to change a field's name.</notes><keywords><keyword>change</keyword><keyword>update</keyword><keyword>replace</keyword><keyword>insert</keyword><keyword>transform</keyword><keyword>format</keyword><keyword>date/time</keyword><keyword>timezone</keyword><keyword>expression language</keyword></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>"Replacement Value Strategy" = "Literal Value"

A single additional property is added to the Processor. The name of the property is a RecordPath identifying the field to update.
The value is an Expression Language expression that references the `field.value` variable. For example, to change the date/time format of a field named `txDate` from `year-month-day` format to `month/day/year` format, we add a property named `/txDate` with a value of `${field.value:toDate('yyyy-MM-dd'):format('MM/dd/yyyy')}`. We could also change the timezone of a timestamp field (and insert the timezone for clarity) by using a value of `${field.value:toDate('yyyy-MM-dd HH:mm:ss', 'UTC-0400'):format('yyyy-MM-dd HH:mm:ss Z', 'UTC')}`.
</configuration></useCase></useCases><seeAlso><see>org.apache.nifi.processors.standard.ConvertRecord</see></seeAlso></extension><extension><name>org.apache.nifi.processors.standard.ValidateCsv</name><type>PROCESSOR</type><description>Validates the contents of FlowFiles or a FlowFile attribute value against a user-specified CSV schema. Take a look at the additional documentation of this processor for some schema examples.</description><tags><tag>csv</tag><tag>schema</tag><tag>validation</tag></tags><properties><property><name>validate-csv-schema</name><displayName>Schema</displayName><description>The schema to be used for validation. Is expected a comma-delimited string representing the cell processors to apply. The following cell processors are allowed in the schema definition: [ParseBigDecimal, ParseBool, ParseChar, ParseDate, ParseDouble, ParseInt, ParseLong, Optional, DMinMax, Equals, ForbidSubStr, LMinMax, NotNull, Null, RequireHashCode, RequireSubStr, Strlen, StrMinMax, StrNotNullOrEmpty, StrRegEx, Unique, UniqueHashCode, IsIncludedIn]. Note: cell processors cannot be nested except with Optional. Schema is required if Header is false.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>CSV Source Attribute</name><displayName>CSV Source Attribute</displayName><description>The name of the attribute containing CSV data to be validated. If this property is blank, the FlowFile content will be validated.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>validate-csv-strategy</propertyName><propertyDisplayName>Validation strategy</propertyDisplayName><dependentValues><dependentValue>FlowFile validation</dependentValue></dependentValues></dependency></dependencies></property><property><name>validate-csv-header</name><displayName>Header</displayName><description>True if the incoming flow file contains a header to ignore, false otherwise.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>validate-csv-delimiter</name><displayName>Delimiter character</displayName><description>Character used as 'delimiter' in the incoming data. Example: ,</description><defaultValue>,</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>validate-csv-quote</name><displayName>Quote character</displayName><description>Character used as 'quote' in the incoming data. Example: "</description><defaultValue>"</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>validate-csv-eol</name><displayName>End of line symbols</displayName><description>Symbols used as 'end of line' in the incoming data. Example: \n</description><defaultValue>\n</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>validate-csv-strategy</name><displayName>Validation strategy</displayName><description>Strategy to apply when routing input files to output relationships.</description><defaultValue>FlowFile validation</defaultValue><allowableValues><allowableValue><displayName>Line by line validation</displayName><value>Line by line validation</value><description>In case an error is found, the input CSV file will be split into two FlowFiles: one routed to the 'valid' relationship containing all the correct lines and one routed to the 'invalid' relationship containing all the incorrect lines. Take care if choosing this option while using Unique cell processors in schema definition:the first occurrence will be considered valid and the next ones as invalid.</description></allowableValue><allowableValue><displayName>FlowFile validation</displayName><value>FlowFile validation</value><description>As soon as an error is found in the CSV file, the validation will stop and the whole flow file will be routed to the 'invalid' relationship. This option offers best performances.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>validate-csv-violations</name><displayName>Include all violations</displayName><description>If true, the validation.error.message attribute would include the list of all the violations for the first invalid line. Note that setting this property to true would slightly decrease the performances as all columns would be validated. If false, a line is invalid as soon as a column is found violating the specified constraint and only this violation for the first invalid line will be included in the validation.error.message attribute.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>invalid</name><description>FlowFiles that are not valid according to the specified schema, or no schema or CSV header can be identified, are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>valid</name><description>FlowFiles that are successfully validated against the schema are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>count.valid.lines</name><description>If line by line validation, number of valid lines extracted from the source data</description></writesAttribute><writesAttribute><name>count.invalid.lines</name><description>If line by line validation, number of invalid lines extracted from the source data</description></writesAttribute><writesAttribute><name>count.total.lines</name><description>If line by line validation, total number of lines in the source data</description></writesAttribute><writesAttribute><name>validation.error.message</name><description>For flow files routed to invalid, message of the first validation error</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.ValidateJson</name><type>PROCESSOR</type><description>Validates the contents of FlowFiles against a configurable JSON Schema. See json-schema.org for specification standards. This Processor does not support input containing multiple JSON objects, such as newline-delimited JSON. If the input FlowFile contains newline-delimited JSON, only the first line will be validated.</description><tags><tag>JSON</tag><tag>schema</tag><tag>validation</tag></tags><properties><property><name>Schema Access Strategy</name><displayName>Schema Access Strategy</displayName><description>Specifies how to obtain the schema that is to be used for interpreting the data.</description><defaultValue>SCHEMA_CONTENT_PROPERTY</defaultValue><allowableValues><allowableValue><displayName>Schema Name Property</displayName><value>SCHEMA_NAME_PROPERTY</value><description>The name of the Schema to use is specified by the 'Schema Name' Property. The value of this property is used to lookup the Schema in the configured JSON Schema Registry Service.</description></allowableValue><allowableValue><displayName>JSON Schema Property</displayName><value>SCHEMA_CONTENT_PROPERTY</value><description>A URL or file path to the JSON schema or the actual JSON schema is specified by the 'JSON Schema' Property. No matter how the JSON schema is specified, it must be a valid JSON schema</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Schema Name</name><displayName>Schema Name</displayName><description>Specifies the name of the schema to lookup in the Schema Registry property</description><defaultValue>${schema.name}</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Schema Access Strategy</propertyName><propertyDisplayName>Schema Access Strategy</propertyDisplayName><dependentValues><dependentValue>SCHEMA_NAME_PROPERTY</dependentValue></dependentValues></dependency></dependencies></property><property><name>JSON Schema Registry</name><displayName>JSON Schema Registry</displayName><description>Specifies the Controller Service to use for the JSON Schema Registry</description><controllerServiceDefinition><className>org.apache.nifi.schemaregistry.services.JsonSchemaRegistry</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Schema Access Strategy</propertyName><propertyDisplayName>Schema Access Strategy</propertyDisplayName><dependentValues><dependentValue>SCHEMA_NAME_PROPERTY</dependentValue></dependentValues></dependency></dependencies></property><property><name>JSON Schema</name><displayName>JSON Schema</displayName><description>A URL or file path to the JSON schema or the actual JSON schema content</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType><resourceType>TEXT</resourceType><resourceType>URL</resourceType></resourceTypes></resourceDefinition><dependencies><dependency><propertyName>Schema Access Strategy</propertyName><propertyDisplayName>Schema Access Strategy</propertyDisplayName><dependentValues><dependentValue>SCHEMA_CONTENT_PROPERTY</dependentValue></dependentValues></dependency></dependencies></property><property><name>JSON Schema Version</name><displayName>JSON Schema Version</displayName><description>The JSON schema specification</description><defaultValue>DRAFT_2020_12</defaultValue><allowableValues><allowableValue><displayName>Draft 4</displayName><value>DRAFT_4</value><description>Draft Version 4</description></allowableValue><allowableValue><displayName>Draft 6</displayName><value>DRAFT_6</value><description>Draft Version 6</description></allowableValue><allowableValue><displayName>Draft 7</displayName><value>DRAFT_7</value><description>Draft Version 7</description></allowableValue><allowableValue><displayName>Draft 2019-09</displayName><value>DRAFT_2019_09</value><description>Draft Version 2019-09</description></allowableValue><allowableValue><displayName>Draft 2020-12</displayName><value>DRAFT_2020_12</value><description>Draft Version 2020-12</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Schema Access Strategy</propertyName><propertyDisplayName>Schema Access Strategy</propertyDisplayName><dependentValues><dependentValue>SCHEMA_CONTENT_PROPERTY</dependentValue></dependentValues></dependency></dependencies></property><property><name>Max String Length</name><displayName>Max String Length</displayName><description>The maximum allowed length of a string value when parsing the JSON document</description><defaultValue>20 MB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>FlowFiles that cannot be read as JSON are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>invalid</name><description>FlowFiles that are not valid according to the specified schema are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>valid</name><description>FlowFiles that are successfully validated against the schema are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>json.validation.errors</name><description>If the flow file is routed to the invalid relationship , this attribute will contain the error message resulting from the validation failure.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><restricted><restrictions><restriction><requiredPermission>reference remote resources</requiredPermission><explanation>Schema configuration can reference resources over HTTP</explanation></restriction></restrictions></restricted><inputRequirement>INPUT_REQUIRED</inputRequirement><systemResourceConsiderations><systemResourceConsideration><resource>MEMORY</resource><description>Validating JSON requires reading FlowFile content into memory</description></systemResourceConsideration></systemResourceConsiderations></extension><extension><name>org.apache.nifi.processors.standard.ValidateRecord</name><type>PROCESSOR</type><description>Validates the Records of an incoming FlowFile against a given schema. All records that adhere to the schema are routed to the "valid" relationship while records that do not adhere to the schema are routed to the "invalid" relationship. It is therefore possible for a single incoming FlowFile to be split into two individual FlowFiles if some records are valid according to the schema and others are not. Any FlowFile that is routed to the "invalid" relationship will emit a ROUTE Provenance Event with the Details field populated to explain why records were invalid. In addition, to gain further explanation of why records were invalid, DEBUG-level logging can be enabled for the "org.apache.nifi.processors.standard.ValidateRecord" logger.</description><tags><tag>record</tag><tag>schema</tag><tag>validate</tag></tags><properties><property><name>record-reader</name><displayName>Record Reader</displayName><description>Specifies the Controller Service to use for reading incoming data</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>record-writer</name><displayName>Record Writer</displayName><description>Specifies the Controller Service to use for writing out the records. Regardless of the Controller Service schema access configuration, the schema that is used to validate record is used to write the valid results.</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>invalid-record-writer</name><displayName>Record Writer for Invalid Records</displayName><description>If specified, this Controller Service will be used to write out any records that are invalid. If not specified, the writer specified by the "Record Writer" property will be used with the schema used to read the input records. This is useful, for example, when the configured Record Writer cannot write data that does not adhere to its schema (as is the case with Avro) or when it is desirable to keep invalid records in their original format while converting valid records to another format.</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>schema-access-strategy</name><displayName>Schema Access Strategy</displayName><description>Specifies how to obtain the schema that should be used to validate records</description><defaultValue>reader-schema</defaultValue><allowableValues><allowableValue><displayName>Use Reader's Schema</displayName><value>reader-schema</value><description>The schema to validate the data against is determined by asking the configured Record Reader for its schema</description></allowableValue><allowableValue><displayName>Use 'Schema Name' Property</displayName><value>schema-name</value><description>The name of the Schema to use is specified by the 'Schema Name' Property. The value of this property is used to lookup the Schema in the configured Schema Registry service.</description></allowableValue><allowableValue><displayName>Use 'Schema Text' Property</displayName><value>schema-text-property</value><description>The text of the Schema itself is specified by the 'Schema Text' Property. The value of this property must be a valid Avro Schema. If Expression Language is used, the value of the 'Schema Text' property must be valid after substituting the expressions.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>schema-registry</name><displayName>Schema Registry</displayName><description>Specifies the Controller Service to use for the Schema Registry</description><controllerServiceDefinition><className>org.apache.nifi.schemaregistry.services.SchemaRegistry</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>schema-access-strategy</propertyName><propertyDisplayName>Schema Access Strategy</propertyDisplayName><dependentValues><dependentValue>schema-name</dependentValue><dependentValue>schema-reference-reader</dependentValue></dependentValues></dependency></dependencies></property><property><name>schema-name</name><displayName>Schema Name</displayName><description>Specifies the name of the schema to lookup in the Schema Registry property</description><defaultValue>${schema.name}</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>schema-access-strategy</propertyName><propertyDisplayName>Schema Access Strategy</propertyDisplayName><dependentValues><dependentValue>schema-name</dependentValue></dependentValues></dependency></dependencies></property><property><name>schema-branch</name><displayName>Schema Branch</displayName><description>Specifies the name of the branch to use when looking up the schema in the Schema Registry property. If the chosen Schema Registry does not support branching, this value will be ignored.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>schema-access-strategy</propertyName><propertyDisplayName>Schema Access Strategy</propertyDisplayName><dependentValues><dependentValue>schema-name</dependentValue></dependentValues></dependency></dependencies></property><property><name>schema-version</name><displayName>Schema Version</displayName><description>Specifies the version of the schema to lookup in the Schema Registry. If not specified then the latest version of the schema will be retrieved.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>schema-access-strategy</propertyName><propertyDisplayName>Schema Access Strategy</propertyDisplayName><dependentValues><dependentValue>schema-name</dependentValue></dependentValues></dependency></dependencies></property><property><name>schema-text</name><displayName>Schema Text</displayName><description>The text of an Avro-formatted Schema</description><defaultValue>${avro.schema}</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>schema-access-strategy</propertyName><propertyDisplayName>Schema Access Strategy</propertyDisplayName><dependentValues><dependentValue>schema-text-property</dependentValue></dependentValues></dependency></dependencies></property><property><name>allow-extra-fields</name><displayName>Allow Extra Fields</displayName><description>If the incoming data has fields that are not present in the schema, this property determines whether or not the Record is valid. If true, the Record is still valid. If false, the Record will be invalid due to the extra fields.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>strict-type-checking</name><displayName>Strict Type Checking</displayName><description>If the incoming data has a Record where a field is not of the correct type, this property determines how to handle the Record. If true, the Record will be considered invalid. If false, the Record will be considered valid and the field will be coerced into the correct type (if possible, according to the type coercion supported by the Record Writer). This property controls how the data is validated against the validation schema.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>coerce-types</name><displayName>Force Types From Reader's Schema</displayName><description>If enabled, the processor will coerce every field to the type specified in the Reader's schema. If the value of a field cannot be coerced to the type, the field will be skipped (will not be read from the input data), thus will not appear in the output. If not enabled, then every field will appear in the output but their types may differ from what is specified in the schema. For details please see the Additional Details page of the processor's Help. This property controls how the data is read by the specified Record Reader.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>validation-details-attribute-name</name><displayName>Validation Details Attribute Name</displayName><description>If specified, when a validation error occurs, this attribute name will be used to leave the details. The number of characters will be limited by the property 'Maximum Validation Details Length'.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>maximum-validation-details-length</name><displayName>Maximum Validation Details Length</displayName><description>Specifies the maximum number of characters that validation details value can have. Any characters beyond the max will be truncated. This property is only used if 'Validation Details Attribute Name' is set</description><defaultValue>1024</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>failure</name><description>If the records cannot be read, validated, or written, for any reason, the original FlowFile will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>invalid</name><description>Records that are not valid according to the schema will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>valid</name><description>Records that are valid according to the schema will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>mime.type</name><description>Sets the mime.type attribute to the MIME Type specified by the Record Writer</description></writesAttribute><writesAttribute><name>record.count</name><description>The number of records in the FlowFile routed to a relationship</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.standard.ValidateXml</name><type>PROCESSOR</type><description>Validates XML contained in a FlowFile. By default, the XML is contained in the FlowFile content. If the 'XML Source Attribute' property is set, the XML to be validated is contained in the specified attribute. It is not recommended to use attributes to hold large XML documents; doing so could adversely affect system performance. Full schema validation is performed if the processor is configured with the XSD schema details. Otherwise, the only validation performed is to ensure the XML syntax is correct and well-formed, e.g. all opening tags are properly closed.</description><tags><tag>xml</tag><tag>schema</tag><tag>validation</tag><tag>xsd</tag></tags><properties><property><name>Schema File</name><displayName>Schema File</displayName><description>The file path or URL to the XSD Schema file that is to be used for validation. If this property is blank, only XML syntax/structure will be validated.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType><resourceType>URL</resourceType></resourceTypes></resourceDefinition></property><property><name>XML Source Attribute</name><displayName>XML Source Attribute</displayName><description>The name of the attribute containing XML to be validated. If this property is blank, the FlowFile content will be validated.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>invalid</name><description>FlowFiles that are not valid according to the specified schema or contain invalid XML are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>valid</name><description>FlowFiles that are successfully validated against the schema, if provided, or verified to be well-formed XML are routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>validatexml.invalid.error</name><description>If the flow file is routed to the invalid relationship the attribute will contain the error message resulting from the validation failure.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><sideEffectFree>true</sideEffectFree><restricted><restrictions><restriction><requiredPermission>reference remote resources</requiredPermission><explanation>Schema configuration can reference resources over HTTP</explanation></restriction></restrictions></restricted><inputRequirement>INPUT_REQUIRED</inputRequirement><systemResourceConsiderations><systemResourceConsideration><resource>MEMORY</resource><description>While this processor supports processing XML within attributes, it is strongly discouraged to hold large amounts of data in attributes. In general, attribute values should be as small as possible and hold no more than a couple hundred characters.</description></systemResourceConsideration></systemResourceConsiderations></extension><extension><name>org.apache.nifi.processors.standard.Wait</name><type>PROCESSOR</type><description>Routes incoming FlowFiles to the 'wait' relationship until a matching release signal is stored in the distributed cache from a corresponding Notify processor. When a matching release signal is identified, a waiting FlowFile is routed to the 'success' relationship. The release signal entry is then removed from the cache. The attributes of the FlowFile that produced the release signal are copied to the waiting FlowFile if the Attribute Cache Regex property of the corresponding Notify processor is set properly. If there are multiple release signals in the cache identified by the Release Signal Identifier, and the Notify processor is configured to copy the FlowFile attributes to the cache, then the FlowFile passing the Wait processor receives the union of the attributes of the FlowFiles that produced the release signals in the cache (identified by Release Signal Identifier). Waiting FlowFiles will be routed to 'expired' if they exceed the Expiration Duration. If you need to wait for more than one signal, specify the desired number of signals via the 'Target Signal Count' property. This is particularly useful with processors that split a source FlowFile into multiple fragments, such as SplitText. In order to wait for all fragments to be processed, connect the 'original' relationship to a Wait processor, and the 'splits' relationship to a corresponding Notify processor. Configure the Notify and Wait processors to use the '${fragment.identifier}' as the value of 'Release Signal Identifier', and specify '${fragment.count}' as the value of 'Target Signal Count' in the Wait processor.It is recommended to use a prioritizer (for instance First In First Out) when using the 'wait' relationship as a loop.</description><tags><tag>map</tag><tag>cache</tag><tag>wait</tag><tag>hold</tag><tag>distributed</tag><tag>signal</tag><tag>release</tag></tags><properties><property><name>release-signal-id</name><displayName>Release Signal Identifier</displayName><description>A value that specifies the key to a specific release signal cache. To decide whether the FlowFile that is being processed by the Wait processor should be sent to the 'success' or the 'wait' relationship, the processor checks the signals in the cache specified by this key.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>target-signal-count</name><displayName>Target Signal Count</displayName><description>The number of signals that need to be in the cache (specified by the Release Signal Identifier) in order for the FlowFile processed by the Wait processor to be sent to the ‘success’ relationship. If the number of signals in the cache has reached this number, the FlowFile is routed to the 'success' relationship and the number of signals in the cache is decreased by this value. If Signal Counter Name is specified, this processor checks a particular counter, otherwise checks against the total number of signals in the cache.</description><defaultValue>1</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>signal-counter-name</name><displayName>Signal Counter Name</displayName><description>Within the cache (specified by the Release Signal Identifier) the signals may belong to different counters. If this property is specified, the processor checks the number of signals in the cache that belong to this particular counter. If not specified, the processor checks the total number of signals in the cache.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>wait-buffer-count</name><displayName>Wait Buffer Count</displayName><description>Specify the maximum number of incoming FlowFiles that can be buffered to check whether it can move forward. The more buffer can provide the better performance, as it reduces the number of interactions with cache service by grouping FlowFiles by signal identifier. Only a signal identifier can be processed at a processor execution.</description><defaultValue>1</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>releasable-flowfile-count</name><displayName>Releasable FlowFile Count</displayName><description>A value, or the results of an Attribute Expression Language statement, which will be evaluated against a FlowFile in order to determine the releasable FlowFile count. This specifies how many FlowFiles can be released when a target count reaches target signal count. Zero (0) has a special meaning, any number of FlowFiles can be released as long as signal count matches target.</description><defaultValue>1</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>expiration-duration</name><displayName>Expiration Duration</displayName><description>Indicates the duration after which waiting FlowFiles will be routed to the 'expired' relationship</description><defaultValue>10 min</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>distributed-cache-service</name><displayName>Distributed Cache Service</displayName><description>The Controller Service that is used to check for release signals from a corresponding Notify processor</description><controllerServiceDefinition><className>org.apache.nifi.distributed.cache.client.AtomicDistributedMapCacheClient</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>attribute-copy-mode</name><displayName>Attribute Copy Mode</displayName><description>Specifies how to handle attributes copied from FlowFiles entering the Notify processor</description><defaultValue>keeporiginal</defaultValue><allowableValues><allowableValue><displayName>Replace if present</displayName><value>replace</value><description>When cached attributes are copied onto released FlowFiles, they replace any matching attributes.</description></allowableValue><allowableValue><displayName>Keep original</displayName><value>keeporiginal</value><description>Attributes on released FlowFiles are not overwritten by copied cached attributes.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>wait-mode</name><displayName>Wait Mode</displayName><description>Specifies how to handle a FlowFile waiting for a notify signal</description><defaultValue>wait</defaultValue><allowableValues><allowableValue><displayName>Transfer to wait relationship</displayName><value>wait</value><description>Transfer a FlowFile to the 'wait' relationship when whose release signal has not been notified yet. This mode allows other incoming FlowFiles to be enqueued by moving FlowFiles into the wait relationship. It is recommended to set a prioritizer (for instance First In First Out) on the 'wait' relationship.</description></allowableValue><allowableValue><displayName>Keep in the upstream connection</displayName><value>keep</value><description>Transfer a FlowFile to the upstream connection where it comes from when whose release signal has not been notified yet. This mode helps keeping upstream connection being full so that the upstream source processor will not be scheduled while back-pressure is active and limit incoming FlowFiles. </description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>wait-penalty-duration</name><displayName>Wait Penalty Duration</displayName><description>If configured, after a signal identifier got processed but did not meet the release criteria, the signal identifier is penalized and FlowFiles having the signal identifier will not be processed again for the specified period of time, so that the signal identifier will not block others to be processed. This can be useful for use cases where a Wait processor is expected to process multiple signal identifiers, and each signal identifier has multiple FlowFiles, and also the order of releasing FlowFiles is important within a signal identifier. The FlowFile order can be configured with Prioritizers. IMPORTANT: There is a limitation of number of queued signals can be processed, and Wait processor may not be able to check all queued signal ids. See additional details for the best practice.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>expired</name><description>A FlowFile that has exceeded the configured Expiration Duration will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>failure</name><description>When the cache cannot be reached, or if the Release Signal Identifier evaluates to null or empty, FlowFiles will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>A FlowFile with a matching release signal in the cache will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>wait</name><description>A FlowFile with no matching release signal in the cache will be routed to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>wait.start.timestamp</name><description>All FlowFiles will have an attribute 'wait.start.timestamp', which sets the initial epoch timestamp when the file first entered this processor.  This is used to determine the expiration time of the FlowFile.  This attribute is not written when the FlowFile is transferred to failure, expired or success</description></writesAttribute><writesAttribute><name>wait.counter.&lt;counterName&gt;</name><description>The name of each counter for which at least one signal has been present in the cache since the last time the cache was empty gets copied to the current FlowFile as an attribute.</description></writesAttribute></writesAttributes><supportsBatching>true</supportsBatching><inputRequirement>INPUT_REQUIRED</inputRequirement><seeAlso><see>org.apache.nifi.distributed.cache.client.DistributedMapCacheClientService</see><see>org.apache.nifi.distributed.cache.server.map.DistributedMapCacheServer</see><see>org.apache.nifi.processors.standard.Notify</see></seeAlso></extension><extension><name>org.apache.nifi.controller.ControllerStatusReportingTask</name><type>REPORTING_TASK</type><description>Logs the 5-minute stats that are shown in the NiFi Summary Page for Processors and Connections, as well optionally logging the deltas between the previous iteration and the current iteration. Processors' stats are logged using the org.apache.nifi.controller.ControllerStatusReportingTask.Processors logger, while Connections' stats are logged using the org.apache.nifi.controller.ControllerStatusReportingTask.Connections logger. These can be configured in the NiFi logging configuration to log to different files, if desired.</description><tags><tag>stats</tag><tag>log</tag></tags><properties><property><name>Show Deltas</name><displayName>Show Deltas</displayName><description>Specifies whether or not to show the difference in values between the current status and the previous status</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>reporting-granularity</name><displayName>Reporting Granularity</displayName><description>When reporting information, specifies the granularity of the metrics to report</description><defaultValue>five-minutes</defaultValue><allowableValues><allowableValue><displayName>Five Minutes</displayName><value>five-minutes</value><description>The stats that are reported will reflect up to the last 5 minutes' worth of processing, which will coincide with the stats that are shown in the UI.</description></allowableValue><allowableValue><displayName>One Second</displayName><value>one-second</value><description>The stats that are reported will be an average of the value per second, gathered over the last 5 minutes. This is essentially obtained by dividing the stats that are shown in the UI by 300 (300 seconds in 5 minutes), with the exception of when NiFi has been running for less than 5 minutes. In that case, the stats will be divided by the amount of time NiFi has been running.</description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties></extension><extension><name>org.apache.nifi.controller.MonitorDiskUsage</name><type>REPORTING_TASK</type><description>Checks the amount of storage space available for the specified directory and warns (via a log message and a System-Level Bulletin) if the partition on which it lives exceeds some configurable threshold of storage space</description><tags><tag>disk</tag><tag>storage</tag><tag>warning</tag><tag>monitoring</tag><tag>repo</tag></tags><properties><property><name>Threshold</name><displayName>Threshold</displayName><description>The threshold at which a bulletin will be generated to indicate that the disk usage of the partition on which the directory found is of concern</description><defaultValue>80%</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Directory Location</name><displayName>Directory Location</displayName><description>The directory path of the partition to be monitored.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Directory Display Name</name><displayName>Directory Display Name</displayName><description>The name to display for the directory in alerts.</description><defaultValue>Un-Named</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties></extension><extension><name>org.apache.nifi.controller.MonitorMemory</name><type>REPORTING_TASK</type><description>Checks the amount of Java Heap available in the JVM for a particular JVM Memory Pool. If the amount of space used exceeds some configurable threshold, will warn (via a log message and System-Level Bulletin) that the memory pool is exceeding this threshold.</description><tags><tag>monitor</tag><tag>memory</tag><tag>heap</tag><tag>jvm</tag><tag>gc</tag><tag>garbage collection</tag><tag>warning</tag></tags><properties><property><name>Memory Pool</name><displayName>Memory Pool</displayName><description>The name of the JVM Memory Pool to monitor. The allowed values for Memory Pools are platform and JVM dependent and may vary for different versions of Java and from published documentation. This reporting task will become invalidated if configured to use a Memory Pool that is not available on the currently running host platform and JVM</description><defaultValue>G1 Old Gen</defaultValue><allowableValues><allowableValue><displayName>G1 Eden Space</displayName><value>G1 Eden Space</value><description></description></allowableValue><allowableValue><displayName>G1 Old Gen</displayName><value>G1 Old Gen</value><description></description></allowableValue><allowableValue><displayName>G1 Survivor Space</displayName><value>G1 Survivor Space</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Usage Threshold</name><displayName>Usage Threshold</displayName><description>Indicates the threshold at which warnings should be generated. This can be a percentage or a Data Size</description><defaultValue>65%</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Reporting Interval</name><displayName>Reporting Interval</displayName><description>Indicates how often this reporting task should report bulletins while the memory utilization exceeds the configured threshold</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties></extension><extension><name>org.apache.nifi.parameter.DatabaseParameterProvider</name><type>PARAMETER_PROVIDER</type><description>Fetches parameters from database tables</description><tags><tag>database</tag><tag>dbcp</tag><tag>sql</tag></tags><properties><property><name>db-type</name><displayName>Database Type</displayName><description>Database Type for generating statements specific to a particular service or vendor.
The Generic Type supports most cases but selecting a specific type enables optimal processing
or additional features.
</description><defaultValue>Generic</defaultValue><allowableValues><allowableValue><displayName>Database Dialect Service</displayName><value>Database Dialect Service</value><description>Requires configuring a Database Dialect Service for SQL statements</description></allowableValue><allowableValue><displayName>Generic</displayName><value>Generic</value><description>Generates ANSI SQL</description></allowableValue><allowableValue><displayName>Oracle</displayName><value>Oracle</value><description>Generates Oracle compliant SQL</description></allowableValue><allowableValue><displayName>Oracle 12+</displayName><value>Oracle 12+</value><description>Generates Oracle compliant SQL for version 12 or greater</description></allowableValue><allowableValue><displayName>MS SQL 2012+</displayName><value>MS SQL 2012+</value><description>Generates MS SQL Compatible SQL, for version 2012 or greater</description></allowableValue><allowableValue><displayName>MS SQL 2008</displayName><value>MS SQL 2008</value><description>Generates MS SQL Compatible SQL for version 2008</description></allowableValue><allowableValue><displayName>MySQL</displayName><value>MySQL</value><description>Generates MySQL compatible SQL</description></allowableValue><allowableValue><displayName>PostgreSQL</displayName><value>PostgreSQL</value><description>Generates PostgreSQL compatible SQL</description></allowableValue><allowableValue><displayName>Phoenix</displayName><value>Phoenix</value><description>Generates Phoenix compliant SQL</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Database Dialect Service</name><displayName>Database Dialect Service</displayName><description>Database Dialect Service for generating statements specific to a particular service or vendor.</description><controllerServiceDefinition><className>org.apache.nifi.database.dialect.service.api.DatabaseDialectService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>db-type</propertyName><propertyDisplayName>Database Type</propertyDisplayName><dependentValues><dependentValue>Database Dialect Service</dependentValue></dependentValues></dependency></dependencies></property><property><name>dbcp-service</name><displayName>Database Connection Pooling Service</displayName><description>The Controller Service that is used to obtain a connection to the database.</description><controllerServiceDefinition><className>org.apache.nifi.dbcp.DBCPService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>parameter-grouping-strategy</name><displayName>Parameter Grouping Strategy</displayName><description>The strategy used to group parameters.</description><defaultValue>grouping-by-column</defaultValue><allowableValues><allowableValue><displayName>Column</displayName><value>grouping-by-column</value><description>A single table is partitioned by the 'Parameter Group Name Column'.  All rows with the same value in this column will map to a group of the same name.</description></allowableValue><allowableValue><displayName>Table Name</displayName><value>grouping-by-table-name</value><description>An entire table maps to a Parameter Group.  The group name will be the table name.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>table-name</name><displayName>Table Name</displayName><description>The name of the database table containing the parameters.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>parameter-grouping-strategy</propertyName><propertyDisplayName>Parameter Grouping Strategy</propertyDisplayName><dependentValues><dependentValue>grouping-by-column</dependentValue></dependentValues></dependency></dependencies></property><property><name>table-names</name><displayName>Table Names</displayName><description>A comma-separated list of names of the database tables containing the parameters.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>parameter-grouping-strategy</propertyName><propertyDisplayName>Parameter Grouping Strategy</propertyDisplayName><dependentValues><dependentValue>grouping-by-table-name</dependentValue></dependentValues></dependency></dependencies></property><property><name>parameter-name-column</name><displayName>Parameter Name Column</displayName><description>The name of a column containing the parameter name.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>parameter-value-column</name><displayName>Parameter Value Column</displayName><description>The name of a column containing the parameter value.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>parameter-group-name-column</name><displayName>Parameter Group Name Column</displayName><description>The name of a column containing the name of the parameter group into which the parameter should be mapped.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>parameter-grouping-strategy</propertyName><propertyDisplayName>Parameter Grouping Strategy</propertyDisplayName><dependentValues><dependentValue>grouping-by-column</dependentValue></dependentValues></dependency></dependencies></property><property><name>sql-where-clause</name><displayName>SQL WHERE clause</displayName><description>A optional SQL query 'WHERE' clause by which to filter all results.  The 'WHERE' keyword should not be included.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties></extension><extension><name>org.apache.nifi.parameter.EnvironmentVariableParameterProvider</name><type>PARAMETER_PROVIDER</type><description>Fetches parameters from environment variables</description><tags><tag>environment</tag><tag>variable</tag></tags><properties><property><name>parameter-group-name</name><displayName>Parameter Group Name</displayName><description>The name of the parameter group that will be fetched.  This indicates the name of the Parameter Context that may receive the fetched parameters.</description><defaultValue>Environment Variables</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>environment-variable-inclusion-strategy</name><displayName>Environment Variable Inclusion Strategy</displayName><description>Indicates how Environment Variables should be included</description><defaultValue>include-all</defaultValue><allowableValues><allowableValue><displayName>Include All</displayName><value>include-all</value><description>All Environment Variables will be included</description></allowableValue><allowableValue><displayName>Comma-Separated</displayName><value>comma-separated</value><description>List comma-separated Environment Variable names to include</description></allowableValue><allowableValue><displayName>Regular Expression</displayName><value>regex</value><description>Include Environment Variable names that match a Regular Expression</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>include-environment-variables</name><displayName>Include Environment Variables</displayName><description>Specifies environment variable names that should be included from the fetched environment variables.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>environment-variable-inclusion-strategy</propertyName><propertyDisplayName>Environment Variable Inclusion Strategy</propertyDisplayName><dependentValues><dependentValue>comma-separated</dependentValue><dependentValue>regex</dependentValue></dependentValues></dependency></dependencies></property></properties><restricted><restrictions><restriction><requiredPermission>access environment credentials</requiredPermission><explanation>Provides operator the ability to read environment variables, which may contain environment credentials.</explanation></restriction></restrictions></restricted></extension><extension><name>org.apache.nifi.parameter.KubernetesSecretParameterProvider</name><type>PARAMETER_PROVIDER</type><description>Fetches parameters from files, in the format provided by Kubernetes mounted secrets.  Parameter groups are indicated by a set of directories, and files within the directories map to parameter names. The content of the file becomes the parameter value.  Since Kubernetes mounted Secrets are base64-encoded, the parameter provider defaults to Base64-decoding the value of the parameter from the file.</description><tags><tag>file</tag></tags><properties><property><name>parameter-group-directories</name><displayName>Parameter Group Directories</displayName><description>A comma-separated list of directory absolute paths that will map to named parameter groups.  Each directory that contains files will map to a parameter group, named after the innermost directory in the path.  Files inside the directory will map to parameter names, whose values are the content of each respective file.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>parameter-value-byte-limit</name><displayName>Parameter Value Byte Limit</displayName><description>The maximum byte size of a parameter value.  Since parameter values are pulled from the contents of files, this is a safeguard that can prevent memory issues if large files are included.</description><defaultValue>256 B</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>parameter-value-encoding</name><displayName>Parameter Value Encoding</displayName><description>Indicates how parameter values are encoded inside Parameter files.</description><defaultValue>base64</defaultValue><allowableValues><allowableValue><displayName>Base64</displayName><value>base64</value><description>File content is Base64-encoded, and will be decoded before providing the value as a Parameter.</description></allowableValue><allowableValue><displayName>Plain text</displayName><value>plaintext</value><description>File content is not encoded, and will be provided directly as a Parameter value.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><restricted><restrictions><restriction><requiredPermission>read filesystem</requiredPermission><explanation>Provides operator the ability to read from any file that NiFi has access to.</explanation></restriction></restrictions></restricted></extension><extension><name>org.apache.nifi.parameter.OnePasswordParameterProvider</name><type>PARAMETER_PROVIDER</type><description>Fetches parameters from 1Password Connect Server</description><tags><tag>1Password</tag></tags><properties><property><name>Web Client Service Provider</name><displayName>Web Client Service Provider</displayName><description>Controller service for HTTP client operations.</description><controllerServiceDefinition><className>org.apache.nifi.web.client.provider.api.WebClientServiceProvider</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.4.0</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Connect Server</name><displayName>Connect Server</displayName><description>HTTP endpoint of the 1Password Connect Server to connect to. Example: http://localhost:8080</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Access Token</name><displayName>Access Token</displayName><description>Access Token used for authentication against the 1Password APIs.</description><required>true</required><sensitive>true</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties></extension><extension><name>org.apache.nifi.flowanalysis.rules.DisallowComponentType</name><type>FLOW_ANALYSIS_RULE</type><description>Produces rule violations for each component (i.e. processors or controller services) of a given type.</description><tags><tag>component</tag><tag>processor</tag><tag>controller service</tag><tag>type</tag></tags><properties><property><name>component-type</name><displayName>Component Type</displayName><description>Components of the given type will produce a rule violation (i.e. they shouldn't exist). Either the simple or the fully qualified name of the type should be provided.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties></extension><extension><name>org.apache.nifi.flowanalysis.rules.RequireServerSSLContextService</name><type>FLOW_ANALYSIS_RULE</type><description>Produces rule violations for each component (i.e. processors or controller services) having a property identifying an SSLContextService that is not set.</description><tags><tag>component</tag><tag>processor</tag><tag>controller service</tag><tag>type</tag><tag>ssl</tag><tag>tls</tag><tag>listen</tag></tags><useCases><useCase><description>Ensure that an SSL Context has been configured for the specified components. This helps avoid ports being opened for insecure (plaintext, e.g.) communications.</description><notes></notes><keywords></keywords><inputRequirement>INPUT_ALLOWED</inputRequirement><configuration>To avoid the violation, ensure that the "SSL Context Service" property is set for the specified component(s).
</configuration></useCase></useCases></extension><extension><name>org.apache.nifi.flowanalysis.rules.RestrictBackpressureSettings</name><type>FLOW_ANALYSIS_RULE</type><description>This rule will generate a violation if backpressure settings of a connection exceed configured thresholds. Improper configuration of backpressure settings can lead to decreased performance because of excessive swapping and can fill up the content repository with too much in-flight data.</description><tags><tag>connection</tag><tag>backpressure</tag></tags><properties><property><name>Minimum Backpressure Object Count Threshold</name><displayName>Minimum Backpressure Object Count Threshold</displayName><description>This is the minimum value that should be set for the Object Count backpressure setting on connections. This can be used to prevent a user from setting a value of 0 which disables backpressure based on count.</description><defaultValue>1</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum Backpressure Object Count Threshold</name><displayName>Maximum Backpressure Object Count Threshold</displayName><description>This is the maximum value that should be set for the Object Count backpressure setting on connections. This can be used to prevent a user from setting a very high value that may be leading to a lot of swapping.</description><defaultValue>10000</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Minimum Backpressure Data Size Threshold</name><displayName>Minimum Backpressure Data Size Threshold</displayName><description>This is the minimum value that should be set for the Data Size backpressure setting on connections. This can be used to prevent a user from setting a value of 0 which disables backpressure based on size.</description><defaultValue>1 MB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum Backpressure Data Size Threshold</name><displayName>Maximum Backpressure Data Size Threshold</displayName><description>This is the maximum value that should be set for the Data Size backpressure setting on connections. This can be used to prevent a user from setting a very high value that may be filling up the content repo.</description><defaultValue>1 GB</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties></extension><extension><name>org.apache.nifi.flowanalysis.rules.RestrictFlowFileExpiration</name><type>FLOW_ANALYSIS_RULE</type><description>This rule will generate a violation if FlowFile expiration settings of a connection exceed configured thresholds. Improper configuration of FlowFile expiration settings can cause files to be deleted unexpectedly and can cause the content repository to fill up.</description><tags><tag>connection</tag><tag>expiration</tag><tag>age</tag></tags><properties><property><name>Allow Zero Expiration</name><displayName>Allow Zero Expiration</displayName><description>If set to true, a 0 second FlowFile Expiration on connections is allowed despite other configured restrictions. If set to false, a 0 second FlowFile Expiration will be compared against the other configured restrictions. This can be used to prevent a user from setting a value of 0 seconds which could fill up the content repository if files accumulate in front of stopped processors.</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Minimum FlowFile Expiration</name><displayName>Minimum FlowFile Expiration</displayName><description>This is the minimum value that should be set for the FlowFile Expiration setting on connections. This can be used to prevent a user from setting a very small expiration which can cause files to be deleted unexpectedly.</description><defaultValue>1 min</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Maximum FlowFile Expiration</name><displayName>Maximum FlowFile Expiration</displayName><description>This is the maximum value that should be set for the FlowFile Expiration setting on connections. This can be used to prevent a user from setting a large expiration which could fill up the content repository if files accumulate in front of stopped processors.</description><defaultValue>30 days</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties></extension></extensions></extensionManifest>